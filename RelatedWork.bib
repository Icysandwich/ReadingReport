#############################################
# This file is machine generated, do not edit
#############################################

@inbook{aagaard:charme:2001,
  abstract = {Most verifications of out-of-order microprocessors compare state-machine-based implementations and specifications, where the specification is based on the instruction-set architecture. The different efforts use a variety of correctness statements, implementations, and verification approaches. We present a framework for classifying correctness statements about safety that is independent of implementation representation and verification approach. We characterize the relationships between the different statements and illustrate how existing and classical approaches fit within this framework.},
  address = {Berlin, Heidelberg},
  author = {Mark D. Aagaard and Byron Cook and Nancy A. Day and Robert B. Jones},
  booktitle = {Correct Hardware Design and Verification Methods: 11th IFIP WG 10.5 Advanced Research Working Conference, CHARME 2001 Livingston, Scotland, UK, September 4-7, 2001 Proceedings},
  doi = {10.1007/3-540-44798-9_33},
  isbn = {978-3-540-44798-6},
  pages = {433-448},
  publisher = {Springer},
  title = {{A framework for microprocessor correctness statements}},
  year = {2001}
}

@inbook{aagaard:fmcad:2000,
  abstract = {We present a formal verification methodology for datapathdominated hardware. This provides a systematic but flexible framework within which to organize the activities undertaken in large-scale verification efforts and to structure the associated code and proof-script artifacts. The methodology deploys a combination of model checking and lightweight theorem proving in higher-order logic, tightly integrated within a general-purpose functional programming language that allows the framework to be easily customized and also serves as a specification language. We illustrate the methodology-which has has proved highly effective in large-scale industrial trials-with the verification of an IEEE- compliant, extended precision floating-point adder.},
  address = {Berlin, Heidelberg},
  author = {Mark D. Aagaard and Robert B. Jones and Thomas F. Melham and John W. O'Leary and Carl-Johan H. Seger},
  booktitle = {Formal Methods in Computer-Aided Design: Third International Conference, FMCAD 2000 Austin, TX, USA, November 1-3, 2000 Proceedings},
  doi = {10.1007/3-540-40922-X_17},
  isbn = {978-3-540-40922-9},
  pages = {300-319},
  publisher = {Springer},
  title = {{A methodology for large-scale hardware verification}},
  year = {2000}
}

@article{abadi:tcs:1991,
  author = {Martín Abadi and Leslie Lamport},
  doi = {10.1016/0304-3975(91)90224-P},
  journal = {Theoretical Computer Science},
  number = {2},
  pages = {253-284},
  publisher = {Elsevier},
  title = {{The existence of refinement mappings}},
  volume = {82},
  year = {1991}
}

@inproceedings{abtahi:chi:2020,
  abstract = {Experienced programmers are capable of learning new programming languages independently using various available resources, but we lack a comprehensive understanding of which resources they find most valuable in doing so. In this paper, we study how experienced programmers learn Rust, a systems programming language with extensive documentation and example code, an active online community, and descriptive compiler errors. We develop a task that requires learning Rust syntax and comprehending the Rust-specific approach to mutability and ownership. Our results show that users spend 43\% of online time viewing example code and that programmers appreciate in-line compiler errors, choosing to refresh, on average, every 30.6 seconds after first discovering this feature. The average time between these refreshes predicted total task time, but individual resource choices did not. Based on our findings we offer design implications for language and IDE developers.},
  address = {New York, NY, USA},
  author = {Parastoo Abtahi and Griffin Dietz},
  booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
  doi = {10.1145/3334480.3383069},
  isbn = {9781450368193},
  keywords = {learning resources, rust, computer science education, programming languages},
  link = {https://doi.org/10.1145/3334480.3383069},
  location = {Honolulu, HI, USA},
  numpages = {8},
  pages = {1-8},
  publisher = {Association for Computing Machinery},
  series = {CHI EA '20},
  title = {{Learning Rust: How experienced programmers leverage resources to learn a new programming language}},
  url = {https://doi.org/10.1145/3334480.3383069},
  year = {2020}
}

@techreport{albin:cli:1995,
  author = {Kenneth L. Albin and Bishop C. Brock and Warren A. Hunt Jr. and Lawrence M. Smith},
  institution = {Computational Logic, Inc},
  month = {January},
  title = {{Testing the FM9001 microprocessor}},
  year = {1995}
}

@article{alexopoulos:tps:2020,
  address = {New York, NY, USA},
  articleno = {3},
  author = {Nikolaos Alexopoulos and Sheikh Mahbub Habib and Steffen Schulz and Max Mühlhüuser},
  doi = {10.1145/3406112},
  issn = {2471-2566},
  issue_date = {September 2020},
  journal = {ACM Trans. Priv. Secur.},
  keywords = {debian GNU/Linux, vulnerability discovery rate, Empirical study},
  link = {https://doi.org/10.1145/3406112},
  month = {September},
  number = {1},
  numpages = {33},
  publisher = {Association for Computing Machinery},
  title = {{The tip of the iceberg: On the merits of finding security bugs}},
  url = {https://doi.org/10.1145/3406112},
  volume = {24},
  year = {2020}
}

@article{alglave:toplas:2014,
  author = {Jade Alglave and Luc Maranget and Michael Tautschnig},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/journals/toplas/AlglaveMT14},
  doi = {10.1145/2627752},
  journal = {ACM Transactions on Programming Languages and Systems},
  number = {2},
  pages = {7:1-7:74},
  timestamp = {Thu, 07 May 2015 18:17:39 +0200},
  title = {{Herding cats: Modelling, simulation, testing, and data mining for weak memory}},
  volume = {36},
  year = {2014}
}

@inproceedings{alkassar:vstte:2010,
  author = {Eyad Alkassar and Mark A. Hillebrand and Wolfgang J. Paul and Elena Petrova},
  booktitle = {International Conference on Verified Software: Theories, Tools, and Experiments},
  doi = {10.1007/978-3-642-15057-9_3},
  organization = {Springer},
  pages = {40-54},
  title = {{Automated verification of a small hypervisor}},
  year = {2010}
}

@inproceedings{alkassar:vstte:2012,
  author = {Eyad Alkassar and Ernie Cohen and Mikhail Kovalev and Wolfgang J. Paul},
  booktitle = {International Conference on Verified Software: Tools, Theories, Experiments},
  doi = {10.1007/978-3-642-27705-4_17},
  organization = {Springer},
  pages = {209-224},
  title = {{Verification of TLB virtualization implemented in C}},
  year = {2012}
}

@inproceedings{almeida:security:2016,
  author = {José Bacelar Almeida and Manuel Barbosa and Gilles Barthe and François Dupressoir and Michael Emmi},
  booktitle = {25th USENIX Security Symposium (USENIX Security 16)},
  pages = {53-70},
  title = {{Verifying constant-time implementations}},
  year = {2016}
}

@inproceedings{almohri:codaspy:2018,
  abstract = {The Rust programming language has a safe memory model that promises to eliminate critical memory bugs. While the language is strong in doing so, its memory guarantees are lost when any unsafe blocks are used. Unsafe code is often needed to call library functions written in an unsafe language inside a Rust program. We present Fidelius Charm (FC), a system that protects a programmer-specified subset of data in memory from unauthorized access through vulnerable unsafe libraries. FC does this by limiting access to the program's memory while executing unsafe libraries. FC uses standard features of Rust and utilizes the Linux kernel as a trusted base for splitting the address space into a trusted privileged region under the control of functions written in Rust and a region available to unsafe external libraries. This paper presents our design and implementation of FC, presents two case studies for using FC in Rust TLS libraries, and reports on experiments showing its performance overhead is low for typical uses.},
  address = {New York, NY, USA},
  author = {Hussain M. J. Almohri and David Evans},
  booktitle = {Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy},
  doi = {10.1145/3176258.3176330},
  isbn = {9781450356329},
  keywords = {isolation, sandboxing, compartmentalization, rust},
  link = {https://doi.org/10.1145/3176258.3176330},
  location = {Tempe, AZ, USA},
  numpages = {8},
  pages = {248-255},
  publisher = {Association for Computing Machinery},
  series = {CODASPY '18},
  title = {{Fidelius Charm: Isolating unsafe Rust code}},
  url = {https://doi.org/10.1145/3176258.3176330},
  year = {2018}
}

@inproceedings{amani:asplos:2016,
  address = {New York, NY, USA},
  author = {Sidney Amani and Alex Hixon and Zilin Chen and Christine Rizkallah and Peter Chubb and Liam O'Connor and Joel Beeren and Yutaka Nagashima and Japheth Lim and Thomas Arthur Leck Sewell and Joseph Tuong and Gabriele Keller and Toby Murray and Gerwin Klein and Gernot Heiser},
  booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/2872362.2872404},
  isbn = {9781450340915},
  keywords = {file systems, co-generation, isabelle/hol, domain-specific languages, verification},
  location = {Atlanta, Georgia, USA},
  numpages = {14},
  pages = {175–188},
  publisher = {Association for Computing Machinery},
  series = {ASPLOS'16},
  title = {{Cogent: Verifying high-assurance file system implementations}},
  url = {https://doi.org/10.1145/2872362.2872404},
  year = {2016}
}

@article{ananda:osr:1992,
  acmid = {142121},
  address = {New York, NY, USA},
  author = {Akkihebbal L. Ananda and Boon Hwa Tay and Eng Kiat Koh},
  doi = {10.1145/142111.142121},
  issn = {0163-5980},
  issue_date = {April 1992},
  journal = {SIGOPS Operating Systems Review},
  keywords = {asynchronous RPC, distributed systems, high-throughput, interprocess communication (IPC), intra-machine call, low-latency, parallelism, remote procedure call (RPC), synchronous RPC, transport-independent},
  month = {April},
  number = {2},
  numpages = {18},
  pages = {92-109},
  publisher = {ACM},
  title = {{A survey of asynchronous remote procedure calls}},
  volume = {26},
  year = {1992}
}

@inproceedings{anderson:icse:2016,
  abstract = {All modern web browsers -- Internet Explorer, Firefox, Chrome, Opera, and Safari -- have a core rendering engine written in C++. This language choice was made because it affords the systems programmer complete control of the underlying hardware features and memory in use, and it provides a transparent compilation model. Unfortunately, this language is complex (especially to new contributors!), challenging to write correct parallel code in, and highly susceptible to memory safety issues that potentially lead to security holes.Servo is a project started at Mozilla Research to build a new web browser engine that preserves the capabilities of these other browser engines but also both takes advantage of the recent trends in parallel hardware and is more memory-safe. We use a new language, Rust, that provides us a similar level of control of the underlying system to C++ but which statically prevents many memory safety issues and provides direct support for parallelism and concurrency.In this paper, we show how a language with an advanced type system can address many of the most common security issues and software engineering challenges in other browser engines, while still producing code that has the same performance and memory profile. This language is also quite accessible to new open source contributors and employees, even those without a background in C++ or systems programming. We also outline several pitfalls encountered along the way and describe some potential areas for future improvement.},
  address = {New York, NY, USA},
  author = {Brian Anderson and Lars Bergstrom and Manish Goregaokar and Josh Matthews and Keegan McAllister and Jack Moffitt and Simon Sapin},
  booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
  doi = {10.1145/2889160.2889229},
  isbn = {9781450342056},
  keywords = {parallelism, browser engine, servo, concurrency, Rust},
  link = {https://doi.org/10.1145/2889160.2889229},
  location = {Austin, Texas},
  numpages = {9},
  pages = {81-89},
  publisher = {Association for Computing Machinery},
  series = {ICSE '16},
  title = {{Engineering the Servo web browser engine using Rust}},
  url = {https://doi.org/10.1145/2889160.2889229},
  year = {2016}
}

@inproceedings{andronick:icse:2012,
  acmid = {2337352},
  address = {Piscataway, NJ, USA},
  author = {June Andronick and Ross Jeffery and Gerwin Klein and Rafal Kolanski and Mark Staples and He Zhang and Liming Zhu},
  booktitle = {Proceedings of the 34th International Conference on Software Engineering},
  doi = {10.1109/ICSE.2012.6227120},
  isbn = {978-1-4673-1067-3},
  location = {Zurich, Switzerland},
  numpages = {10},
  pages = {1002-1011},
  publisher = {IEEE Press},
  series = {ICSE'12},
  title = {{Large-scale formal verification in practice: A process perspective}},
  year = {2012}
}

@inproceedings{angelini:vizsec:2019,
  abstract = {Modern software systems require the support of automatic program analyses to answer questions about their correctness, reliability, and safety. In recent years, symbolic execution techniques have played a pivotal role in this field, backing research in different domains such as software testing and software security. Like other powerful machine analyses, symbolic execution is often affected by efficiency and scalability issues that can be mitigated when a domain expert interacts with its working, steering the computation to achieve the desired goals faster. In this paper we explore how visual analytics techniques can help the user to grasp properties of the ongoing analysis and use such insights to refine the symbolic exploration process. To this end, we discuss two real-world usage scenarios from the malware analysis and the vulnerability detection domains, showing how our prototype system can help users make a wiser use of symbolic exploration techniques in the analysis of binary code.},
  author = {Marco Angelini and Graziano Blasilli and Luca Borzacchiello and Emilio Coppa and Daniele Cono D’Elia and Camil Demetrescu and Simone Lenti and Simone Nicchi and Giuseppe Santucci},
  booktitle = {2019 IEEE Symposium on Visualization for Cyber Security (VizSec)},
  doi = {10.1109/VizSec48167.2019.9161524},
  issn = {2639-4332},
  keywords = {data visualisation;invasive software;program testing;security of data;symbolic exploration process;vulnerability detection domains;prototype system;symbolic exploration techniques;automatic program analyses;symbolic execution techniques;software testing;software security;machine analyses;scalability issues;visual analytics techniques;SymNav;Engines;Software;Security;Explosions;Software testing;Computer bugs;Visualization;Human-centered computing\textemdash Visualization\textemdash Visualization application domains\textemdash Visual Analytics;Security and privacy\textemdash Software and application security\textemdash Software reverse engineering},
  month = {Oct},
  number = {},
  pages = {1-11},
  title = {{SymNav: Visually assisting symbolic execution}},
  volume = {},
  year = {2019}
}

@article{armstrong:arw:2018,
  abstract = {Processor instruction set architectures (ISAs) are typically specified using a mixture of prose and pseudocode. We present ongoing work on expressing such specifications rigorously and automatically trans- lating them to interactive theorem prover definitions, making them amenable to mechanised proof. Our ISA descriptions are written in Sail-a custom ISA specification language designed to support idioms from var- ious processor vendor's pseudocode, with lightweight dependent typing for bitvectors, targeting a variety of use cases including sequential and concurrent ISA semantics. From Sail we aim to portably generate usable theorem prover definitions for multiple provers, including Isabelle, HOL4, and Coq. We are focusing on the full ARMv8.3-A specification, CHERI-MIPS, and RISC-V, together with fragments of IBM POWER and x86.},
  ar_shortname = {ARW 18},
  author = {Alasdair Armstrong and Thomas Bauereiss and Brian Campbell and Shaked Flur and Kathryn E. Gray and Prashanth Mundkur and Robert M. Norton and Christopher Pulte and Alastair D. Reid and Peter Sewell and Ian Stark and Mark Wassell},
  booktitle = {Automated Reasoning Workshop 2018},
  location = {Cambridge, UK},
  month = {April},
  title = {{Detailed models of instruction set architectures: From pseudocode to formal semantics}},
  year = {2018}
}

@inproceedings{armstrong:popl19:2019,
  abstract = {Architecture specifications notionally define the fundamental interface between hardware and software: the envelope of allowed behaviour for processor implementations, and the basic assumptions for software development and verification.  But in practice, they are typically prose and pseudocode documents, not rigorous or executable artifacts, leaving software and verification on shaky ground.  In this paper, we present rigorous semantic models for the sequential behaviour of large parts of the mainstream ARMv8-A, RISC-V, and MIPS architectures, and the research CHERI-MIPS architecture, that are complete enough to boot operating systems, variously Linux, FreeBSD, or seL4.  Our ARMv8-A models are automatically translated from authoritative ARM-internal definitions, and (in one variant) tested against the ARM Architecture Validation Suite.  We do this using a custom language for ISA semantics, Sail, with a lightweight dependent type system, that supports automatic generation of emulator code in C and OCaml, and automatic generation of proof-assistant definitions for Isabelle, HOL4, and (currently only for MIPS) Coq.  We use the former for validation, and to assess specification coverage.  To demonstrate the usability of the latter, we prove (in Isabelle) correctness of a purely functional characterisation of ARMv8-A address translation.  We moreover integrate the RISC-V model into the RMEM tool for (user-mode) relaxed-memory concurrency exploration.  We prove (on paper) the soundness of the core Sail type system.  We thereby take a big step towards making the architectural abstraction actually well-defined, establishing foundations for verification and reasoning.},
  address = {New York, NY, USA},
  ar_shortname = {POPL 19},
  author = {Alasdair Armstrong and Thomas Bauereiss and Brian Campbell and Alastair D. Reid and Kathryn E. Gray and Robert M. Norton and Prashanth Mundkur and Mark Wassell and Jon French and Christopher Pulte and Shaked Flur and Ian Stark and Neel R. Krishnaswami and Peter Sewell},
  booktitle = {Proc. 46th ACM SIGPLAN Symposium on Principles of Programming Languages},
  day = {13-19},
  doi = {10.1145/3290384},
  journal = {PACMPL},
  location = {Cascais/Lisbon, Portugal},
  month = {January},
  number = {POPL},
  numpages = {31},
  pages = {71:1-71:31},
  publisher = {ACM},
  title = {{ISA semantics for ARMv8-A, RISC-V, and CHERI-MIPS}},
  volume = {3},
  year = {2019}
}

@article{armstrong:spisa:2019,
  ar_shortname = {SpISA 19},
  author = {Alasdair Armstrong and Thomas Bauereiss and Brian Campbell and Alastair D. Reid and Kathryn E. Gray and Robert M. Norton and Prashanth Mundkur and Mark Wassell and Jon French and Christopher Pulte and Shaked Flur and Ian Stark and Neel R. Krishnaswami and Peter Sewell},
  booktitle = {SpISA 2019: Workshop on Instruction Set Architecture Specification},
  location = {Portland, Oregon, USA},
  month = {September},
  title = {{The state of Sail}},
  year = {2019}
}

@phdthesis{asanovic:phd:1998,
  author = {Krste Asanović},
  month = {May},
  school = {University of California, Berkeley},
  title = {{Vector microprocessors}},
  year = {1998}
}

@article{astrauskas:oopsla:2019,
  address = {New York, NY, USA},
  articleno = {Article 147},
  author = {Vytautas Astrauskas and Peter Müller and Federico Poli and Alexander J. Summers},
  doi = {10.1145/3360573},
  issue_date = {October 2019},
  journal = {Proc. ACM Program. Lang.},
  keywords = {heap-manipulating programs, type systems, Rust, concurrency},
  month = {October},
  number = {OOPSLA},
  numpages = {30},
  publisher = {Association for Computing Machinery},
  title = {{Leveraging Rust types for modular specification and verification}},
  url = {https://doi.org/10.1145/3360573},
  volume = {3},
  year = {2019}
}

@inproceedings{astrauskas:oopsla:2020,
  author = {Vytautas Astrauskas and Christoph Matheja and Federico Poli and Peter Müller and Alexander J. Summers},
  booktitle = {Object-Oriented Programming Systems, Languages, and Applications (OOPSLA)},
  doi = {10.1145/3428204},
  journal = {Proc. ACM Program. Lang.},
  month = {November},
  pages = {27},
  publisher = {ACM},
  title = {{How do programmers use unsafe Rust?}},
  volume = {4},
  year = {2020}
}

@article{avgerinos:cacm:2014,
  abstract = {The idea is to identify security-critical software bugs so they can be fixed first.},
  address = {New York, NY, USA},
  author = {Thanassis Avgerinos and Sang Kil Cha and Alexandre Rebert and Edward J. Schwartz and Maverick Woo and David Brumley},
  doi = {10.1145/2560217.2560219},
  issn = {0001-0782},
  issue_date = {February 2014},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/2560217.2560219},
  month = {February},
  number = {2},
  numpages = {11},
  pages = {74-84},
  publisher = {Association for Computing Machinery},
  title = {{Automatic exploit generation}},
  url = {https://doi.org/10.1145/2560217.2560219},
  volume = {57},
  year = {2014}
}

@inproceedings{avgerinos:icse:2014,
  address = {New York, NY, USA},
  author = {Thanassis Avgerinos and Alexandre Rebert and Sang Kil Cha and David Brumley},
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  doi = {10.1145/2568225.2568293},
  isbn = {9781450327565},
  keywords = {Verification, Symbolic Execution, Veritesting},
  link = {https://doi.org/10.1145/2568225.2568293},
  location = {Hyderabad, India},
  numpages = {12},
  pages = {1083-1094},
  publisher = {Association for Computing Machinery},
  series = {ICSE 2014},
  title = {{Enhancing symbolic execution with veritesting}},
  url = {https://doi.org/10.1145/2568225.2568293},
  year = {2014}
}

@inproceedings{azevedo:post:2018,
  abstract = {We give a rigorous characterization of what it means for a programming language to be memory safe, capturing the intuition that memory safety supports local reasoning about state. We formalize this principle in two ways. First, we show how a small memory-safe language validates a noninterference property: a program can neither affect nor be affected by unreachable parts of the state. Second, we extend separation logic, a proof system for heap-manipulating programs, with a ``memory-safe variant'' of its frame rule. The new rule is stronger because it applies even when parts of the program are buggy or malicious, but also weaker because it demands a stricter form of separation between parts of the program state. We also consider a number of pragmatically motivated variations on memory safety and the reasoning principles they support. As an application of our characterization, we evaluate the security of a previously proposed dynamic monitor for memory safety of heap-allocated data.},
  address = {Cham},
  author = {Arthur Azevedo de Amorim and Cătălin Hrițcu and Benjamin C. Pierce},
  booktitle = {Principles of Security and Trust},
  editor = {Bauer, Lujo and Küsters, Ralf},
  isbn = {978-3-319-89722-6},
  pages = {79-105},
  publisher = {Springer International Publishing},
  title = {{The meaning of memory safety}},
  year = {2018}
}

@inproceedings{babic:fse:2019,
  address = {New York, NY, USA},
  author = {Domagoj Babić and Stefan Bucur and Yaohui Chen and Franjo Ivančić and Tim King and Markus Kusano and Caroline Lemieux and László Szekeres and Wei Wang},
  booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3338906.3340456},
  isbn = {9781450355728},
  keywords = {code synthesis, testing, program slicing, fuzz testing, software security, fuzzing, automated test generation},
  link = {https://doi.org/10.1145/3338906.3340456},
  location = {Tallinn, Estonia},
  numpages = {11},
  pages = {975-985},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2019},
  title = {{FUDGE: Fuzz driver generation at scale}},
  url = {https://doi.org/10.1145/3338906.3340456},
  year = {2019}
}

@inproceedings{bader:vmcai:2018,
  abstract = {Both static and dynamic program verification approaches have significant disadvantages when considered in isolation. Inspired by research on gradual typing, we propose gradual verification to seamlessly and flexibly combine static and dynamic verification. Drawing on general principles from abstract interpretation, and in particular on the recent Abstracting Gradual Typing methodology of Garcia et al., we systematically derive a gradual verification system from a static one. This approach yields, by construction, a gradual verification system that is compatible with the original static system, but overcomes its rigidity by resorting to dynamic verification when desired. As with gradual typing, the programmer can control the trade-off between static and dynamic checking by tuning the (im)precision of pre- and postconditions. The formal semantics of the gradual verification system and the proofs of its properties, including the gradual guarantees of Siek et al., have been fully mechanized in the Coq proof assistant.},
  address = {Cham},
  author = {Johannes Bader and Jonathan Aldrich and Éric Tanter},
  booktitle = {Verification, Model Checking, and Abstract Interpretation},
  editor = {Dillig, Isil and Palsberg, Jens},
  isbn = {978-3-319-73721-8},
  pages = {25-46},
  publisher = {Springer International Publishing},
  title = {{Gradual program verification}},
  year = {2018}
}

@article{balasubramanium:hotos:2017,
  address = {New York, NY, USA},
  author = {Abhiram Balasubramanian and Marek S. Baranowski and Anton Burtsev and Aurojit Panda and Zvonimir Rakamarić and Leonid Ryzhyk},
  doi = {10.1145/3139645.3139660},
  issn = {0163-5980},
  issue_date = {September 2017},
  journal = {SIGOPS Oper. Syst. Rev.},
  month = {September},
  number = {1},
  numpages = {6},
  pages = {94–99},
  publisher = {Association for Computing Machinery},
  title = {{System programming in Rust: Beyond safety}},
  url = {https://doi.org/10.1145/3139645.3139660},
  volume = {51},
  year = {2017}
}

@article{baldoni:compsurv:2018,
  address = {New York, NY, USA},
  articleno = {50},
  author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
  doi = {10.1145/3182657},
  issn = {0360-0300},
  issue_date = {July 2018},
  journal = {ACM Computing Surveys},
  keywords = {static analysis, software testing, Symbolic execution, concolic execution},
  link = {https://doi.org/10.1145/3182657},
  month = {May},
  number = {3},
  numpages = {39},
  publisher = {Association for Computing Machinery},
  title = {{A survey of symbolic execution techniques}},
  url = {https://doi.org/10.1145/3182657},
  volume = {51},
  year = {2018}
}

@techreport{ball:dsse:2015,
  abstract = {Dynamic symbolic execution (DSE) is a well-known technique for automatically generating tests to achieve higher levels of coverage in a program. Two keys ideas of DSE are to: (1) seed symbolic execution by executing a program on an initial input; (2) using concrete values from the program execution in place of symbolic expressions whenever symbolic reasoning is hard or not desired. We describe DSE for a simple core language and then present a minimalist implementation of DSE for Python (in Python) that follows this basic recipe. The code is available at https://www.github.com/thomasjball/PyExZ3/ (tagged v1.0) and has been designed to make it easy to experiment with and extend.},
  author = {Thomas Ball and Jakub Daniel},
  booktitle = {The 2014 Marktober Summer School on Deop},
  edition = {Proceedings of the 2014 Marktoberdorf Summer School on Dependable Software Systems Engineering, The 2014 Marktober Summer School on Deop},
  journal = {Proceedings of the 2014 Marktoberdorf Summer School on Dependable Software Systems Engineering},
  link = {https://www.microsoft.com/en-us/research/publication/deconstructing-dynamic-symbolic-execution/},
  month = {January},
  note = {Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, Boston, MA},
  number = {MSR-TR-2015-95},
  publisher = {IOS Press},
  title = {{Deconstructing dynamic symbolic execution}},
  url = {https://www.microsoft.com/en-us/research/publication/deconstructing-dynamic-symbolic-execution/},
  year = {2015}
}

@inproceedings{ball:pldi:2001,
  address = {New York, NY, USA},
  author = {Thomas Ball and Rupak Majumdar and Todd Millstein and Sriram K. Rajamani},
  booktitle = {Proceedings of the ACM SIGPLAN 2001 Conference on Programming Language Design and Implementation},
  doi = {10.1145/378795.378846},
  isbn = {1581134142},
  link = {https://doi.org/10.1145/378795.378846},
  location = {Snowbird, Utah, USA},
  numpages = {11},
  pages = {203-213},
  publisher = {Association for Computing Machinery},
  series = {PLDI '01},
  title = {{Automatic predicate abstraction of C programs}},
  url = {https://doi.org/10.1145/378795.378846},
  year = {2001}
}

@inproceedings{bansal:asplos:2006,
  acmid = {1168906},
  address = {New York, NY, USA},
  author = {Sorav Bansal and Alex Aiken},
  booktitle = {Proceedings of the 12th International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/1168857.1168906},
  isbn = {1-59593-451-0},
  keywords = {code selection, peephole optimization, superoptimization},
  location = {San Jose, California, USA},
  numpages = {10},
  pages = {394-403},
  publisher = {ACM},
  series = {ASPLOS XII},
  title = {{Automatic generation of peephole superoptimizers}},
  year = {2006}
}

@inproceedings{bansal:osdi:2008,
  acmid = {1855754},
  address = {Berkeley, CA, USA},
  author = {Sorav Bansal and Alex Aiken},
  booktitle = {Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation},
  link = {https://www.usenix.org/legacy/event/osdi08/tech/full_papers/bansal/bansal.pdf},
  location = {San Diego, California},
  numpages = {16},
  pages = {177-192},
  publisher = {USENIX Association},
  series = {OSDI'08},
  title = {{Binary translation using peephole superoptimizers}},
  url = {https://www.usenix.org/legacy/event/osdi08/tech/full_papers/bansal/bansal.pdf},
  year = {2008}
}

@inproceedings{baranova:atva:2017,
  abstract = {The fourth version of the DIVINE model checker provides a modular platform for verification of real-world programs. It is built around an efficient interpreter of LLVM code which, together with a small, verification-oriented operating system and a set of runtime libraries, enables verification of code written in C and C++.},
  address = {Cham},
  author = {Zuzana Baranová and Jiří Barnat and Katarína Kejstová and Tadeáš Kučera and Henrich Lauko and Jan Mrázek and Petr Ročkai and Vladimír Štill},
  booktitle = {Automated Technology for Verification and Analysis},
  editor = {D'Souza, Deepak and Narayan Kumar, K.},
  isbn = {978-3-319-68167-2},
  pages = {201-207},
  publisher = {Springer International Publishing},
  title = {{Model checking of C and C++ with DIVINE 4}},
  year = {2017}
}

@inproceedings{baranowski:atva:2018,
  abstract = {Rust is an emerging systems programming language with guaranteed memory safety and modern language features that has been extensively adopted to build safety-critical software. However, there is currently a lack of automated software verifiers for Rust. In this work, we present our experience extending the SMACK verifier to enable its usage on Rust programs. We evaluate SMACK on a set of Rust programs to demonstrate a wide spectrum of language features it supports.},
  address = {Cham},
  author = {Marek S. Baranowski and Shaobo He and Zvonimir Rakamarić},
  booktitle = {Automated Technology for Verification and Analysis},
  doi = {10.1007/978-3-030-01090-4_32},
  editor = {Lahiri, Shuvendu K. and Wang, Chao},
  isbn = {978-3-030-01090-4},
  pages = {528-535},
  publisher = {Springer International Publishing},
  title = {{Verifying Rust programs with SMACK}},
  year = {2018}
}

@article{barbacci2:computer:1973,
  author = {Mario R. Barbacci and C. Gordon Bell and Daniel P. Siewiorek},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/computer/BarbacciBS73a.bib},
  doi = {10.1109/C-M.1973.217035},
  journal = {IEEE Computer},
  link = {https://doi.org/10.1109/C-M.1973.217035},
  number = {3},
  pages = {22-24},
  timestamp = {Wed, 17 May 2017 01:00:00 +0200},
  title = {{ISP: A notation to describe a computer's instruction sets}},
  url = {https://doi.org/10.1109/C-M.1973.217035},
  volume = {6},
  year = {1973}
}

@inproceedings{barbacci:afips:1977,
  author = {Mario R. Barbacci and Daniel P. Siewiorek and Robert L. Gordon and Rosemary Howbrigg and Susan Zuckerman},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/afips/BarbacciSGHZ77.bib},
  booktitle = {American Federation of Information Processing Societies: 1977 National Computer Conference, June 13-16, 1977, Dallas, Texas, USA},
  doi = {10.1145/1499402.1499435},
  link = {https://doi.org/10.1145/1499402.1499435},
  pages = {161-173},
  publisher = {AFIPS Press},
  series = {AFIPS Conference Proceedings},
  timestamp = {Tue, 06 Nov 2018 00:00:00 +0100},
  title = {{An architectural research facility: ISP descriptions, simulation, data collection}},
  url = {https://doi.org/10.1145/1499402.1499435},
  volume = {46},
  year = {1977}
}

@techreport{barbacci:cmu:1972,
  author = {Mario R. Barbacci and C. Gordon Bell and Allen C. Newell},
  institution = {Carnegie Mellon University},
  link = {http://digitalcollections.library.cmu.edu/awweb/awarchive?type=file&item=360601},
  month = {January},
  pages = {},
  title = {{ISP: A language to describe instruction sets and other register transfer systems}},
  url = {http://digitalcollections.library.cmu.edu/awweb/awarchive?type=file&item=360601},
  year = {1972}
}

@article{barbacci:computer:1973,
  author = {Mario R. Barbacci and C. Gordon Bell and Daniel P. Siewiorek},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/computer/BarbacciBS73.bib},
  doi = {10.1109/C-M.1973.217034},
  journal = {IEEE Computer},
  link = {https://doi.org/10.1109/C-M.1973.217034},
  number = {3},
  pages = {19-21},
  timestamp = {Wed, 17 May 2017 01:00:00 +0200},
  title = {{PMS: A notation to describe computer structures}},
  url = {https://doi.org/10.1109/C-M.1973.217034},
  volume = {6},
  year = {1973}
}

@article{barbacci:computer:1977,
  author = {Mario R. Barbacci and Daniel P. Siewiorek},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/computer/BarbacciS77.bib},
  doi = {10.1109/C-M.1977.217524},
  journal = {IEEE Computer},
  link = {https://doi.org/10.1109/C-M.1977.217524},
  number = {10},
  pages = {36-43},
  timestamp = {Mon, 05 Jun 2017 01:00:00 +0200},
  title = {{Evaluation of the CFA test programs via formal computer descriptions}},
  url = {https://doi.org/10.1109/C-M.1977.217524},
  volume = {10},
  year = {1977}
}

@article{barbacci:computer:1978,
  author = {Mario R. Barbacci and Alan Parker},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/computer/BarbacciP78.bib},
  doi = {10.1109/C-M.1978.218183},
  journal = {IEEE Computer},
  link = {https://doi.org/10.1109/C-M.1978.218183},
  number = {5},
  pages = {51-56},
  timestamp = {Wed, 17 May 2017 01:00:00 +0200},
  title = {{Using emulation to verify formal architecture descriptions}},
  url = {https://doi.org/10.1109/C-M.1978.218183},
  volume = {11},
  year = {1978}
}

@inproceedings{barbacci:dac:1979,
  author = {Mario R. Barbacci},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/dac/Barbacci79.bib},
  booktitle = {Proceedings of the 16th Design Automation Conference, DAC '79, San Diego, California, USA, June 25-27, 1979},
  doi = {10.1109/DAC.1979.1600090},
  editor = {David W. Hightower},
  link = {http://dl.acm.org/citation.cfm?id=811693},
  pages = {64-72},
  publisher = {ACM},
  timestamp = {Thu, 01 Mar 2012 18:20:57 +0100},
  title = {{Instruction set processor specifications for simulation, evaluation, and synthesis}},
  url = {http://dl.acm.org/citation.cfm?id=811693},
  year = {1979}
}

@inproceedings{barbacci:icse:1988,
  author = {Mario R. Barbacci and Charles B. Weinstock and Jeannette M. Wing},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icse/BarbacciWW88.bib},
  booktitle = {Proceedings, 10th International Conference on Software Engineering, Singapore, Singapore, April 11-15, 1988},
  doi = {10.1109/ICSE.1988.93684},
  editor = {Tan Chin Nam and Larry E. Druffel and Bertrand Meyer},
  link = {http://dl.acm.org/citation.cfm?id=55826},
  pages = {19-29},
  publisher = {IEEE Computer Society},
  timestamp = {Mon, 30 Oct 2017 11:35:10 +0100},
  title = {{Programming at the Processor-Memory-Switch level}},
  url = {http://dl.acm.org/citation.cfm?id=55826},
  year = {1988}
}

@article{barbacci:ieee:1981,
  author = {Mario R. Barbacci},
  doi = {10.1109/TC.1981.6312154},
  issn = {0018-9340},
  journal = {IEEE Transactions on Computers},
  keywords = {high level languages;logic design;ISPS;Instruction Set Processor Specifications;architecture evaluation;computer description language;digital design process;hardware description language;program verification;simulation;software generation;Algorithms;Computational modeling;Computer languages;Computers;Hardware;Radiation detectors;Registers;Architecture evaluation;automatic programming;behavioral description;computer description languages;computer-aided design;instruction set processor},
  month = {January},
  number = {1},
  pages = {24-40},
  title = {{Instruction set processor specifications (ISPS): The notation and its applications}},
  volume = {C-30},
  year = {1981}
}

@article{barbacci:ieeetc:1975,
  author = {Mario R. Barbacci},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/tc/Barbacci75.bib},
  doi = {10.1109/T-C.1975.224181},
  journal = {IEEE Trans. Computers},
  link = {https://doi.org/10.1109/T-C.1975.224181},
  number = {2},
  pages = {137-150},
  timestamp = {Sat, 20 May 2017 01:00:00 +0200},
  title = {{A comparison of register transfer languages for describing computers and digital systems}},
  url = {https://doi.org/10.1109/T-C.1975.224181},
  volume = {24},
  year = {1975}
}

@article{barbacci:ieeetc:1981,
  author = {Mario R. Barbacci},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/tc/Barbacci81.bib},
  doi = {10.1109/TC.1981.6312154},
  journal = {IEEE Trans. Computers},
  link = {https://doi.org/10.1109/TC.1981.6312154},
  number = {1},
  pages = {24-40},
  timestamp = {Sat, 20 May 2017 01:00:00 +0200},
  title = {{Instruction set processor specifications (ISPS): The notation and its applications}},
  url = {https://doi.org/10.1109/TC.1981.6312154},
  volume = {30},
  year = {1981}
}

@inproceedings{barbacci:isca:1973,
  author = {Mario R. Barbacci and Daniel P. Siewiorek},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/isca/BarbacciS73.bib},
  booktitle = {Proceedings of the 1st Annual Symposium on Computer Architecture, Gainesville, FL, USA, December 1973},
  doi = {10.1145/800123.803975},
  editor = {G. Jack Lipovski and Stephen A. Szygenda},
  link = {https://doi.org/10.1145/800123.803975},
  pages = {101-106},
  publisher = {ACM},
  timestamp = {Tue, 06 Nov 2018 00:00:00 +0100},
  title = {{Automated exploration of the design space for register transfer (RT) systems}},
  url = {https://doi.org/10.1145/800123.803975},
  year = {1973}
}

@article{barnett:cacm:2011,
  address = {New York, NY, USA},
  author = {Mike Barnett and Manuel Fähndrich and K. Rustan M. Leino and Peter Müller and Wolfram Schulte and Herman Venter},
  doi = {10.1145/1953122.1953145},
  issn = {0001-0782},
  issue_date = {June 2011},
  journal = {Communications of the ACM},
  month = {June},
  number = {6},
  numpages = {11},
  pages = {81-91},
  publisher = {Association for Computing Machinery},
  title = {{Specification and verification: The Spec\# experience}},
  url = {https://doi.org/10.1145/1953122.1953145},
  volume = {54},
  year = {2011}
}

@inproceedings{barnett:cassis:2004,
  author = {Mike Barnett and K. Rustan M. Leino and Wolfram Schulte},
  booktitle = {International Workshop on Construction and Analysis of Safe, Secure, and Interoperable Smart Devices},
  doi = {10.1007/978-3-540-30569-9_3},
  organization = {Springer},
  pages = {49-69},
  title = {{The Spec\# programming system: An overview}},
  year = {2004}
}

@inproceedings{barnett:fmco:2005,
  author = {Mike Barnett and Bor-Yuh Evan Chang and Robert DeLine and Bart Jacobs and K. Rustan M. Leino},
  booktitle = {International Symposium on Formal Methods for Components and Objects},
  doi = {10.1007/11804192_17},
  organization = {Springer},
  pages = {364-387},
  title = {{Boogie: A modular reusable verifier for object-oriented programs}},
  year = {2005}
}

@inbook{barnett:vstte:2005,
  abstract = {The Spec\# programming system [4] is a new attempt to increase the quality of general purpose, industrial software. Using old wisdom, we propose the use of specifications to make programmer assumptions explicit. Using modern technology, we propose the use of tools to enforce the specifications. To increase its chances of having impact, we want to design the system so that it can be widely adopted.},
  address = {Berlin, Heidelberg},
  author = {Mike Barnett and Robert DeLine and Manuel Fähndrich and Bart Jacobs and K. Rustan M. Leino and Wolfram Schulte and Herman Venter},
  booktitle = {Verified Software: Theories, Tools, Experiments: First IFIP TC 2/WG 2.3 Conference, VSTTE 2005, Zurich, Switzerland, October 10-13, 2005, Revised Selected Papers and Discussions},
  doi = {10.1007/978-3-540-69149-5\_16},
  editor = {Meyer, Bertrand and Woodcock, Jim},
  isbn = {978-3-540-69149-5},
  pages = {144-152},
  publisher = {Springer Berlin Heidelberg},
  title = {{The Spec\# programming system: Challenges and directions}},
  url = {https://doi.org/10.1007/978-3-540-69149-5\_16},
  year = {2008}
}

@article{barr:tse:2015,
  author = {Earl T. Barr and Mark Harman and Phil McMinn and Muzammil Shahbaz and Shin Yoo},
  doi = {10.1109/TSE.2014.2372785},
  issn = {0098-5589},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {formal specification;program testing;contract-driven development;domain specific information;informal oracle guidance;informal specifications;metamorphic testing;oracle automation;software testing practice;software testing research;test oracle information;test oracle problem;Automation;Licenses;Market research;Probabilistic logic;Reliability;Software testing;Automatic testing;Test oracle;Testing formalism;automatic testing;testing formalism},
  month = {May},
  number = {5},
  pages = {507-525},
  title = {{The oracle problem in software testing: A survey}},
  volume = {41},
  year = {2015}
}

@inproceedings{barrett:cade:2000,
  author = {Clark W. Barrett and David L. Dill and Aaron Stump},
  booktitle = {International Conference on Automated Deduction},
  doi = {10.1007/10721959_6},
  organization = {Springer},
  pages = {79-98},
  title = {{A framework for cooperating decision procedures}},
  year = {2000}
}

@inproceedings{barrett:cav:2011,
  author = {Clark W. Barrett and Christopher L. Conway and Morgan Deters and Liana Hadarean and Dejan Jovanović and Tim King and Andrew Reynolds and Cesare Tinelli},
  booktitle = {Proceedings of the 23rd International Conference on Computer Aided Verification (CAV '11)},
  category = {Conference Publications},
  doi = {10.1007/978-3-642-22110-1_14},
  editor = {Ganesh Gopalakrishnan and Shaz Qadeer},
  month = {July},
  note = {Snowbird, Utah},
  pages = {171-177},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  title = {{CVC4}},
  volume = {6806},
  year = {2011}
}

@incollection{barrett:mlf:2015,
  address = {London, UK},
  author = {Clark W. Barrett and Leonardo de Moura and Pascal Fontaine},
  booktitle = {All about Proofs, Proofs for All},
  editor = {David Delahaye and Woltzenlogel Paleo, Bruno},
  isbn = {978-1-84890-166-7},
  link = {http://www.cs.stanford.edu/~barrett/pubs/BdMF15.pdf},
  month = {January},
  pages = {23-44},
  publisher = {College Publications},
  series = {Mathematical Logic and Foundations},
  title = {{Proofs in satisfiability modulo theories}},
  url = {http://www.cs.stanford.edu/~barrett/pubs/BdMF15.pdf},
  volume = {55},
  year = {2015}
}

@misc{barrett:smtlib:2016,
  author = {Clark W. Barrett and Pascal Fontaine and Cesare Tinelli},
  title = {{The Satisfiability Modulo Theories Library (SMT-LIB)}},
  year = {2016}
}

@inproceedings{barthe:csfw:2004,
  author = {Gilles Barthe and Pedro R. D'Argenio and Tamara Rezk},
  booktitle = {17th IEEE Computer Security Foundations Workshop, (CSFW-17 2004)},
  doi = {10.1109/CSFW.2004.17},
  pages = {100-114},
  title = {{Secure information flow by self composition}},
  year = {2004}
}

@article{barthe:iacr:2007,
  author = {Gilles Barthe and Benjamin Grégoire and Vincent Laporte},
  journal = {IACR Cryptology ePrint Archive},
  pages = {38},
  title = {{Provably secure compilation of side-channel countermeasures.}},
  volume = {2017},
  year = {2017}
}

@article{barthe:mscs:2011,
  author = {Gilles Barthe and Pedro R. D'Argenio and Tamara Rezk},
  doi = {10.1017/S0960129511000193},
  journal = {Mathematical Structures in Computer Science},
  number = {6},
  pages = {1207-1252},
  publisher = {Cambridge University Press},
  title = {{Secure information flow by self-composition}},
  volume = {21},
  year = {2011}
}

@article{bastian:oopsla:2019,
  author = {Théophile Bastian and Stephen Kell and Francesco Zappa Nardelli},
  doi = {10.1145/3360572},
  journal = {Proceedings of the ACM on Programming Languages},
  number = {OOPSLA},
  pages = {146},
  publisher = {ACM},
  title = {{Reliable and fast DWARF-based stack unwinding}},
  volume = {3},
  year = {2019}
}

@inproceedings{baumann:hotos:2017,
  acmid = {3103002},
  address = {New York, NY, USA},
  author = {Andrew Baumann},
  booktitle = {Proceedings of the 16th Workshop on Hot Topics in Operating Systems},
  doi = {10.1145/3102980.3103002},
  isbn = {978-1-4503-5068-6},
  keywords = {CET, SGX, complexity, instruction set extensions, security, x86},
  location = {Whistler, BC, Canada},
  numpages = {6},
  pages = {132-137},
  publisher = {ACM},
  series = {HotOS '17},
  title = {{Hardware is the new software}},
  year = {2017}
}

@inproceedings{becker:fm:2016,
  author = {Hanno Becker and Juan Manuel Crespo and Jacek Galowicz and Ulrich Hensel and Yoichi Hirai and César Kunz and Keiko Nakata and Jorge Luis Sacchini and Hendrik Tews and Thomas Tuerk},
  booktitle = {International Symposium on Formal Methods},
  doi = {10.1007/978-3-319-48989-6_5},
  organization = {Springer},
  pages = {69-84},
  title = {{Combining mechanized proofs and model-based testing in the formal analysis of a hypervisor}},
  year = {2016}
}

@inproceedings{becker:tacas:2019,
  author = {Nils Becker and Peter Müller and Alexander J. Summers},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems (TACAS)},
  editor = {Vojnar, Tomás and Zhang, Lijun},
  pages = {99-116},
  publisher = {Springer-Verlag},
  series = {LNCS},
  title = {{The Axiom profiler: Understanding and debugging SMT quantifier instantiations}},
  volume = {11427},
  year = {2019}
}

@mastersthesis{beckmann:msc:2020,
  author = {Jakob Beckmann},
  location = {Zürich},
  month = {April},
  school = {Programming Methodology Group, Institute for Programming Languages and Systems, ETH Zürich},
  title = {{Verifying safe clients of unsafe code and trait implementations in Rust}},
  year = {2020}
}

@mastersthesis{beingessner:msc:2015,
  author = {Alexis Beingessner},
  link = {https://github.com/Gankra/thesis/blob/master/thesis.pdf},
  location = {Ottawa, Ontario, Canada},
  school = {Carleton University},
  title = {{You can't spell trust without Rust}},
  year = {2015}
}

@inproceedings{bell:afips:1970,
  acmid = {1476993},
  address = {New York, NY, USA},
  author = {C. Gordon Bell and Allen C. Newell},
  booktitle = {Proceedings of the May 5-7, 1970, Spring Joint Computer Conference},
  doi = {10.1145/1476936.1476993},
  location = {Atlantic City, New Jersey},
  numpages = {24},
  pages = {351-374},
  publisher = {ACM},
  series = {AFIPS '70 (Spring)},
  title = {{The PMS and ISP descriptive systems for computer structures}},
  year = {1970}
}

@book{bell:book:1971,
  author = {C. Gordon Bell and Allen C. Newell},
  isbn = {0070043574},
  publisher = {McGraw-Hill Pub. Co.},
  title = {{Computer structures: Readings and examples}},
  year = {1971}
}

@article{bell:cacm:2008,
  address = {New York, NY, USA},
  author = {C. Gordon Bell},
  doi = {10.1145/1327452.1327453},
  issn = {0001-0782},
  issue_date = {January 2008},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/1327452.1327453},
  month = {January},
  number = {1},
  numpages = {9},
  pages = {86-94},
  publisher = {Association for Computing Machinery},
  title = {{Bell's law for the birth and death of computer classes}},
  url = {https://doi.org/10.1145/1327452.1327453},
  volume = {51},
  year = {2008}
}

@article{bell:procieee:2014,
  abstract = {During the 1960s a new class of low-cost computers evolved, which, combined with a growing number of individuals programming and using them, led to wide-ranging innovations that helped to stimulate decades of growth of the entire computer industry. Sold as components to original equipment manufacturers, classic minicomputers provided the opportunity for businesses to create new solutions for process control, manufacturing, engineering design, scientific experiments, communication systems, and many more.},
  author = {C. Gordon Bell},
  doi = {10.1109/JPROC.2014.2306257},
  issn = {1558-2256},
  journal = {Proceedings of the IEEE},
  keywords = {DP industry;minicomputers;minicomputers;low-cost computer;computer industry;Computers;History;Product development;Tablet computers;Microcomputers},
  month = {April},
  number = {4},
  pages = {629-638},
  title = {{STARS: Rise and fall of minicomputers [scanning our past]}},
  volume = {102},
  year = {2014}
}

@article{bembenek:oopsla:2020,
  abstract = {Satisfiability modulo theories (SMT) solving has become a critical part of many static analyses, including symbolic execution, refinement type checking, and model checking. We propose Formulog, a domain-specific language that makes it possible to write a range of SMT-based static analyses in a way that is both close to their formal specifications and amenable to high-level optimizations and efficient evaluation.  Formulog extends the logic programming language Datalog with a first-order functional language and mechanisms for representing and reasoning about SMT formulas; a novel type system supports the construction of expressive formulas, while ensuring that neither normal evaluation nor SMT solving goes wrong. Our case studies demonstrate that a range of SMT-based analyses can naturally and concisely be encoded in Formulog, and that - thanks to this encoding - high-level Datalog-style optimizations can be automatically and advantageously applied to these analyses.},
  address = {New York, NY, USA},
  articleno = {141},
  author = {Aaron Bembenek and Michael Greenberg and Stephen Chong},
  doi = {10.1145/3428209},
  issue_date = {November 2020},
  journal = {Proc. ACM Program. Lang.},
  keywords = {Datalog, SMT solving},
  link = {https://doi.org/10.1145/3428209},
  month = {November},
  number = {OOPSLA},
  numpages = {31},
  publisher = {Association for Computing Machinery},
  title = {{Formulog: Datalog for SMT-based static analysis}},
  url = {https://doi.org/10.1145/3428209},
  volume = {4},
  year = {2020}
}

@inproceedings{berdine:aplas:2005,
  abstract = {We describe a sound method for automatically proving Hoare triples for loop-free code in Separation Logic, for certain preconditions and postconditions (symbolic heaps). The method uses a form of symbolic execution, a decidable proof theory for symbolic heaps, and extraction of frame axioms from incomplete proofs. This is a precursor to the use of the logic in automatic specification checking, program analysis, and model checking.},
  address = {Berlin, Heidelberg},
  author = {Josh Berdine and Cristiano Calcagno and Peter W. O'Hearn},
  booktitle = {Programming Languages and Systems},
  doi = {10.1007/11575467_5},
  editor = {Yi, Kwangkeun},
  isbn = {978-3-540-32247-4},
  pages = {52-68},
  publisher = {Springer Berlin Heidelberg},
  title = {{Symbolic execution with separation logic}},
  year = {2005}
}

@inproceedings{berdine:cav:2007,
  abstract = {We propose a shape analysis that adapts to some of the complex composite data structures found in industrial systems-level programs. Examples of such data structures include ``cyclic doubly-linked lists of acyclic singly-linked lists'', ``singly-linked lists of cyclic doubly-linked lists with back-pointers to head nodes'', etc. The analysis introduces the use of generic higher-order inductive predicates describing spatial relationships together with a method of synthesizing new parameterized spatial predicates which can be used in combination with the higher-order predicates. In order to evaluate the proposed approach for realistic programs we have performed experiments on examples drawn from device drivers: the analysis proved safety of the data structure manipulation of several routines belonging to an IEEE 1394 (firewire) driver, and also found several previously unknown memory safety bugs.},
  address = {Berlin, Heidelberg},
  author = {Josh Berdine and Cristiano Calcagno and Byron Cook and Dino Distefano and Peter W. O'Hearn and Thomas Wies and Hongseok Yang},
  booktitle = {Computer Aided Verification},
  editor = {Damm, Werner and Hermanns, Holger},
  isbn = {978-3-540-73368-3},
  pages = {178-192},
  publisher = {Springer Berlin Heidelberg},
  title = {{Shape analysis for composite data structures}},
  year = {2007}
}

@inproceedings{berdine:fmco:2005,
  abstract = {Separation logic is a program logic for reasoning about programs that manipulate pointer data structures. We describe Smallfoot, a tool for checking certain lightweight separation logic specifications. The assertions describe the shapes of data structures rather than their detailed contents, and this allows reasoning to be fully automatic. The presentation in the paper is tutorial in style. We illustrate what the tool can do via examples which are oriented toward novel aspects of separation logic, namely: avoidance of frame axioms (which say what a procedure does not change); embracement of \textasciigrave \textasciigrave dirty\textquotesingle \textquotesingle  features such as memory disposal and address arithmetic; information hiding in the presence of pointers; and modular reasoning about concurrent programs.},
  address = {Berlin, Heidelberg},
  author = {Josh Berdine and Cristiano Calcagno and Peter W. O'Hearn},
  booktitle = {Formal Methods for Components and Objects},
  doi = {10.1007/11804192_6},
  editor = {de Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and de Roever, Willem-Paul},
  isbn = {978-3-540-36750-5},
  pages = {115-137},
  publisher = {Springer Berlin Heidelberg},
  title = {{Smallfoot: Modular automatic assertion checking with separation logic}},
  year = {2006}
}

@inproceedings{bergan:oopsla:2014,
  abstract = {We describe an algorithm to perform symbolic execution of a multithreaded program starting from an arbitrary program context. We argue that this can enable more efficient symbolic exploration of deep code paths in multithreaded programs by allowing the symbolic engine to jump directly to program contexts of interest.The key challenge is modeling the initial context with reasonable precision - an overly approximate model leads to exploration of many infeasible paths during symbolic execution, while a very precise model would be so expensive to compute that computing it would defeat the purpose of jumping directly to the initial context in the first place. We propose a context-specific dataflow analysis that approximates the initial context cheaply, but precisely enough to avoid some common causes of infeasible-path explosion. This model is necessarily approximate - it may leave portions of the memory state unconstrained, leaving our symbolic execution unable to answer simple questions such as "which thread holds lock A?". For such cases, we describe a novel algorithm for evaluating symbolic synchronization during symbolic execution. Our symbolic execution semantics are sound and complete up to the limits of the underlying SMT solver. We describe initial experiments on an implementation in Cloud 9.},
  address = {New York, NY, USA},
  author = {Tom Bergan and Dan Grossman and Luis Ceze},
  booktitle = {Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages \& Applications},
  doi = {10.1145/2660193.2660200},
  isbn = {9781450325851},
  keywords = {static analysis, multithreading, symbolic execution},
  link = {https://doi.org/10.1145/2660193.2660200},
  location = {Portland, Oregon, USA},
  numpages = {16},
  pages = {491-506},
  publisher = {Association for Computing Machinery},
  series = {OOPSLA '14},
  title = {{Symbolic execution of multithreaded programs from arbitrary program contexts}},
  url = {https://doi.org/10.1145/2660193.2660200},
  year = {2014}
}

@inproceedings{bershad:cmpcon:1993,
  author = {Brian N. Bershad and Matthew J. Zekauskas and Wayne A. Sawdon},
  booktitle = {Digest of Papers, Compcon Spring},
  doi = {10.1109/CMPCON.1993.289730},
  title = {{The Midway distributed shared memory system}},
  year = {1993}
}

@article{bevier:jar:1989,
  abstract = {The term systems verification refers to the specification and verification of the components of a computing system, including compilers, assemblers, operating systems and hardware. We outline our approach to systems verification, and summarize the application of this approach to several systems components. These components consist of a code generator for a simple high-level language, an assembler and linking loader, a simple operating system kernel, and a microprocessor design.},
  author = {William R. Bevier and Warren A. Hunt Jr. and J. Strother Moore and William D. Young},
  day = {01},
  doi = {10.1007/BF00243131},
  issn = {1573-0670},
  journal = {Journal of Automated Reasoning},
  month = {December},
  number = {4},
  pages = {411-428},
  title = {{An approach to systems verification}},
  volume = {5},
  year = {1989}
}

@inproceedings{beyer:ase:2019,
  author = {Dirk Beyer and Thomas Lemberger},
  booktitle = {2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE.2019.00105},
  number = {},
  pages = {1074-1077},
  title = {{TestCov: Robust test-suite execution and coverage measurement}},
  volume = {},
  year = {2019}
}

@inproceedings{beyer:cav:2011,
  author = {Dirk Beyer and M. Erkan Keremoglu},
  booktitle = {Proceedings of the 23rd International Conference on Computer Aided Verification (CAV 2011, Snowbird, UT, July 14-20)},
  doi = {10.1007/978-3-642-22110-1_16},
  editor = {G.~Gopalakrishnan and S.~Qadeer},
  isbn = {978-3-642-22109-5},
  keyword = {CPAchecker,Software Model Checking},
  link = {https://cpachecker.sosy-lab.org},
  pages = {184-190},
  pdf = {https://www.sosy-lab.org/research/pub/2011-CAV.CPAchecker\_A\_Tool\_for\_Configurable\_Software\_Verification.pdf},
  publisher = {Springer-Verlag, Heidelberg},
  series = {LNCS 6806},
  title = {{CPAchecker: A tool for configurable software verification}},
  url = {https://cpachecker.sosy-lab.org},
  year = {2011}
}

@inproceedings{beyer:hvc:2017,
  abstract = {In practice, software testing has been the established method for finding bugs in programs for a long time. But in the last 15 years, software model checking has received a lot of attention, and many successful tools for software model checking exist today. We believe it is time for a careful comparative evaluation of automatic software testing against automatic software model checking. We chose six existing tools for automatic test-case generation, namely AFL-fuzz, CPATiger, Crest-ppc, FShell, Klee, and PRtest, and four tools for software model checking, namely Cbmc, CPA-Seq, Esbmc-incr, and Esbmc-kInd, for the task of finding specification violations in a large benchmark suite consisting of 5 693 C programs. In order to perform such an evaluation, we have implemented a framework for test-based falsification (tbf) that executes and validates test cases produced by test-case generation tools in order to find errors in programs. The conclusion of our experiments is that software model checkers can (i) find a substantially larger number of bugs (ii) in less time, and (iii) require less adjustment to the input programs.},
  address = {Cham},
  author = {Dirk Beyer and Thomas Lemberger},
  booktitle = {Hardware and Software: Verification and Testing},
  doi = {10.1007/978-3-319-70389-3_7},
  editor = {Strichman, Ofer and Tzoref-Brill, Rachel},
  isbn = {978-3-319-70389-3},
  pages = {99-114},
  publisher = {Springer International Publishing},
  title = {{Software verification: Testing vs. model checking}},
  year = {2017}
}

@article{beyer:ijsttt:2006,
  abstract = {In the verified architecture microprocessor (VAMP) project we have designed, functionally verified, and synthesized a processor with full DLX instruction set, delayed branch, Tomasulo scheduler, maskable nested precise interrupts, pipelined fully IEEE compatible dual precision floating point unit with variable latency, and separate instruction and data caches. The verification has been carried out in the theorem proving system PVS. The processor has been implemented on a Xilinx FPGA.},
  author = {Sven Beyer and Christian Jacobi and Daniel Kröning and Dirk Leinenbach and Wolfgang J. Paul},
  day = {01},
  doi = {10.1007/s10009-006-0204-6},
  issn = {1433-2787},
  journal = {International Journal on Software Tools for Technology Transfer},
  month = {August},
  number = {4},
  pages = {411-430},
  title = {{Putting it all together - Formal verification of the VAMP}},
  volume = {8},
  year = {2006}
}

@article{beyer:ijsttt:2007,
  annote = {DOI: 10.1007/s10009-007-0044-z
BLAST is available at:  http://www.sosy-lab.org/\textasciitilde dbeyer/Blast},
  author = {Dirk Beyer and Thomas A. Henzinger and Ranjit Jhala and Rupak Majumdar},
  doi = {10.1007/s10009-007-0044-z},
  journal = {International Journal on Software Tools for Technology Transfer (STTT)},
  keyword = {Software Model Checking},
  link = {},
  number = {5-6},
  pages = {505-525},
  pdf = {https://www.sosy-lab.org/research/pub/2007-STTT.The\_Software\_Model\_Checker\_BLAST.pdf},
  postscript = {https://www.sosy-lab.org/research/prs/2008-05-08\_EPFL\_BLAST\_Dirk.pdf},
  title = {{The software model checker BLAST: Applications to software engineering}},
  url = {},
  volume = {9},
  year = {2007}
}

@inproceedings{beyer:sas:2004,
  annote = {SAS 2004, Verona, August 26-28,
Roberto Giacobazzi, editor.
\textcopyright  2006 Springer-Verlag 
Online:  http://dx.doi.org/10.1007/b99688},
  author = {Dirk Beyer and Adam J. Chlipala and Thomas A. Henzinger and Ranjit Jhala and Rupak Majumdar},
  booktitle = {Proceedings of the 11th International Static Analysis Symposium (SAS 2004, Verona, August 26-28)},
  editor = {R.~Giacobazzi},
  isbn = {3-540-22791-1},
  keyword = {BLAST,Software Model Checking},
  link = {},
  pages = {2-18},
  pdf = {https://www.sosy-lab.org/research/pub/2004-SAS.The\_Blast\_Query\_Language\_for\_Software\_Verification.pdf},
  publisher = {Springer-Verlag, Heidelberg},
  series = {LNCS 3148},
  title = {{The BLAST query language for software verification}},
  url = {},
  year = {2004}
}

@inbook{biere:tacas:1999,
  abstract = {Symbolic Model Checking [3], [14] has proven to be a powerful technique for the verification of reactive systems. BDDs [2] have traditionally been used as a symbolic representation of the system. In this paper we show how boolean decision procedures, like St{\aa}lmarck's Method [16] or the Davis & Putnam Procedure [7], can replace BDDs. This new technique avoids the space blow up of BDDs, generates counterexamples much faster, and sometimes speeds up the verification. In addition, it produces counterexamples of minimal length. We introduce a bounded model checking procedure for LTL which reduces model checking to propositional satisfiability.We show that bounded LTL model checking can be done without a tableau construction. We have implemented a model checker BMC, based on bounded model checking, and preliminary results are presented.},
  address = {Berlin, Heidelberg},
  author = {Armin Biere and Alessandro Cimatti and Edmund M. Clarke and Yunshan Zhu},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems: 5th International Conference, TACAS'99 Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS'99 Amsterdam, The Netherlands, March 22-28, 1999 Proceedings},
  doi = {10.1007/3-540-49059-0_14},
  isbn = {978-3-540-49059-3},
  pages = {193-207},
  publisher = {Springer},
  title = {{Symbolic model checking without BDDs}},
  year = {1999}
}

@article{binder:cacm:1994,
  address = {New York, NY, USA},
  author = {Robert V. Binder},
  doi = {10.1145/182987.184077},
  issn = {0001-0782},
  issue_date = {Sept. 1994},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/182987.184077},
  month = {September},
  number = {9},
  numpages = {15},
  pages = {87-101},
  publisher = {Association for Computing Machinery},
  title = {{Design for testability in object-oriented systems}},
  url = {https://doi.org/10.1145/182987.184077},
  volume = {37},
  year = {1994}
}

@inproceedings{bird:sc:1993,
  author = {Peter L. Bird and Alasdair Rawsthorne and Nigel P. Topham},
  booktitle = {International Conference on Supercomputing},
  doi = {10.1145/165939.165952},
  pages = {47-56},
  title = {{The effectiveness of decoupling}},
  year = {1993}
}

@article{birrell:tocs:1984,
  author = {Andrew D. Birrell and Bruce Jay Nelson},
  doi = {10.1145/2080.357392},
  issn = {0734-2071},
  journal = {ACM Transactions on Computing Systems (TOCS)},
  number = {1},
  pages = {39-59},
  publisher = {ACM Press},
  title = {{Implementing remote procedure calls}},
  volume = {2},
  year = {1984}
}

@inproceedings{blanchard:fmics:2015,
  author = {Allan Blanchard and Nikolai Kosmatov and Matthieu Lemerre and Frédéric Loulergue},
  booktitle = {International Workshop on Formal Methods for Industrial Critical Systems},
  doi = {10.1007/978-3-319-19458-5_2},
  organization = {Springer},
  pages = {15-30},
  title = {{A case study on formal verification of the Anaxagoros hypervisor paging system with Frama-C}},
  year = {2015}
}

@article{blanqui:rapido:2011,
  author = {Frédéric Blanqui and Claude Helmstetter and Vania Joloboff and Jean-François Monin and Xiaomu Shi},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1109-4351},
  journal = {RAPIDO'11 3rd Workshop on: Rapid Simulation and Performance Evaluation: Methods and Tools},
  link = {http://arxiv.org/abs/1109.4351},
  timestamp = {Mon, 05 Dec 2011 18:05:33 +0100},
  title = {{Designing a CPU model: from a pseudo-formal document to fast code}},
  url = {http://arxiv.org/abs/1109.4351},
  year = {2011}
}

@book{blelloch:book:1990,
  address = {Cambridge, MA, USA},
  author = {Guy E. Blelloch},
  isbn = {0-262-02313-X},
  publisher = {MIT Press},
  title = {{Vector models for data-parallel computing}},
  year = {1990}
}

@article{blom:ijsttt:2015,
  author = {Stefan Blom and Marieke Huisman},
  doi = {10.1007/s10009-015-0372-3},
  journal = {International journal on software tools for technology transfer},
  number = {6},
  pages = {757-781},
  publisher = {Springer},
  title = {{Witnessing the elimination of magic wands}},
  volume = {17},
  year = {2015}
}

@article{blume:babel:2001,
  abstract = {We present a new foreign-function interface for SML/NJ. It is based on the idea of data-level interoperability-the ability of ML programs to inspect as well as manipulate C data structures directly. The core component of this work is an encoding of the almost2 complete C type system in ML types. The encoding makes extensive use of a "folklore" typing trick, taking advantage of ML's polymorphism, its type constructors, its abstraction mechanisms, and even functors. A small low-level component which deals with C struct and union declarations as well as program linkage is hidden from the programmer's eye by a simple program-generator tool that translates C declarations to corresponding ML glue code.},
  author = {Matthias Blume},
  doi = {https://doi.org/10.1016/S1571-0661(05)80452-9},
  issn = {1571-0661},
  journal = {Electronic Notes in Theoretical Computer Science},
  link = {https://www.sciencedirect.com/science/article/pii/S1571066105804529},
  note = {BABEL'01, First International Workshop on Multi-Language Infrastructure and Interoperability (Satellite Event of PLI 2001)},
  number = {1},
  pages = {36-52},
  title = {{No-longer-foreign: Teaching an ML compiler to speak C "natively"}},
  url = {https://www.sciencedirect.com/science/article/pii/S1571066105804529},
  volume = {59},
  year = {2001}
}

@inproceedings{bodin:popl:2014,
  acmid = {2535876},
  address = {New York, NY, USA},
  author = {Martin Bodin and Arthur Chargueraud and Daniele Filaretti and Philippa Gardner and Sergio Maffeis and Daiva Naudziuniene and Alan Schmitt and Gareth Smith},
  booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/2535838.2535876},
  isbn = {978-1-4503-2544-8},
  keywords = {coq, javascript, mechanised semantics},
  location = {San Diego, California, USA},
  numpages = {14},
  pages = {87-100},
  publisher = {ACM},
  series = {POPL '14},
  title = {{A trusted mechanised JavaScript specification}},
  year = {2014}
}

@inproceedings{boespflug:fdtc:2020,
  abstract = {Fault attacks consist in changing the program behavior by injecting faults at run-time, either at hardware or at software level. Their goal is to change the correct progress of the algorithm and hence, either to allow gaining some privilege access or to allow retrieving some secret information based on an analysis of the deviation of the corrupted behavior with respect to the original one. Countermeasures have been proposed to protect embedded systems by adding spatial, temporal or information redundancy at hardware or software level. First we define Countermeasures Check Point (CCP) and CCPs-based countermeasures as an important subclass of countermeasures. Then we propose a methodology to generate an optimal protection scheme for CCPs-based countermeasure. Finally we evaluate our work on a benchmark of code examples with respect to several Control Flow Integrity (CFI) oriented existing protection schemes.},
  author = {Etienne Boespflug and Cristian Ene and Laurent Mounier and Marie-Laure Potet},
  booktitle = {2020 Workshop on Fault Detection and Tolerance in Cryptography (FDTC)},
  doi = {10.1109/FDTC51366.2020.00011},
  issn = {},
  keywords = {},
  month = {Sep.},
  number = {},
  pages = {26-34},
  title = {{Countermeasures optimization in multiple fault-injection context}},
  volume = {},
  year = {2020}
}

@inproceedings{boettcher:date:2014,
  abstract = {SIMD extensions have gained widespread acceptance in modern microprocessors as a way to exploit data-level parallelism in general-purpose cores. Popular SIMD architectures (e.g., Intel SSE/AVX) have evolved by adding support for wider registers and datapaths, and advanced features like indexed memory accesses, per-lane predication and inter-lane instructions, at the cost of additional silicon area and design complexity.  This paper evaluates the performance impact of such advanced features on a set of workloads considered hard to vectorize for traditional SIMD architectures. Their sensitivity to the most relevant design parameters (e.g. register/datapath width and L1 data cache configuration) is quantified and discussed.  We developed an ARMv7 NEON based ISA extension (ARGON), augmented a cycle accurate simulation framework for it, and derived a set of benchmarks from the Berkeley dwarfs. Our analyses demonstrate how ARGON can, depending on the structure of an algorithm, achieve speedups of 1.5x to 16x.},
  acceptance = {22},
  affiliation = {ARM Ltd and University of Southampton},
  ar_shortname = {DATE 14},
  author = {Matthias Boettcher and Bashir M. Al-Hashimi and Mbou Eyole and Giacomo Gabrielli and Alastair D. Reid},
  booktitle = {Design, Automation \& Test in Europe Conference \& Exhibition (DATE 2014)},
  day = {24-28},
  doi = {10.7873/DATE.2014.037},
  editor = {Gerhard Fettweis and Wolfgang Nebel},
  location = {Dresden, Germany},
  month = {March},
  pages = {1-4},
  publisher = {European Design and Automation Association},
  title = {{Advanced SIMD: Extending the reach of contemporary SIMD architectures}},
  year = {2014}
}

@inproceedings{bohme2:fse:2020,
  author = {Marcel Böhme and Brandon Falk},
  booktitle = {Proceedings of the 2020 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  number = {},
  pages = {11},
  title = {{Fuzzing: On the exponential cost of vulnerability discovery}},
  volume = {},
  year = {2020}
}

@inproceedings{bohme:fse:2020,
  author = {Marcel Böhme and Valentin Manes and Sang Kil Cha},
  booktitle = {Proceedings of the 2020 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  number = {},
  pages = {11},
  title = {{Boosting fuzzer efficiency: An information theoretic perspective}},
  volume = {},
  year = {2020}
}

@inproceedings{boos:plos:2017,
  address = {New York, NY, USA},
  author = {Kevin Boos and Lin Zhong},
  booktitle = {Proceedings of the 9th Workshop on Programming Languages and Operating Systems},
  doi = {10.1145/3144555.3144560},
  isbn = {9781450351539},
  link = {https://doi.org/10.1145/3144555.3144560},
  location = {Shanghai, China},
  numpages = {7},
  pages = {29-35},
  publisher = {Association for Computing Machinery},
  series = {PLOS'17},
  title = {{Theseus: A state spill-free operating system}},
  url = {https://doi.org/10.1145/3144555.3144560},
  year = {2017}
}

@inproceedings{bornat:popl:2005,
  address = {New York, NY, USA},
  author = {Richard Bornat and Cristiano Calcagno and Peter W. O'Hearn and Matthew Parkinson},
  booktitle = {Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/1040305.1040327},
  isbn = {158113830X},
  keywords = {permissions, logic, concurrency, separation},
  location = {Long Beach, California, USA},
  numpages = {12},
  pages = {259-270},
  publisher = {Association for Computing Machinery},
  series = {POPL '05},
  title = {{Permission accounting in separation logic}},
  url = {https://doi.org/10.1145/1040305.1040327},
  year = {2005}
}

@article{bornholt:oopsla:2018,
  address = {New York, NY, USA},
  articleno = {Article 149},
  author = {James Bornholt and Emina Torlak},
  doi = {10.1145/3276519},
  issue_date = {October 2018},
  journal = {Proc. ACM Program. Lang.},
  keywords = {solver-aided programming, symbolic execution, profiling},
  link = {https://doi.org/10.1145/3276519},
  month = {October},
  number = {OOPSLA},
  numpages = {26},
  publisher = {Association for Computing Machinery},
  title = {{Finding code that explodes under symbolic evaluation}},
  url = {https://doi.org/10.1145/3276519},
  volume = {2},
  year = {2018}
}

@inproceedings{boulton:tpcd:1993,
  address = {Nijmegen, The Netherlands},
  author = {Richard Boulton and Andrew Gordon and Michael J. C. Gordon and John Harrison and John Herbert and John Van Tassel},
  booktitle = {Proceedings of the IFIP TC10/WG 10.2 International Conference on Theorem Provers in Circuit Design: Theory, Practice and Experience},
  date = {22--24 June 1993},
  link = {https://www.cl.cam.ac.uk/~jrh13/papers/EmbeddingPaper.html},
  pages = {129-156},
  publisher = {North-Holland},
  series = {IFIP Transactions A: Computer Science and Technology},
  title = {{Experience with embedding hardware description languages in HOL}},
  url = {https://www.cl.cam.ac.uk/~jrh13/papers/EmbeddingPaper.html},
  volume = {A-10},
  year = {1993}
}

@article{bowman:icfp:2015,
  address = {New York, NY, USA},
  author = {William J. Bowman and Amal Ahmed},
  doi = {10.1145/2858949.2784733},
  issn = {0362-1340},
  issue_date = {December 2015},
  journal = {SIGPLAN Not.},
  keywords = {dependency, polymorphism, information flow, parametricity, fully abstract compilation, security, Noninterference, logical relations, secure compilation},
  month = {August},
  number = {9},
  numpages = {13},
  pages = {101-113},
  publisher = {Association for Computing Machinery},
  title = {{Noninterference for free}},
  url = {https://doi.org/10.1145/2858949.2784733},
  volume = {50},
  year = {2015}
}

@inproceedings{braione:icse:2018,
  address = {New York, NY, USA},
  author = {Pietro Braione and Giovanni Denaro and Andrea Mattavelli and Mauro Pezzè},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
  doi = {10.1145/3183440.3183472},
  isbn = {9781450356633},
  keywords = {search-based software engineering, symbolic execution, automatic test case generation},
  link = {https://doi.org/10.1145/3183440.3183472},
  location = {Gothenburg, Sweden},
  numpages = {4},
  pages = {21-24},
  publisher = {Association for Computing Machinery},
  series = {ICSE '18},
  title = {{SUSHI: A test generator for programs with complex structured inputs}},
  url = {https://doi.org/10.1145/3183440.3183472},
  year = {2018}
}

@inproceedings{bridges:micro:2007,
  author = {Matthew Bridges and Neil Vachharajani and Yun Zhang and Thomas Jablin and David August},
  booktitle = {40th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2007)},
  doi = {10.1109/MICRO.2007.20},
  issn = {1072-4451},
  keywords = {feature extraction;multi-threading;program debugging;programming languages;software engineering;SPEC CINT2000 suite;automatic thread extraction;multicore model;parallel programming;program debugging;programmer training;programming languages;sequential programming model;single-threaded programming;software development;Computer languages;Costs;Debugging;Hardware;Law;Legal factors;Parallel programming;Programming profession;System recovery;Yarn},
  month = {December},
  number = {},
  pages = {69-84},
  title = {{Revisiting the sequential programming model for multi-core}},
  volume = {},
  year = {2007}
}

@article{brookes:tcs:2006,
  abstract = {We present a trace semantics for a language of parallel programs which share access to mutable data. We introduce a resource-sensitive logic for partial correctness, based on a recent proposal of O'Hearn, adapting separation logic to the concurrent setting. The logic allows proofs of parallel programs in which "ownership" of critical data, such as the right to access, update or deallocate a pointer, is transferred dynamically between concurrent processes. We prove soundness of the logic, using a novel "local" interpretation of traces which allows accurate reasoning about ownership. We show that every provable program is race-free.},
  author = {Stephen Brookes},
  doi = {10.1016/j.tcs.2006.12.034},
  issn = {0304-3975},
  journal = {Theoretical Computer Science},
  keywords = {Concurrency, Pointers, Race condition, Semantics, Logic},
  note = {Festschrift for John C. Reynolds's 70th birthday},
  number = {1},
  pages = {227 - 270},
  title = {{A semantics for concurrent separation logic}},
  url = {http://www.sciencedirect.com/science/article/pii/S0304397506009248},
  volume = {375},
  year = {2007}
}

@inproceedings{brown:asplos:2016,
  abstract = {Modern static bug finding tools are complex. They typically consist of hundreds of thousands of lines of code, and most of them are wedded to one language (or even one compiler). This complexity makes the systems hard to understand, hard to debug, and hard to retarget to new languages, thereby dramatically limiting their scope. This paper reduces checking system complexity by addressing a fundamental assumption, the assumption that checkers must depend on a full-blown language specification and compiler front end. Instead, our program checkers are based on drastically incomplete language grammars ("micro-grammars") that describe only portions of a language relevant to a checker. As a result, our implementation is tiny-roughly 2500 lines of code, about two orders of magnitude smaller than a typical system. We hope that this dramatic increase in simplicity will allow people to use more checkers on more systems in more languages.We implement our approach in \mu chex, a language-agnostic framework for writing static bug checkers. We use it to build micro-grammar based checkers for six languages (C, the C preprocessor, C++, Java, JavaScript, and Dart) and find over 700 errors in real-world projects.},
  address = {New York, NY, USA},
  author = {Fraser Brown and Andres Nötzli and Dawson Engler},
  booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/2872362.2872364},
  isbn = {9781450340915},
  keywords = {bug finding, micro-grammars, parsing, static analysis},
  link = {https://doi.org/10.1145/2872362.2872364},
  location = {Atlanta, Georgia, USA},
  numpages = {15},
  pages = {143-157},
  publisher = {Association for Computing Machinery},
  series = {ASPLOS '16},
  title = {{How to build static checking systems using orders of magnitude less code}},
  url = {https://doi.org/10.1145/2872362.2872364},
  year = {2016}
}

@inproceedings{brown:sec:2020,
  author = {Fraser Brown and Deian Stefan and Dawson Engler},
  booktitle = {29th USENIX Security Symposium (USENIX Security 20)},
  isbn = {978-1-939133-17-5},
  link = {https://www.usenix.org/conference/usenixsecurity20/presentation/brown},
  month = {August},
  pages = {199-216},
  publisher = {USENIX Association},
  title = {{Sys: A static/symbolic tool for finding good bugs in good (browser) code}},
  url = {https://www.usenix.org/conference/usenixsecurity20/presentation/brown},
  year = {2020}
}

@article{bruel:compsurv:2021,
  abstract = {A major determinant of the quality of software systems is the quality of their requirements, which should be both understandable and precise. Most requirements are written in natural language, which is good for understandability but lacks precision.To make requirements precise, researchers have for years advocated the use of mathematics-based notations and methods, known as "formal." Many exist, differing in their style, scope, and applicability. The present survey discusses some of the main formal approaches and compares them to informal methods.The analysis uses a set of nine complementary criteria, such as level of abstraction, tool availability, and traceability support. It classifies the approaches into five categories based on their principal style for specifying requirements: natural-language, semi-formal, automata/graphs, mathematical, and seamless (programming-language-based). It includes examples from all of these categories, altogether 21 different approaches, including for example SysML, Relax, Eiffel, Event-B, and Alloy.The review discusses a number of open questions, including seamlessness, the role of tools and education, and how to make industrial applications benefit more from the contributions of formal approaches.},
  address = {New York, NY, USA},
  articleno = {93},
  author = {Jean-Michel Bruel and Sophie Ebersold and Florian Galinier and Manuel Mazzara and Alexandr Naumchev and Bertrand Meyer},
  doi = {10.1145/3448975},
  issn = {0360-0300},
  issue_date = {June 2021},
  journal = {ACM Comput. Surv.},
  keywords = {requirement, Formal, software, seamless, specification},
  link = {https://doi.org/10.1145/3448975},
  month = {May},
  number = {5},
  numpages = {36},
  publisher = {Association for Computing Machinery},
  title = {{The role of formalism in system requirements}},
  url = {https://doi.org/10.1145/3448975},
  volume = {54},
  year = {2021}
}

@inproceedings{brummayer:sat:2010,
  abstract = {Robustness and correctness are essential criteria for SAT and QBF solvers. We develop automated testing and debugging techniques designed and optimized for SAT and QBF solver development. Our fuzz testing techniques are able to find critical solver defects that lead to crashes, invalid satisfying assignments and incorrect satisfiability results. Moreover, we show that sequential and concurrent delta debugging techniques are highly effective in minimizing failure-inducing inputs.},
  address = {Berlin, Heidelberg},
  author = {Robert Brummayer and Florian Lonsing and Armin Biere},
  booktitle = {Theory and Applications of Satisfiability Testing - SAT 2010},
  doi = {10.1007/978-3-642-14186-7_6},
  editor = {Strichman, Ofer and Szeider, Stefan},
  isbn = {978-3-642-14186-7},
  pages = {44-57},
  publisher = {Springer Berlin Heidelberg},
  title = {{Automated testing and debugging of SAT and QBF solvers}},
  year = {2010}
}

@inproceedings{burch:cav:1994,
  acmid = {735662},
  address = {London, UK},
  author = {Jerry R. Burch and David L. Dill},
  booktitle = {Proceedings of the 6th International Conference on Computer Aided Verification},
  doi = {10.1007/3-540-58179-0_44},
  isbn = {3-540-58179-0},
  numpages = {13},
  pages = {68-80},
  publisher = {Springer-Verlag},
  series = {CAV '94},
  title = {{Automatic verification of pipelined microprocessor control}},
  year = {1994}
}

@inproceedings{burke:lacl:2005,
  author = {David A. Burke and Kristofer Johannisson},
  booktitle = {Logical Aspects of Computational Linguistics (LACL 2005)},
  doi = {10.1007/11422532_4},
  editor = {P. Blace, E. Stabler, J. Busquets and R. Moot},
  pages = {51-66},
  publisher = {Springer},
  series = {LNAI},
  title = {{Translating formal software specifications to natural language / A grammar-based approach}},
  volume = {3402},
  year = {2005}
}

@article{burton:toplas:1990,
  abstract = {A record data type can be extended by addition of more fields. The extended type is a subtype of the original, in that any value of the extended type can be regarded as a value of the original type by ignoring the additional fields. This results in a type hierarchy.Milner [3] has proposed a polymorphic type system. With the Milner approach, the type of a function may contain type variables. This also results in a type hierarchy.In a language with a polymorphic type system, if it is anticipated that a record type will need to be extended, then the record type can be defined to have a dummy extension field. In the parent type, the extension field will have null contents of type void. The type of the extension field can differ with different subtypes.The approach can be extended to allow a type to be subtype of two or more parent types.To a limited extent, this approach can be used in Ada and other languages with generic program units.},
  address = {New York, NY, USA},
  author = {F. Warren Burton},
  doi = {10.1145/77606.214515},
  issn = {0164-0925},
  issue_date = {Jan. 1990},
  journal = {ACM Trans. Program. Lang. Syst.},
  link = {https://doi.org/10.1145/77606.214515},
  month = {January},
  number = {1},
  numpages = {4},
  pages = {135-138},
  publisher = {Association for Computing Machinery},
  title = {{Type extension through polymorphism}},
  url = {https://doi.org/10.1145/77606.214515},
  volume = {12},
  year = {1990}
}

@article{bush:atlantic:1945,
  author = {Vannevar Bush},
  journal = {Atlantic Monthly},
  pages = {101-108},
  title = {{As we may think}},
  url = {https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/},
  volume = {176},
  year = {1945}
}

@article{bush:spe:2000,
  address = {USA},
  author = {William R. Bush and Jonathan D. Pincus and David J. Sielaff},
  doi = {10.1002/(SICI)1097-024X(200006)30:7<775::AID-SPE309>3.0.CO;2-H},
  issn = {0038-0644},
  issue_date = {June 2000},
  journal = {Software Practice and Experience},
  keywords = {program error checking, program analysis},
  link = {https://doi.org/10.1002/(SICI)1097-024X(200006)30:7\%3C775::AID-SPE309\%3E3.0.CO;2-H},
  month = {June},
  number = {7},
  numpages = {28},
  pages = {775-802},
  publisher = {John Wiley & Sons, Inc.},
  title = {{A static analyzer for finding dynamic programming errors}},
  url = {https://doi.org/10.1002/(SICI)1097-024X(200006)30:7\%3C775::AID-SPE309\%3E3.0.CO;2-H},
  volume = {30},
  year = {2000}
}

@inproceedings{busse:issta:2020,
  abstract = {When symbolic execution is used to analyse real-world applications, it often consumes all available memory in a relatively short amount of time, sometimes making it impossible to analyse an application for an extended period. In this paper, we present a technique that can record an ongoing symbolic execution analysis to disk and selectively restore paths of interest later, making it possible to run symbolic execution indefinitely. To be successful, our approach addresses several essential research challenges related to detecting divergences on re-execution, storing long-running executions efficiently, changing search heuristics during re-execution, and providing a global view of the stored execution. Our extensive evaluation of 93 Linux applications shows that our approach is practical, enabling these applications to run for days while continuing to explore new execution paths.},
  address = {New York, NY, USA},
  author = {Frank Busse and Martin Nowack and Cristian Cadar},
  booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  doi = {10.1145/3395363.3397360},
  isbn = {9781450380089},
  keywords = {memoization, KLEE, symbolic execution},
  link = {https://doi.org/10.1145/3395363.3397360},
  location = {Virtual Event, USA},
  numpages = {12},
  pages = {63-74},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2020},
  title = {{Running symbolic execution forever}},
  url = {https://doi.org/10.1145/3395363.3397360},
  year = {2020}
}

@article{cadar:cacm:2013,
  address = {New York, NY, USA},
  author = {Cristian Cadar and Koushik Sen},
  doi = {10.1145/2408776.2408795},
  issn = {0001-0782},
  issue_date = {February 2013},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/2408776.2408795},
  month = {February},
  number = {2},
  numpages = {9},
  pages = {82-90},
  publisher = {Association for Computing Machinery},
  title = {{Symbolic execution for software testing: Three decades later}},
  url = {https://doi.org/10.1145/2408776.2408795},
  volume = {56},
  year = {2013}
}

@inproceedings{cadar:fse:2015,
  abstract = {Semantics-preserving program transformations, such as refactorings and optimisations, can have a significant impact on the effectiveness of symbolic execution testing and analysis. Furthermore, semantics-preserving transformations that increase the performance of native execution can in fact decrease the scalability of symbolic execution. Similarly, semantics-altering transformations, such as type changes and object size modifications, can often lead to substantial improvements in the testing effectiveness achieved by symbolic execution in the original program. As a result, we argue that one should treat program transformations as first-class ingredients of scalable symbolic execution, alongside widely-accepted aspects such as search heuristics and constraint solving optimisations. First, we propose to understand the impact of existing program transformations on symbolic execution, to increase scalability and improve experimental design and reproducibility. Second, we argue for the design of testability transformations specifically targeted toward more scalable symbolic execution.},
  address = {New York, NY, USA},
  author = {Cristian Cadar},
  booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
  doi = {10.1145/2786805.2803205},
  isbn = {9781450336758},
  keywords = {dynamic symbolic execution, Testability transformations},
  link = {https://doi.org/10.1145/2786805.2803205},
  location = {Bergamo, Italy},
  numpages = {4},
  pages = {906-909},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2015},
  title = {{Targeted program transformations for symbolic execution}},
  url = {https://doi.org/10.1145/2786805.2803205},
  year = {2015}
}

@inproceedings{cadar:osdi:2008,
  acmid = {1855756},
  address = {Berkeley, CA, USA},
  author = {Cristian Cadar and Daniel Dunbar and Dawson Engler},
  booktitle = {Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation},
  location = {San Diego, California},
  numpages = {16},
  pages = {209-224},
  publisher = {USENIX Association},
  series = {OSDI'08},
  title = {{KLEE: Unassisted and automatic generation of high-coverage tests for complex systems programs}},
  year = {2008}
}

@article{cadar:tiss:2008,
  abstract = {This article presents EXE, an effective bug-finding tool that automatically generates inputs that crash real code. Instead of running code on manually or randomly constructed input, EXE runs it on symbolic input initially allowed to be anything. As checked code runs, EXE tracks the constraints on each symbolic (i.e., input-derived) memory location. If a statement uses a symbolic value, EXE does not run it, but instead adds it as an input-constraint; all other statements run as usual. If code conditionally checks a symbolic expression, EXE forks execution, constraining the expression to be true on the true branch and false on the other. Because EXE reasons about all possible values on a path, it has much more power than a traditional runtime tool: (1) it can force execution down any feasible program path and (2) at dangerous operations (e.g., a pointer dereference), it detects if the current path constraints allow any value that causes a bug. When a path terminates or hits a bug, EXE automatically generates a test case by solving the current path constraints to find concrete values using its own co-designed constraint solver, STP. Because EXE's constraints have no approximations, feeding this concrete input to an uninstrumented version of the checked code will cause it to follow the same path and hit the same bug (assuming deterministic code).EXE works well on real code, finding bugs along with inputs that trigger them in: the BSD and Linux packet filter implementations, the dhcpd DHCP server, the pcre regular expression library, and three Linux file systems.},
  address = {New York, NY, USA},
  articleno = {10},
  author = {Cristian Cadar and Vijay Ganesh and Peter M. Pawlowski and David L. Dill and Dawson R. Engler},
  doi = {10.1145/1455518.1455522},
  issn = {1094-9224},
  issue_date = {December 2008},
  journal = {ACM Trans. Inf. Syst. Secur.},
  keywords = {constraint solving, symbolic execution, attack generation, dynamic analysis, test case generation, bug finding},
  link = {https://doi.org/10.1145/1455518.1455522},
  month = {December},
  number = {2},
  numpages = {38},
  publisher = {Association for Computing Machinery},
  title = {{EXE: Automatically Generating Inputs of Death}},
  url = {https://doi.org/10.1145/1455518.1455522},
  volume = {12},
  year = {2008}
}

@inproceedings{calcagno:popl:2009,
  address = {New York, NY, USA},
  author = {Cristiano Calcagno and Dino Distefano and Peter W. O'Hearn and Hongseok Yang},
  booktitle = {Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/1480881.1480917},
  isbn = {9781605583792},
  keywords = {proof theory, abduction, program analysis},
  location = {Savannah, GA, USA},
  numpages = {12},
  pages = {289-300},
  publisher = {Association for Computing Machinery},
  series = {POPL '09},
  title = {{Compositional shape analysis by means of bi-abduction}},
  url = {https://doi.org/10.1145/1480881.1480917},
  year = {2009}
}

@inproceedings{calcagno:sas:2006,
  abstract = {Previous shape analysis algorithms use a memory model where the heap is composed of discrete nodes that can be accessed only via access paths built from variables and field names, an assumption that is violated by pointer arithmetic. In this paper we show how this assumption can be removed, and pointer arithmetic embraced, by using an analysis based on separation logic. We describe an abstract domain whose elements are certain separation logic formulae, and an abstraction mechanism that automatically transits between a low-level RAM view of memory and a higher, fictional, view that abstracts from the representation of nodes and multiword linked-lists as certain configurations of the RAM. A widening operator is used to accelerate the analysis. We report experimental results obtained from running our analysis on a number of classic algorithms for dynamic memory management.},
  address = {Berlin, Heidelberg},
  author = {Cristiano Calcagno and Dino Distefano and Peter W. O'Hearn and Hongseok Yang},
  booktitle = {Static Analysis},
  editor = {Yi, Kwangkeun},
  isbn = {978-3-540-37758-0},
  pages = {182-203},
  publisher = {Springer Berlin Heidelberg},
  title = {{Beyond reachability: Shape abstraction in the presence of pointer arithmetic}},
  year = {2006}
}

@phdthesis{cattell:phd:1978,
  address = {Pittsburgh, PA, USA},
  author = {Roderic Geoffrey Galton Cattell},
  link = {https://pdfs.semanticscholar.org/5caa/48dc2c51e19bc3c8983e27419f69e1098e9c.pdf},
  note = {AAI7815197},
  school = {Carnegie Mellon University},
  title = {{Formalization and automatic derivation of code generators}},
  url = {https://pdfs.semanticscholar.org/5caa/48dc2c51e19bc3c8983e27419f69e1098e9c.pdf},
  year = {1978}
}

@article{cattell:toplas:1980,
  acmid = {357097},
  address = {New York, NY, USA},
  author = {Roderic Geoffrey Galton Cattell},
  doi = {10.1145/357094.357097},
  issn = {0164-0925},
  issue_date = {April 1980},
  journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
  month = {April},
  number = {2},
  numpages = {18},
  pages = {173-190},
  publisher = {ACM},
  title = {{Automatic derivation of code generators from machine descriptions}},
  volume = {2},
  year = {1980}
}

@inproceedings{cha:sandp:2012,
  abstract = {In this paper we present Mayhem, a new system for automatically finding exploitable bugs in binary (i.e., executable) programs. Every bug reported by Mayhem is accompanied by a working shell-spawning exploit. The working exploits ensure soundness and that each bug report is security-critical and actionable. Mayhem works on raw binary code without debugging information. To make exploit generation possible at the binary-level, Mayhem addresses two major technical challenges: actively managing execution paths without exhausting memory, and reasoning about symbolic memory indices, where a load or a store address depends on user input. To this end, we propose two novel techniques: 1) hybrid symbolic execution for combining online and offline (concolic) execution to maximize the benefits of both techniques, and 2) index-based memory modeling, a technique that allows Mayhem to efficiently reason about symbolic memory at the binary level. We used Mayhem to find and demonstrate 29 exploitable vulnerabilities in both Linux and Windows programs, 2 of which were previously undocumented.},
  author = {Sang Kil Cha and Thanassis Avgerinos and Alexandre Rebert and David Brumley},
  booktitle = {2012 IEEE Symposium on Security and Privacy},
  doi = {10.1109/SP.2012.31},
  issn = {2375-1207},
  keywords = {binary codes;program debugging;Mayhem;binary programs;executable programs;working shell-spawning exploit;bug report;raw binary code;exploit generation;binary-level;active managing execution paths;symbolic memory indices;hybrid symbolic execution;online execution;offline execution;concolic execution;Linux programs;Windows programs;Concrete;Computer bugs;Engines;Servers;Binary codes;Switches;Memory management;hybrid execution;symbolic memory;index-based memory modeling;exploit generation},
  month = {May},
  number = {},
  pages = {380-394},
  title = {{Unleashing Mayhem on binary code}},
  volume = {},
  year = {2012}
}

@article{chakravarty:haskffi:2003,
  ar_shortname = {Haskell FFI},
  author = {Manuel Chakravarty and Sigbjorn Finne and Fergus Henderson and Marcin Kowalczyk and Daan Leijen and Simon Marlow and Erik Meijer and Sven Panne and Simon L. Peyton Jones and Alastair D. Reid and Malcolm Wallace and Michael Weber},
  link = {https://www.cse.unsw.edu.au/~chak/haskell/ffi},
  title = {{The Haskell 98 foreign function interface 1.0: An addendum to the Haskell 98 report}},
  url = {https://www.cse.unsw.edu.au/~chak/haskell/ffi},
  year = {2003}
}

@inproceedings{chalupa:tacas:2021,
  abstract = {Symbiotic  8 extends the traditional combination of static analyses, instrumentation, program slicing, and symbolic execution with one substantial novelty, namely a technique mixing symbolic execution with k-induction. This technique can prove the correctness of programs with possibly unbounded loops, which cannot be done by classic symbolic execution. Symbiotic  8 delivers also several other improvements. In particular, we have modified our fork of the symbolic executor Klee to support the comparison of symbolic pointers. Further, we have tuned the shape analysis tool Predator (integrated already in Symbiotic  7) to perform better on llvm bitcode. We have also developed a light-weight analysis of relations between variables that can prove the absence of out-of-bound accesses to arrays.},
  address = {Cham},
  author = {Marek Chalupa and Tomáš Jašek and Jakub Novák and Anna Řechtáčková and Veronika Šoková and Jan Strejček},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  editor = {Groote, Jan Friso and Larsen, Kim Guldstrand},
  isbn = {978-3-030-72013-1},
  pages = {453-457},
  publisher = {Springer International Publishing},
  title = {{Symbiotic 8: Beyond symbolic execution}},
  year = {2021}
}

@article{chang:tocs:2012,
  address = {New York, NY, USA},
  articleno = {4},
  author = {Fay Chang and Jeffrey Dean and Sanjay Ghemawat and Wilson C. Hsieh and Deborah A. Wallach and Mike Burrows and Tushar Chandra and Andrew Fikes and Robert E. Gruber},
  doi = {10.1145/1365815.1365816},
  issn = {0734-2071},
  issue_date = {June 2008},
  journal = {ACM Trans. Comput. Syst.},
  keywords = {Large-Scale Distributed Storage},
  link = {https://doi.org/10.1145/1365815.1365816},
  month = {June},
  number = {2},
  numpages = {26},
  publisher = {Association for Computing Machinery},
  title = {{Bigtable: A distributed storage system for structured data}},
  url = {https://doi.org/10.1145/1365815.1365816},
  volume = {26},
  year = {2008}
}

@inproceedings{chatterjee:tacas:2007,
  abstract = {Reasoning about heap-allocated data structures such as linked lists and arrays is challenging. The reachability predicate has proved to be useful for reasoning about the heap in type-safe languages where memory is manipulated by dereferencing object fields. Sound and precise analysis for such data structures becomes significantly more challenging in the presence of low-level pointer manipulation that is prevalent in systems software.},
  address = {Berlin, Heidelberg},
  author = {Shaunak Chatterjee and Shuvendu K. Lahiri and Shaz Qadeer and Zvonimir Rakamarić},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  doi = {10.1007/978-3-540-71209-1_4},
  editor = {Grumberg, Orna and Huth, Michael},
  isbn = {978-3-540-71209-1},
  pages = {19-33},
  publisher = {Springer Berlin Heidelberg},
  title = {{A reachability predicate for analyzing low-level software}},
  year = {2007}
}

@misc{chen:arxiv:2021,
  archiveprefix = {arXiv},
  author = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde and Jared Kaplan and Harri Edwards and Yura Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and Will Guss and Alex Nichol and Igor Babuschkin and Suchir Balaji and Shantanu Jain and Andrew Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  eprint = {2107.03374},
  primaryclass = {cs.LG},
  title = {{Evaluating large language models trained on code}},
  year = {2021}
}

@inproceedings{chen:iiswc:2019,
  author = {Yishen Chen and Ajay Brahmakshatriya and Charith Mendis and Alex Renda and Eric Atkinson and Ondřej Sýkora and Saman P. Amarasinghe and Michael Carbin},
  booktitle = {2019 IEEE International Symposium on Workload Characterization (IISWC)},
  doi = {10.1109/IISWC47752.2019.9042166},
  number = {},
  pages = {167-177},
  title = {{BHive: A benchmark suite and measurement framework for validating x86-64 basic block performance models}},
  volume = {},
  year = {2019}
}

@inproceedings{chen:sp:2020,
  author = {Yaohui Chen and Peng Li and Jun Xu and Shengjian Guo and Rundong Zhou and Yulong Zhang and Tao Wei and Long Lu},
  booktitle = {2020 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP40000.2020.00002},
  number = {},
  pages = {1580-1596},
  title = {{SAVIOR: Towards bug-driven hybrid testing}},
  volume = {},
  year = {2020}
}

@inproceedings{chipounov:asplos:2011,
  address = {New York, NY, USA},
  author = {Vitaly Chipounov and Volodymyr Kuznetsov and George Candea},
  booktitle = {Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/1950365.1950396},
  isbn = {9781450302661},
  keywords = {in-vivo, symbolic execution, testing, dbt, analysis, binary, performance, framework, virtualization, consistency models},
  link = {https://doi.org/10.1145/1950365.1950396},
  location = {Newport Beach, California, USA},
  numpages = {14},
  pages = {265-278},
  publisher = {Association for Computing Machinery},
  series = {ASPLOS XVI},
  title = {{S2E: A platform for in-vivo multi-path analysis of software systems}},
  url = {https://doi.org/10.1145/1950365.1950396},
  year = {2011}
}

@article{chipounov:hotdep:2009,
  abstract = {Symbolic execution is a powerful technique for analyzing  program behavior, finding bugs, and generating tests, but  suffers from severely limited scalability: the largest  programs that can be symbolically executed today are on the  order of thousands of lines of code. To ensure feasibility  of symbolic execution, even small programs must curtail  their interactions with libraries, the operating system,  and hardware devices. This paper introduces selective  symbolic execution, a technique for creating the illusion  of full-system symbolic execution, while symbolically  running only the code that is of interest to the developer.  We describe a prototype that can symbolically execute  arbitrary portions of a full system, including  applications, libraries, operating system, and device  drivers. It seamlessly transitions back and forth between  symbolic and concrete execution, while transparently  converting system state from symbolic to concrete and back.  Our technique makes symbolic execution practical for large  software that runs in real environments, without requiring  explicit modeling of these environments.},
  author = {Vitaly Chipounov and Vlad Georgescu and Cristian Zamfir and George Candea},
  journal = {Proceedings of the 5th Workshop on Hot Topics in System Dependability (HotDep)},
  link = {http://infoscience.epfl.ch/record/139393},
  title = {{Selective symbolic execution}},
  url = {http://infoscience.epfl.ch/record/139393},
  year = {2009}
}

@article{chipounov:tcs:2012,
  address = {New York, NY, USA},
  articleno = {2},
  author = {Vitaly Chipounov and Volodymyr Kuznetsov and George Candea},
  doi = {10.1145/2110356.2110358},
  issn = {0734-2071},
  issue_date = {February 2012},
  journal = {ACM Transactions on Computer Systems},
  keywords = {analysis, profiling, testing, Symbolic execution},
  link = {https://doi.org/10.1145/2110356.2110358},
  month = {February},
  number = {1},
  numpages = {49},
  publisher = {Association for Computing Machinery},
  title = {{The S2E platform: Design, implementation, and applications}},
  url = {https://doi.org/10.1145/2110356.2110358},
  volume = {30},
  year = {2012}
}

@article{choi:icfp:2017,
  author = {Joonwon Choi and Muralidaran Vijayaraghavan and Benjamin Sherman and Adam J. Chlipala and Arvind},
  doi = {10.1145/3110268},
  journal = {Proceedings of the ACM on Programming Languages},
  number = {ICFP},
  pages = {24},
  publisher = {ACM},
  title = {{Kami: A platform for high-level parametric hardware specification and its modular verification}},
  volume = {1},
  year = {2017}
}

@inproceedings{chong:asplos:2008,
  author = {Nathan Chong and Samin Ishtiaq},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/asplos/ChongI08},
  booktitle = {Proceedings of the 2008 ACM SIGPLAN workshop on Memory Systems Performance and Correctness: held in conjunction with the Thirteenth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS '08), Seattle, Washington, USA, March 2, 2008},
  doi = {10.1145/1353522.1353528},
  pages = {16-19},
  timestamp = {Tue, 08 Apr 2008 14:40:59 +0200},
  title = {{Reasoning about the ARM weakly consistent memory model}},
  year = {2008}
}

@inproceedings{chong:icse:2020,
  author = {Nathan Chong and Byron Cook and Konstantinos Kallas and Kareem Khazem and Felipe R. Monteiro and Daniel Schwartz-Narbonne and Serdar Tasiran and Michael Tautschnig and Mark R. Tuttle},
  booktitle = {Proceedings of the 2020 International Conference on Software Engineering (ICSE)},
  doi = {10.1145/3377813.3381347},
  month = {June},
  title = {{Code-level model checking in the software development workflow}},
  year = {2020}
}

@inproceedings{chou:bugs:2005,
  author = {Andy Chou},
  booktitle = {Proceedings of BUGS 2005 (PLDI 2005 Workshop on the Evaluation of Software Defect Detection Tools)},
  location = {Chicago, IL, USA},
  month = {June},
  title = {{False positives over time: A problem in deploying static analysis tools}},
  url = {http://www.cs.umd.edu/~pugh/SoftwareDefectWorkshop05/BugWorkshop05.pdf},
  year = {2005}
}

@article{chu:ieeedtc:1992,
  author = {Yaohan Chu and Donald L. Dietmeyer and James R. Duley and Fredrick J. Hill and Mario R. Barbacci and Charles W. Rose and Greg Ordy and Bill Johnson and Martin Roberts},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/dt/ChuDDHBROJR92.bib},
  doi = {10.1109/54.143147},
  journal = {IEEE Des. Test Comput.},
  link = {https://doi.org/10.1109/54.143147},
  number = {2},
  pages = {69-81},
  timestamp = {Sun, 17 May 2020 01:00:00 +0200},
  title = {{Three decades of HDLs: Part I, CDL through TI-HDL}},
  url = {https://doi.org/10.1109/54.143147},
  volume = {9},
  year = {1992}
}

@article{cifuentes:computer:2000,
  author = {Cristina Cifuentes and M. Van Emmerik},
  doi = {10.1109/2.825697},
  issn = {1558-0814},
  journal = {Computer},
  keywords = {program interpreters;computer architecture;adaptable binary translation;software migration;University of Queensland Binary Translator;machine specifications;operating systems;static binary-translation framework;complex-instruction-set computers;reduced-instruction-set computers;stack-based machines;translators;Sun Sparc;Intel Pentium;Java virtual machine architectures;Costs;Electronics industry;Portable computers;Home appliances;System-on-a-chip;Operating systems;Reduced instruction set computing;Sun;Java;Computer architecture},
  month = {March},
  number = {3},
  pages = {60-66},
  title = {{UQBT: Adaptable binary translation at low cost}},
  volume = {33},
  year = {2000}
}

@inproceedings{cifuentes:iwpc:1998,
  author = {Cristina Cifuentes and Shane Sendall},
  booktitle = {Program Comprehension, 1998. IWPC '98. Proceedings., 6th International Workshop on},
  doi = {10.1109/WPC.1998.693332},
  issn = {1092-8138},
  keywords = {instruction sets;software portability;specification languages;systems re-engineering;Instruction Set Processor descriptions;binary debuggers;binary profilers;instruction set;instrumentors;intermediate representation;machine instructions semantics;machine-code manipulation tools;machine-independent issues;optimizing compilers;retargetable binary translation framework;retargetable binary translator;semantic specification language;Australia Council;Binary codes;Computer science;Instruments;Operating systems;Process design;Programming profession;Read only memory;Runtime;Specification languages},
  month = {Jun},
  pages = {126-133},
  title = {{Specifying the semantics of machine instructions}},
  year = {1998}
}

@inproceedings{claessen:icfp:2000,
  address = {New York, NY, USA},
  author = {Koen Claessen and John Hughes},
  booktitle = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/351240.351266},
  isbn = {1581132026},
  link = {https://doi.org/10.1145/351240.351266},
  numpages = {12},
  pages = {268-279},
  publisher = {Association for Computing Machinery},
  series = {ICFP '00},
  title = {{QuickCheck: A lightweight tool for random testing of Haskell programs}},
  url = {https://doi.org/10.1145/351240.351266},
  year = {2000}
}

@inproceedings{claessen:sfm:2006,
  author = {Koen Claessen and Jan-Willem Roorda},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/sfm/ClaessenR06.bib},
  booktitle = {Formal Methods for Hardware Verification, 6th International School on Formal Methods for the Design of Computer, Communication, and Software Systems, SFM 2006, Bertinoro, Italy, May 22-27, 2006, Advanced Lectures},
  doi = {10.1007/11757283_3},
  editor = {Marco Bernardo and Alessandro Cimatti},
  link = {https://doi.org/10.1007/11757283_3},
  pages = {56-77},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  timestamp = {Tue, 14 May 2019 10:00:44 +0200},
  title = {{An introduction to symbolic trajectory evaluation}},
  url = {https://doi.org/10.1007/11757283_3},
  volume = {3965},
  year = {2006}
}

@article{clark:entcs:2002,
  abstract = {Basic information theory is used to analyse the amount of confidential information which may be leaked by programs written in a very simple imperative language. In particular, a detailed analysis is given of the possible leakage due to equality tests and if statements. The analysis is presented as a set of syntax-directed inference rules and can readily be automated.},
  author = {David Clark and Sebastian Hunt and Pasquale Malacaria},
  doi = {10.1016/S1571-0661(04)00290-7},
  issn = {1571-0661},
  journal = {Electronic Notes in Theoretical Computer Science},
  note = {QAPL'01, Quantitative Aspects of Programming Laguages (Satellite Event of PLI 2001)},
  number = {3},
  pages = {238 - 251},
  title = {{Quantitative analysis of the leakage of confidential data}},
  volume = {59},
  year = {2002}
}

@article{clarke:cacm:2009,
  address = {New York, NY, USA},
  author = {Edmund M. Clarke and E. Allen Emerson and Joseph Sifakis},
  doi = {10.1145/1592761.1592781},
  issn = {0001-0782},
  issue_date = {November 2009},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/1592761.1592781},
  month = {November},
  number = {11},
  numpages = {11},
  pages = {74-84},
  publisher = {Association for Computing Machinery},
  title = {{Model checking: Algorithmic verification and debugging}},
  url = {https://doi.org/10.1145/1592761.1592781},
  volume = {52},
  year = {2009}
}

@inproceedings{clarke:cav:2000,
  abstract = {We present an automatic iterative abstraction-refinement methodology in which the initial abstract model is generated by an automatic analysis of the control structures in the program to be verified. Abstract models may admit erroneous (or ``spurious'') counterexamples. We devise new symbolic techniques which analyze such counterexamples and refine the abstract model correspondingly. The refinement algorithm keeps the size of the abstract state space small due to the use of abstraction functions which distinguish many degrees of abstraction for each program variable. We describe an implementation of our methodology in NuSMV. Practical experiments including a large Fujitsu IP core design with about 500 latches and 10000 lines of SMV code confirm the effectiveness of our approach.},
  address = {Berlin, Heidelberg},
  author = {Edmund M. Clarke and Orna Grumberg and Somesh Jha and Yuan Lu and Helmut Veith},
  booktitle = {Computer Aided Verification},
  doi = {10.1007/10722167_15},
  editor = {Emerson, E. Allen and Sistla, Aravinda Prasad},
  isbn = {978-3-540-45047-4},
  pages = {154-169},
  publisher = {Springer Berlin Heidelberg},
  title = {{Counterexample-guided abstraction refinement}},
  year = {2000}
}

@inproceedings{clarke:oopsla:1998,
  abstract = {Object-oriented programming languages allow inter-object aliasing. Although necessary to construct linked data structures and networks of interacting objects, aliasing is problematic in that an aggregate object's state can change via an alias to one of its components, without the aggregate being aware of any aliasing.Ownership types form a static type system that indicates object ownership. This provides a flexible mechanism to limit the visibility of object references and restrict access paths to objects, thus controlling a system's dynamic topology. The type system is shown to be sound, and the specific aliasing properties that a system's object graph satisfies are formulated and proven invariant for well-typed programs.},
  address = {New York, NY, USA},
  author = {David G. Clarke and John M. Potter and James Noble},
  booktitle = {Proceedings of the 13th ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
  doi = {10.1145/286936.286947},
  isbn = {1581130058},
  keywords = {containment, ownership, programming language design, representation exposure, sharing, alias protection},
  link = {https://doi.org/10.1145/286936.286947},
  location = {Vancouver, British Columbia, Canada},
  numpages = {17},
  pages = {48-64},
  publisher = {Association for Computing Machinery},
  series = {OOPSLA '98},
  title = {{Ownership types for flexible alias protection}},
  url = {https://doi.org/10.1145/286936.286947},
  year = {1998}
}

@inproceedings{clarke:tacas:2004,
  abstract = {We present a tool for the formal verification of ANSI-C programs using Bounded Model Checking (BMC). The emphasis is on usability: the tool supports almost all ANSI-C language features, including pointer constructs, dynamic memory allocation, recursion, and the float and double data types. From the perspective of the user, the verification is highly automated: the only input required is the BMC bound. The tool is integrated into a graphical user interface. This is essential for presenting long counterexample traces: the tool allows stepping through the trace in the same way a debugger allows stepping through a program.},
  address = {Berlin, Heidelberg},
  author = {Edmund M. Clarke and Daniel Kroening and Flavio Lerda},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  doi = {10.1007/978-3-540-24730-2_15},
  editor = {Jensen, Kurt and Podelski, Andreas},
  isbn = {978-3-540-24730-2},
  pages = {168-176},
  publisher = {Springer Berlin Heidelberg},
  title = {{A tool for checking ANSI-C programs}},
  year = {2004}
}

@inproceedings{clarke:wlop:1982,
  acmid = {747438},
  address = {London, UK, UK},
  author = {Edmund M. Clarke and E. Allen Emerson},
  booktitle = {Logic of Programs, Workshop},
  doi = {10.1007/BFb0025774},
  isbn = {3-540-11212-X},
  numpages = {20},
  pages = {52-71},
  publisher = {Springer-Verlag},
  title = {{Design and synthesis of synchronization skeletons using branching-time temporal logic}},
  year = {1982}
}

@article{clarkson:jcs:2010,
  author = {Michael R. Clarkson and Fred B. Schneider},
  doi = {10.3233/JCS-2009-0393},
  journal = {Journal of Computer Security},
  number = {6},
  pages = {1157-1210},
  publisher = {IOS Press},
  title = {{Hyperproperties}},
  volume = {18},
  year = {2010}
}

@misc{coblenz:arxiv:2020,
  archiveprefix = {arXiv},
  author = {Michael Coblenz and Gauri Kambhatla and Paulette Koronkevich and Jenna L. Wise and Celeste Barnaby and Joshua Sunshine and Jonathan Aldrich and Brad A. Myers},
  eprint = {1912.04719},
  primaryclass = {cs.HC},
  title = {{PLIERS: A process that integrates user-centered methods into programming language design}},
  year = {2020}
}

@inproceedings{cock:ccs:2014,
  address = {New York, NY, USA},
  author = {David Cock and Qian Ge and Toby Murray and Gernot Heiser},
  booktitle = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
  doi = {10.1145/2660267.2660294},
  isbn = {978-1-4503-2957-6},
  keywords = {measurement, performance, security},
  location = {Scottsdale, Arizona, USA},
  numpages = {12},
  pages = {570-581},
  publisher = {ACM},
  series = {CCS'14},
  title = {{The last mile: An empirical study of timing channels on seL4}},
  year = {2014}
}

@inproceedings{cohen:cav:2010,
  author = {Ernie Cohen and Michał Moskal and Wolfram Schulte and Stephan Tobies},
  booktitle = {International Conference on Computer Aided Verification},
  doi = {10.1007/978-3-642-14295-6_42},
  organization = {Springer},
  pages = {480-494},
  title = {{Local verification of global invariants in concurrent programs}},
  year = {2010}
}

@article{cohen:entcs:2009,
  author = {Ernie Cohen and Michał Moskal and Stephan Tobies and Wolfram Schulte},
  doi = {10.1016/j.entcs.2009.09.061},
  journal = {Electronic Notes in Theoretical Computer Science},
  pages = {85-103},
  publisher = {Elsevier},
  title = {{A precise yet efficient memory model for C}},
  volume = {254},
  year = {2009}
}

@inproceedings{cok:bugs:2005,
  author = {David R. Cok},
  booktitle = {Proceedings of BUGS 2005 (PLDI 2005 Workshop on the Evaluation of Software Defect Detection Tools)},
  location = {Chicago, IL, USA},
  month = {June},
  title = {{Issues in deploying software defect detection tools}},
  url = {http://www.cs.umd.edu/~pugh/SoftwareDefectWorkshop05/BugWorkshop05.pdf},
  year = {2005}
}

@inproceedings{condit:esop:2007,
  abstract = {In this paper, we describe the key principles of a dependent type system for low-level imperative languages. The major contributions of this work are (1) a sound type system that combines dependent types and mutation for variables and for heap-allocated structures in a more flexible way than before and (2) a technique for automatically inferring dependent types for local variables. We have applied these general principles to design Deputy, a dependent type system for C that allows the user to describe bounded pointers and tagged unions. Deputy has been used to annotate and check a number of real-world C programs.},
  address = {Berlin, Heidelberg},
  author = {Jeremy Condit and Matthew Harren and Zachary Anderson and David Gay and George C. Necula},
  booktitle = {Programming Languages and Systems},
  editor = {De Nicola, Rocco},
  isbn = {978-3-540-71316-6},
  pages = {520-535},
  publisher = {Springer Berlin Heidelberg},
  title = {{Dependent types for low-level programming}},
  year = {2007}
}

@inproceedings{condit:popl:2009,
  author = {Jeremy Condit and Brian Hackett and Shuvendu K. Lahiri and Shaz Qadeer},
  booktitle = {ACM SIGPLAN Notices},
  doi = {10.1145/1594834.1480921},
  number = {1},
  organization = {ACM},
  pages = {302-314},
  title = {{Unifying type checking and property checking for low-level code}},
  volume = {44},
  year = {2009}
}

@article{conway:cacm:1963,
  acmid = {366704},
  address = {New York, NY, USA},
  author = {Melvin E. Conway},
  doi = {10.1145/366663.366704},
  issn = {0001-0782},
  issue_date = {July 1963},
  journal = {Communications of the ACM},
  month = {July},
  number = {7},
  numpages = {13},
  pages = {396-408},
  publisher = {ACM},
  title = {{Design of a separable transition-diagram compiler}},
  volume = {6},
  year = {1963}
}

@misc{conway:datamation:1968,
  author = {Melvin E. Conway},
  booktitle = {Datamation},
  link = {http://www.melconway.com/Home/pdf/committees.pdf},
  month = {April},
  pages = {28-31},
  title = {{How do committees invent}},
  url = {http://www.melconway.com/Home/pdf/committees.pdf},
  year = {1968}
}

@inproceedings{cook:cav:2018,
  author = {Byron Cook and Kareem Khazem and Daniel Kroening and Serdar Tasiran and Michael Tautschnig and Mark R. Tuttle},
  booktitle = {International Conference on Computer Aided Verification},
  doi = {10.1007/s10703-020-00344-2},
  organization = {Springer},
  pages = {467-486},
  title = {{Model checking boot code from AWS data centers}},
  year = {2018}
}

@inproceedings{coppa:ase:2017,
  abstract = {Symbolic execution is a popular program analysis technique that allows seeking for bugs by reasoning over multiple alternative execution states at once. As the number of states to explore may grow exponentially, a symbolic executor may quickly run out of space. For instance, a memory access to a symbolic address may potentially reference the entire address space, leading to a combinatorial explosion of the possible resulting execution states. To cope with this issue, state-of-the-art executors concretize symbolic addresses that span memory intervals larger than some threshold. Unfortunately, this could result in missing interesting execution states, e.g., where a bug arises. In this paper we introduce MEMSIGHT, a new approach to symbolic memory that reduces the need for concretization, hence offering the opportunity for broader state explorations and more precise pointer reasoning. Rather than mapping address instances to data as previous tools do, our technique maps symbolic address expressions to data, maintaining the possible alternative states resulting from the memory referenced by a symbolic address in a compact, implicit form. A preliminary experimental investigation on prominent benchmarks from the DARPA Cyber Grand Challenge shows that MemSight enables the exploration of states unreachable by previous techniques.},
  author = {Emilio Coppa and Daniele Cono D'Elia and Camil Demetrescu},
  booktitle = {2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE.2017.8115671},
  issn = {},
  keywords = {program debugging;program diagnostics;program testing;program verification;symbolic execution;symbolic executor;memory access;span memory intervals;symbolic memory;address instances;bugs;address space;execution states;program analysis technique;pointer reasoning;symbolic address expressions;Concrete;Weapons;Cognition;Indexes;Merging;Load modeling;Computer bugs},
  month = {Oct},
  number = {},
  pages = {613-618},
  title = {{Rethinking pointer reasoning in symbolic execution}},
  volume = {},
  year = {2017}
}

@inbook{coquand:eurocal:1985,
  abstract = {We present an extensive set of mathematical propositions and proofs in order to demonstrate the power of expression of the theory of constructions.},
  address = {Berlin, Heidelberg},
  author = {Thierry Coquand and Gérard Huet},
  booktitle = {EUROCAL '85: European Conference on Computer Algebra Linz, Austria, April 1-3 1985 Proceedings Vol. 1: Invited Lectures},
  doi = {10.1007/3-540-15983-5_13},
  isbn = {978-3-540-39684-0},
  pages = {151-184},
  publisher = {Springer},
  title = {{Constructions: A higher order proof system for mechanizing mathematics}},
  year = {1985}
}

@article{corbett:tocs:2013,
  address = {New York, NY, USA},
  articleno = {8},
  author = {James C. Corbett and Jeffrey Dean and Michael Epstein and Andrew Fikes and Christopher Frost and J. J. Furman and Sanjay Ghemawat and Andrey Gubarev and Christopher Heiser and Peter Hochschild and Wilson C. Hsieh and Sebastian Kanthak and Eugene Kogan and Hongyi Li and Alexander Lloyd and Sergey Melnik and David Mwaura and David Nagle and Sean Quinlan and Rajesh Rao and Lindsay Rolig and Yasushi Saito and Michal Szymaniak and Christopher Taylor and Ruth Wang and Dale Woodford},
  doi = {10.1145/2491245},
  issn = {0734-2071},
  issue_date = {August 2013},
  journal = {ACM Trans. Comput. Syst.},
  keywords = {Distributed databases, transactions, replication, time management, concurrency control},
  link = {https://doi.org/10.1145/2491245},
  month = {August},
  number = {3},
  numpages = {22},
  publisher = {Association for Computing Machinery},
  title = {{Spanner: Google's globally distributed database}},
  url = {https://doi.org/10.1145/2491245},
  volume = {31},
  year = {2013}
}

@inproceedings{corteggiani:usenix:2018,
  address = {Baltimore, MD},
  affiliations = {Eurecom, Maxim Integrated},
  arate = {100/524},
  author = {Nassim Corteggiani and Giovanni Camurati and Aurélien Francillon},
  booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
  extralink = {Code: https://inception-framework.github.io/inception/},
  link = {https://www.usenix.org/conference/usenixsecurity18/presentation/corteggiani},
  month = {August},
  publisher = {USENIX Association},
  title = {{Inception: System-wide security testing of real-world embedded systems software}},
  url = {https://www.usenix.org/conference/usenixsecurity18/presentation/corteggiani},
  year = {2018}
}

@inproceedings{costanzo:pldi:2016,
  acmid = {2908100},
  address = {New York, NY, USA},
  author = {David Costanzo and Zhong Shao and Ronghui Gu},
  booktitle = {Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2908080.2908100},
  isbn = {978-1-4503-4261-2},
  keywords = {Certified OS Kernels, Information Flow Control, Program Verification, Security Policy Specification, Security-Preserving Simulation},
  location = {Santa Barbara, CA, USA},
  numpages = {17},
  pages = {648-664},
  publisher = {ACM},
  series = {PLDI'16},
  title = {{End-to-end verification of information flow security for C and assembly programs}},
  url = {http://doi.acm.org/10.1145/2908080.2908100},
  year = {2016}
}

@inproceedings{cousot:oopsla:2012,
  author = {Patrick Cousot and Radhia Cousot and Francesco Logozzo and Mike Barnett},
  booktitle = {Proceedings of the 27th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2012},
  doi = {10.1145/2384616.2384633},
  isbn = {978-1-4503-1561-6},
  pages = {213-232},
  publisher = {ACM},
  title = {{An abstract interpretation framework for refactoring with application to extract methods with contracts}},
  year = {2012}
}

@inproceedings{cui:asplos:2013,
  abstract = {Systems code must obey many rules, such as "opened files must be closed." One approach to verifying rules is static analysis, but this technique cannot infer precise runtime effects of code, often emitting many false positives. An alternative is symbolic execution, a technique that verifies program paths over all inputs up to a bounded size. However, when applied to verify rules, existing symbolic execution systems often blindly explore many redundant program paths while missing relevant ones that may contain bugs.Our key insight is that only a small portion of paths are relevant to rules, and the rest (majority) of paths are irrelevant and do not need to be verified. Based on this insight, we create WOODPECKER, a new symbolic execution system for effectively checking rules on systems programs. It provides a set of builtin checkers for common rules, and an interface for users to easily check new rules. It directs symbolic execution toward the program paths relevant to a checked rule, and soundly prunes redundant paths, exponentially speeding up symbolic execution. It is designed to be heuristic-agnostic, enabling users to leverage existing powerful search heuristics.Evaluation on 136 systems programs totaling 545K lines of code, including some of the most widely used programs, shows that, with a time limit of typically just one hour for each verification run, WOODPECKER effectively verifies 28.7\% of the program and rule combinations over bounded input, whereas an existing symbolic execution system KLEE verifies only 8.5\%. For the remaining combinations, WOODPECKER verifies 4.6 times as many relevant paths as KLEE. With a longer time limit, WOODPECKER verifies much more paths than KLEE, e.g., 17 times as many with a fourhour limit. WOODPECKER detects 113 rule violations, including 10 serious data loss errors with 2 most serious ones already confirmed by the corresponding developers.},
  address = {New York, NY, USA},
  author = {Heming Cui and Gang Hu and Jingyue Wu and Junfeng Yang},
  booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/2451116.2451152},
  isbn = {9781450318709},
  keywords = {verification, path slicing, systems rules, error detection, symbolic execution},
  link = {https://doi.org/10.1145/2451116.2451152},
  location = {Houston, Texas, USA},
  numpages = {14},
  pages = {329-342},
  publisher = {Association for Computing Machinery},
  series = {ASPLOS '13},
  title = {{Verifying systems rules using rule-directed symbolic execution}},
  url = {https://doi.org/10.1145/2451116.2451152},
  year = {2013}
}

@inproceedings{cuoq:sefm:2012,
  author = {Pascal Cuoq and Florent Kirchner and Nikolai Kosmatov and Virgile Prevosto and Julien Signoles and Boris Yakobowski and Patrick Baudin and Richard Bonichon and Bernard Botella and Loïc Correnson and Zaynah Dargaye and Philippe Herrmann and Benjamin Monate and Yannick Moy and Anne Pacalet and Armand Puccetti and Muriel Roger and Nicky Williams},
  booktitle = {International Conference on Software Engineering and Formal Methods},
  doi = {10.1007/s00165-014-0326-7},
  organization = {Springer},
  pages = {233-247},
  title = {{Frama-C: A software analysis perspective}},
  year = {2012}
}

@article{curtsinger:cacm:2018,
  abstract = {Improving performance is a central concern for software developers. To locate optimization opportunities, developers rely on software profilers. However, these profilers only report where programs spend their time: optimizing that code may have no impact on performance. Past profilers thus both waste developer time and make it difficult for them to uncover significant optimization opportunities.This paper introduces causal profiling. Unlike past profiling approaches, causal profiling indicates exactly where programmers should focus their optimization efforts, and quantifies their potential impact. Causal profiling works by running performance experiments during program execution. Each experiment calculates the impact of any potential optimization by virtually speeding up code: inserting pauses that slow down all other code running concurrently. The key insight is that this slowdown has the same relative effect as running that line faster, thus "virtually" speeding it up.We present Coz, a causal profiler, which we evaluate on a range of highly-tuned applications such as Memcached, SQLite, and the PARSEC benchmark suite. Coz identifies previously unknown optimization opportunities that are both significant and targeted. Guided by Coz, we improve the performance of Memcached by 9\%, SQLite by 25\%, and accelerate six PARSEC applications by as much as 68\%; in most cases, these optimizations involve modifying under 10 lines of code.},
  address = {New York, NY, USA},
  author = {Charlie Curtsinger and Emery D. Berger},
  doi = {10.1145/3205911},
  issn = {0001-0782},
  issue_date = {June 2018},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/3205911},
  month = {May},
  number = {6},
  numpages = {9},
  pages = {91-99},
  publisher = {Association for Computing Machinery},
  title = {{Coz: Finding code that counts with causal profiling}},
  url = {https://doi.org/10.1145/3205911},
  volume = {61},
  year = {2018}
}

@inproceedings{dabek:sigops:2002,
  acmid = {1133410},
  address = {New York, NY, USA},
  author = {Frank Dabek and Nickolai Zeldovich and M. Frans Kaashoek and David Mazières and Robert Morris},
  booktitle = {Proceedings of the 10th Workshop on ACM SIGOPS European Workshop},
  doi = {10.1145/1133373.1133410},
  location = {Saint-Emilion, France},
  numpages = {4},
  pages = {186-189},
  publisher = {ACM},
  series = {EW 10},
  title = {{Event-driven programming for robust software}},
  year = {2002}
}

@inproceedings{dai:pldi:2005,
  acmid = {1065039},
  address = {New York, NY, USA},
  author = {Jinquan Dai and Bo Huang and Long Li and Luddy Harrison},
  booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/1065010.1065039},
  isbn = {1-59593-056-6},
  keywords = {live-set transmission, network processor, packet processing, parallel, pipelining transformation, program partition},
  location = {Chicago, IL, USA},
  numpages = {12},
  pages = {237-248},
  publisher = {ACM},
  series = {PLDI '05},
  title = {{Automatically partitioning packet processing applications for pipelined architectures}},
  year = {2005}
}

@article{dam:ieeetc:1981,
  author = {Andries van Dam and Mario R. Barbacci and Constantine Halatsis and J. Joosten and M. Letheren},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/tc/DamBHJL81.bib},
  doi = {10.1109/TC.1981.1675830},
  journal = {IEEE Trans. Computers},
  link = {https://doi.org/10.1109/TC.1981.1675830},
  number = {7},
  pages = {513-519},
  timestamp = {Sat, 20 May 2017 01:00:00 +0200},
  title = {{Simulation of a horizontal bit-sliced processor using the ISPS architecture simulation facility}},
  url = {https://doi.org/10.1109/TC.1981.1675830},
  volume = {30},
  year = {1981}
}

@inproceedings{dam:ted:2013,
  acmid = {2517302},
  address = {New York, NY, USA},
  author = {Mads Dam and Roberto Guanciale and Hamed Nemati},
  booktitle = {Proceedings of the 3rd International Workshop on Trustworthy Embedded Devices},
  doi = {10.1145/2517300.2517302},
  isbn = {978-1-4503-2486-1},
  keywords = {binary verification, hypervisor},
  location = {Berlin, Germany},
  numpages = {10},
  pages = {3-12},
  publisher = {ACM},
  series = {TrustED '13},
  title = {{Machine code verification of a tiny ARM hypervisor}},
  year = {2013}
}

@inproceedings{dam:trusted:2013,
  author = {Mads Dam and Roberto Guanciale and Hamed Nemati},
  booktitle = {Proceedings of the 3rd international workshop on Trustworthy embedded devices},
  doi = {10.1145/2517300.2517302},
  organization = {ACM},
  pages = {3-12},
  title = {{Machine code verification of a tiny ARM hypervisor}},
  year = {2013}
}

@inproceedings{damm:fmoods:1999,
  author = {Werner Damm and David Harel},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/fmoods/DammH99.bib},
  booktitle = {Formal Methods for Open Object-Based Distributed Systems, IFIF TC6/WG6.1 Third International Conference on Formal Methods for Open Object-Based Distributed Systems (FMOODS), February 15-18, 1999, Florence, Italy},
  doi = {10.1023/A:1011227529550},
  editor = {Paolo Ciancarini and Alessandro Fantechi and Roberto Gorrieri},
  publisher = {Kluwer},
  series = {IFIP Conference Proceedings},
  timestamp = {Tue, 04 Mar 2003 07:57:24 +0100},
  title = {{LSCs: Breathing life into message sequence charts}},
  volume = {139},
  year = {1999}
}

@inproceedings{daniel:sandp:2020,
  abstract = {The constant-time programming discipline (CT) is an efficient countermeasure against timing side-channel attacks, requiring the control flow and the memory accesses to be independent from the secrets. Yet, writing CT code is challenging as it demands to reason about pairs of execution traces (2-hypersafety property) and it is generally not preserved by the compiler, requiring binary-level analysis. Unfortunately, current verification tools for CT either reason at higher level (C or LLVM), or sacrifice bug-finding or bounded-verification, or do not scale. We tackle the problem of designing an efficient binary-level verification tool for CT providing both bug-finding and bounded-verification. The technique builds on relational symbolic execution enhanced with new optimizations dedicated to information flow and binary-level analysis, yielding a dramatic improvement over prior work based on symbolic execution. We implement a prototype, BINSEC/REL, and perform extensive experiments on a set of 338 cryptographic implementations, demonstrating the benefits of our approach in both bug-finding and bounded-verification. Using BINSEC/REL, we also automate a previous manual study of CT preservation by compilers. Interestingly, we discovered that gcc -O0 and backend passes of clang introduce violations of CT in implementations that were previously deemed secure by a state-of-the-art CT verification tool operating at LLVM level, showing the importance of reasoning at binary-level.},
  author = {Lesly-Ann Daniel and Sébastien Bardin and Tamara Rezk},
  booktitle = {2020 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP40000.2020.00074},
  issn = {2375-1207},
  keywords = {},
  month = {May},
  number = {},
  pages = {1021-1038},
  title = {{Binsec/Rel: Efficient relational symbolic execution for constant-time at binary-level}},
  volume = {},
  year = {2020}
}

@inproceedings{dasgupta:pldi:2019,
  author = {Sandeep Dasgupta and Vikram Adve},
  booktitle = {Proceedings of the 2019 ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/3314221.3314601},
  month = {June},
  pages = {1103-1118},
  publisher = {ACM},
  series = {PLDI '19},
  title = {{A complete formal semantics of x86-64 user-level instruction set architecture}},
  year = {2019}
}

@inproceedings{david:issta:2016,
  abstract = {Symbolic Execution (SE) is a popular and profitable approach to automatic code-based software testing. Concretization and symbolization (C/S) is a crucial part of modern SE tools, since it directly impacts the trade-offs between correctness, completeness and efficiency of the approach. Yet, C/S policies have been barely studied. We intend to remedy to this situation and to establish C/S policies on a firm ground. To this end, we propose a clear separation of concerns between C/S specification on one side, through the new rule-based description language CSml, and the algorithmic core of SE on the other side, revisited to take C/S policies into account. This view is implemented on top of an existing SE tool, demonstrating the feasibility and the benefits of the method. This work paves the way for more flexible SE tools with well-documented and reusable C/S policies, as well as for a systematic study of C/S policies.},
  address = {New York, NY, USA},
  author = {Robin David and Sébastien Bardin and Josselin Feist and Laurent Mounier and Marie-Laure Potet and Thanh Dinh Ta and Jean-Yves Marion},
  booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
  doi = {10.1145/2931037.2931048},
  isbn = {9781450343909},
  keywords = {formal methods, specification language, symbolic execution, automatic test generation},
  link = {https://doi.org/10.1145/2931037.2931048},
  location = {Saarbrücken, Germany},
  numpages = {11},
  pages = {36-46},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2016},
  title = {{Specification of concretization and symbolization policies in symbolic execution}},
  url = {https://doi.org/10.1145/2931037.2931048},
  year = {2016}
}

@phdthesis{degenbaev:phd:2012,
  address = {Postfach 151141, 66041 Saarbrücken},
  author = {Ulan Degenbaev},
  language = {eng},
  link = {http://scidok.sulb.uni-saarland.de/volltexte/2012/4707},
  school = {Universität des Saarlandes},
  title = {{Formal specification of the x86 instruction set architecture}},
  url = {http://scidok.sulb.uni-saarland.de/volltexte/2012/4707},
  year = {2012}
}

@inproceedings{deline:pldi:2001,
  address = {New York, NY, USA},
  author = {Robert DeLine and Manuel Fähndrich},
  booktitle = {Proceedings of the ACM SIGPLAN 2001 Conference on Programming Language Design and Implementation},
  doi = {10.1145/378795.378811},
  isbn = {1581134142},
  location = {Snowbird, Utah, USA},
  numpages = {11},
  pages = {59--69},
  publisher = {Association for Computing Machinery},
  series = {PLDI'01},
  title = {{Enforcing high-level protocols in low-level software}},
  url = {https://doi.org/10.1145/378795.378811},
  year = {2001}
}

@article{demoura:cacm:2011,
  address = {New York, NY, USA},
  author = {Leonardo de Moura and Nikolaj Bjørner},
  doi = {10.1145/1995376.1995394},
  issn = {0001-0782},
  issue_date = {September 2011},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/1995376.1995394},
  month = {September},
  number = {9},
  numpages = {9},
  pages = {69-77},
  publisher = {Association for Computing Machinery},
  title = {{Satisfiability modulo theories: Introduction and applications}},
  url = {https://doi.org/10.1145/1995376.1995394},
  volume = {54},
  year = {2011}
}

@inproceedings{demoura:cade:2015,
  author = {Leonardo de Moura and Soonho Kong and Jeremy Avigad and Floris Van Doorn and Jakob von Raumer},
  booktitle = {International Conference on Automated Deduction},
  doi = {10.1007/978-3-319-21401-6_26},
  organization = {Springer},
  pages = {378-388},
  title = {{The Lean theorem prover (system description)}},
  year = {2015}
}

@inproceedings{demoura:tacas:2008,
  author = {Leonardo de Moura and Nikolaj Bjørner},
  booktitle = {International conference on Tools and Algorithms for the Construction and Analysis of Systems},
  doi = {10.1007/978-3-540-78800-3_24},
  organization = {Springer},
  pages = {337-340},
  title = {{Z3: An efficient SMT solver}},
  year = {2008}
}

@inproceedings{deng:hasp:2019,
  author = {Shuwen Deng and Doğuhan Gümüşoğlu and Wenjie Xiong and Sercan Sari and Y. Serhan Gener and Corine Lu and Onur Demir and Jakub Szefer},
  booktitle = {Proceedings of the 8th International Workshop on Hardware and Architectural Support for Security and Privacy},
  doi = {10.1145/3337167.3337174},
  pages = {7:1-7:8},
  publisher = {ACM},
  title = {{SecChisel: Language and tool for practical and scalable security verification of security-aware hardware architectures}},
  year = {2019}
}

@techreport{denis:hal:2020,
  author = {Xavier Denis},
  hal_id = {hal-02962804},
  hal_version = {v1},
  institution = {Université de Paris},
  link = {https://hal.archives-ouvertes.fr/hal-02962804},
  month = {September},
  pdf = {https://hal.archives-ouvertes.fr/hal-02962804/file/paper.pdf},
  title = {{Deductive program verification for a language with a Rust-like typing discipline type [Internship report]}},
  url = {https://hal.archives-ouvertes.fr/hal-02962804},
  year = {2020}
}

@article{denning:cacm:1976,
  address = {New York, NY, USA},
  author = {Dorothy E. Denning},
  doi = {10.1145/360051.360056},
  issn = {0001-0782},
  issue_date = {May 1976},
  journal = {Communications of the ACM},
  keywords = {information flow, lattice, program certification, protection, security, security class},
  month = {May},
  number = {5},
  numpages = {8},
  pages = {236-243},
  publisher = {ACM},
  title = {{A lattice model of secure information flow}},
  volume = {19},
  year = {1976}
}

@inproceedings{dias:popl:2010,
  address = {New York, NY, USA},
  author = {João Dias and Norman Ramsey},
  booktitle = {Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/1706299.1706346},
  isbn = {9781605584799},
  keywords = {retargetable compilers, instruction selection, declarative machine descriptions},
  link = {https://doi.org/10.1145/1706299.1706346},
  location = {Madrid, Spain},
  numpages = {14},
  pages = {403-416},
  publisher = {Association for Computing Machinery},
  series = {POPL '10},
  title = {{Automatically generating instruction selectors using declarative machine descriptions}},
  url = {https://doi.org/10.1145/1706299.1706346},
  year = {2010}
}

@inproceedings{dimjasevic:ifm:2018,
  abstract = {Testing is currently the main technique adopted by the industry for improving the quality, reliability, and security of software. In order to lower the cost of manual testing, automatic testing techniques have been devised, such as random and symbolic testing, with their respective trade-offs. For example, random testing excels at fast global exploration of software, while it plateaus when faced with hard-to-hit numerically-intensive execution paths. On the other hand, symbolic testing excels at exploring such paths, while it struggles when faced with complex heap class structures. In this paper, we describe an approach for automatic unit testing of object-oriented software that integrates the two techniques. We leverage feedback-directed unit testing to generate meaningful sequences of constructor+method invocations that create rich heap structures, and we in turn further explore these sequences using dynamic symbolic execution. We implement this approach in a tool called JDoop, which we augment with several parameters for fine-tuning its heuristics; such ``knobs'' allow for a detailed exploration of the various trade-offs that the proposed integration offers. Using JDoop, we perform an extensive empirical exploration of this space, and we describe lessons learned and guidelines for future research efforts in this area.},
  address = {Cham},
  author = {Marko Dimjašević and Falk Howar and Kasper Luckow and Zvonimir Rakamarić},
  booktitle = {Integrated Formal Methods},
  doi = {10.1007/978-3-319-98938-9_6},
  editor = {Furia, Carlo A. and Winter, Kirsten},
  isbn = {978-3-319-98938-9},
  pages = {89-109},
  publisher = {Springer International Publishing},
  title = {{Study of integrating random and symbolic testing for object-oriented software}},
  year = {2018}
}

@inproceedings{dinsdale-young:popl:2013,
  address = {New York, NY, USA},
  author = {Thomas Dinsdale-Young and Lars Birkedal and Philippa Gardner and Matthew Parkinson and Hongseok Yang},
  booktitle = {Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/2429069.2429104},
  isbn = {9781450318327},
  keywords = {axiomatic semantics, compositional reasoning, concurrency},
  location = {Rome, Italy},
  numpages = {14},
  pages = {287-300},
  publisher = {Association for Computing Machinery},
  series = {POPL '13},
  title = {{Views: Compositional reasoning for concurrent programs}},
  url = {https://doi.org/10.1145/2429069.2429104},
  year = {2013}
}

@article{distefano:cacm:2019,
  abstract = {Key lessons for designing static analyses tools deployed to find bugs in hundreds of millions of lines of code.},
  address = {New York, NY, USA},
  author = {Dino Distefano and Manuel Fähndrich and Francesco Logozzo and Peter W. O'Hearn},
  doi = {10.1145/3338112},
  issn = {0001-0782},
  issue_date = {August 2019},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/3338112},
  month = {July},
  number = {8},
  numpages = {9},
  pages = {62-70},
  publisher = {Association for Computing Machinery},
  title = {{Scaling static analyses at Facebook}},
  url = {https://doi.org/10.1145/3338112},
  volume = {62},
  year = {2019}
}

@inproceedings{distefano:tacas:2006,
  author = {Dino Distefano and Peter W. O'Hearn and Hongseok Yang},
  booktitle = {International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
  organization = {Springer},
  pages = {287-302},
  title = {{A local shape analysis based on separation logic}},
  year = {2006}
}

@article{dixit:arxiv:2021,
  author = {Harish Dattatraya Dixit and Sneha Pendharkar and Matt Beadon and Chris Mason and Tejasvi Chakravarthy and Bharath Muthiah and Sriram Sankar},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-2102-11245.bib},
  eprint = {2102.11245},
  eprinttype = {arXiv},
  journal = {CoRR},
  link = {https://arxiv.org/abs/2102.11245},
  timestamp = {Wed, 24 Feb 2021 15:42:45 +0100},
  title = {{Silent data corruptions at scale}},
  url = {https://arxiv.org/abs/2102.11245},
  volume = {abs/2102.11245},
  year = {2021}
}

@article{djordjevic:cj:1985,
  author = {Jovan Djordjevic and Mario R. Barbacci and Brad Hosler},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/cj/DjordjevicBH85.bib},
  doi = {10.1093/comjnl/28.4.357},
  journal = {Comput. J.},
  link = {https://doi.org/10.1093/comjnl/28.4.357},
  number = {4},
  pages = {357-365},
  timestamp = {Sat, 20 May 2017 01:00:00 +0200},
  title = {{A PMS level notation for the description and simulation of digital systems}},
  url = {https://doi.org/10.1093/comjnl/28.4.357},
  volume = {28},
  year = {1985}
}

@inproceedings{draves:sosp:1991,
  acmid = {121155},
  address = {New York, NY, USA},
  author = {Richard P. Draves and Brian N. Bershad and Richard F. Rashid and Randall W. Dean},
  booktitle = {Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles},
  doi = {10.1145/121132.121155},
  isbn = {0-89791-447-3},
  location = {Pacific Grove, California, USA},
  numpages = {15},
  pages = {122-136},
  publisher = {ACM},
  series = {SOSP '91},
  title = {{Using continuations to implement thread management and communication in operating systems}},
  year = {1991}
}

@inproceedings{du:sc:2003,
  author = {Wei Du and Renato Ferreira and Gagan Agrawal},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  booktitle = {Proceedings of Conference on High Performance Networking and Computing (SC2003)},
  doi = {10.1145/1048935.1050159},
  pages = {8},
  title = {{Compiler support for exploiting coarse-grained pipelined parallelism.}},
  year = {2003}
}

@inproceedings{dunkels:enss:2006,
  acmid = {1182811},
  address = {New York, NY, USA},
  author = {Adam Dunkels and Oliver Schmidt and Thiemo Voigt and Muneeb Ali},
  booktitle = {Proceedings of the 4th International Conference on Embedded Networked Sensor Systems},
  doi = {10.1145/1182807.1182811},
  isbn = {1-59593-343-3},
  keywords = {embedded systems, threads, wireless sensor networks},
  location = {Boulder, Colorado, USA},
  numpages = {14},
  pages = {29-42},
  publisher = {ACM},
  series = {SenSys '06},
  title = {{Protothreads: Simplifying Event-driven Programming of Memory-constrained Embedded Systems}},
  year = {2006}
}

@inproceedings{dutra:icse:2018,
  abstract = {In software and hardware testing, generating multiple inputs which satisfy a given set of constraints is an important problem with applications in fuzz testing and stimulus generation. However, it is a challenge to perform the sampling efficiently, while generating a diverse set of inputs which satisfy the constraints. We developed a new algorithm QuickSampler which requires a small number of solver calls to produce millions of samples which satisfy the constraints with high probability. We evaluate QuickSampler on large real-world benchmarks and show that it can produce unique valid solutions orders of magnitude faster than other state-of-the-art sampling tools, with a distribution which is reasonably close to uniform in practice.},
  address = {New York, NY, USA},
  author = {Rafael Dutra and Kevin Laeufer and Jonathan Bachrach and Koushik Sen},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  doi = {10.1145/3180155.3180248},
  isbn = {9781450356381},
  keywords = {sampling, constrained-random verification, stimulus generation, constraint-based testing},
  link = {https://doi.org/10.1145/3180155.3180248},
  location = {Gothenburg, Sweden},
  numpages = {11},
  pages = {549-559},
  publisher = {Association for Computing Machinery},
  series = {ICSE '18},
  title = {{Efficient sampling of SAT solutions for testing}},
  url = {https://doi.org/10.1145/3180155.3180248},
  year = {2018}
}

@inproceedings{edwards:icrs:1975,
  address = {New York, NY, USA},
  author = {N. P. Edwards},
  booktitle = {Proceedings of the International Conference on Reliable Software},
  doi = {10.1145/800027.808463},
  isbn = {9781450373852},
  keywords = {Testing, Modularity, Verifying function of logic, Reducing complexity of logical structures},
  link = {https://doi.org/10.1145/800027.808463},
  location = {Los Angeles, California},
  numpages = {10},
  pages = {401-410},
  publisher = {Association for Computing Machinery},
  title = {{The effect of certain modular design principles on testability}},
  url = {https://doi.org/10.1145/800027.808463},
  year = {1975}
}

@inproceedings{efstathopoulos:sosp:2005,
  address = {New York, NY, USA},
  author = {Petros Efstathopoulos and Maxwell Krohn and Steve VanDeBogart and Cliff Frey and David Ziegler and Eddie Kohler and David Mazières and M. Frans Kaashoek and Robert Morris},
  booktitle = {Proceedings of the Twentieth ACM Symposium on Operating Systems Principles},
  doi = {10.1145/1095810.1095813},
  isbn = {1-59593-079-5},
  keywords = {event processes, information flow, labels, mandatory access control, secure web servers},
  location = {Brighton, United Kingdom},
  numpages = {14},
  pages = {17-30},
  publisher = {ACM},
  series = {SOSP'05},
  title = {{Labels and event processes in the Asbestos operating system}},
  year = {2005}
}

@inproceedings{eide:aspse:2001,
  abstract = {Knit is a new component specification and linking language. It was initially designed for low-level systems software, which requires especially flexible components with especially well-defined interfaces. For example, threads and virtual memory are typically implemented by components within the system, instead of being supplied by some execution environment. Consequently, components used to construct the system must expose interactions with threads and memory. The component composition tool must then check the resulting system for correctness, and weave the components together to achieve reasonable performance.  Component composition with Knit thus acts like aspect weaving: component interfaces determine the ``join points'' for weaving, while components (some of which may be automatically generated) implement aspects. Knit is not limited to the construction of low-level software, and to the degree that a set of components exposes fine-grained relationships, Knit provides the benefits of aspect-oriented programming within its component model.},
  affiliation = {University of Utah},
  ar_shortname = {ASPSE 01},
  author = {Eric Eide and Alastair D. Reid and Matthew Flatt and Jay Lepreau},
  booktitle = {Workshop on Advanced Separation of Concerns in Software Engineering},
  location = {Toronto, Ontario, Canada},
  month = {May},
  title = {{Aspect weaving as component knitting: Separating concerns with Knit}},
  year = {2001}
}

@inproceedings{eide:icse:2002,
  abstract = {Design patterns are a valuable mechanism for emphasizing structure, capturing design expertise, and facilitating restructuring of software systems. Patterns are typically applied in the context of an object-oriented language and are implemented so that the pattern participants correspond to object instances that are created and connected at run-time. This paper describes a complementary realization of design patterns, in which many pattern participants correspond to statically instantiated and connected components.Our approach separates the static parts of the software design from the dynamic parts of the system behavior. This separation makes the software design more amenable to analysis, thus enabling more effective and domain-specific detection of system design errors, prediction of run-time behavior, and more effective optimization. This technique is applicable to imperative, functional, and object-oriented languages: we have extended C, Scheme, and Java with our component model. In this paper, we illustrate our approach in the context of the OSKit, a collection of operating system components written in C.},
  acceptance = {15},
  affiliation = {University of Utah},
  ar_shortname = {ICSE 02},
  author = {Eric Eide and Alastair D. Reid and John Regehr and Jay Lepreau},
  booktitle = {Proceedings of the 24th International Conference on Software Engineering (ICSE 2002)},
  day = {19-25},
  doi = {10.1145/581339.581367},
  editor = {Will Tracz and Michal Young and Jeff Magee},
  location = {Orlando, Florida, USA},
  month = {May},
  pages = {208-218},
  publisher = {ACM},
  title = {{Static and dynamic structure in design patterns}},
  year = {2002}
}

@inproceedings{engler:issta:2007,
  address = {New York, NY, USA},
  author = {Dawson Engler and Daniel Dunbar},
  booktitle = {Proceedings of the 2007 International Symposium on Software Testing and Analysis},
  doi = {10.1145/1273463.1273464},
  isbn = {9781595937346},
  keywords = {bug finding, dynamic analysis, symbolic execution},
  link = {https://doi.org/10.1145/1273463.1273464},
  location = {London, United Kingdom},
  numpages = {4},
  pages = {1-4},
  publisher = {Association for Computing Machinery},
  series = {ISSTA '07},
  title = {{Under-constrained execution: Making automatic code destruction easy and scalable}},
  url = {https://doi.org/10.1145/1273463.1273464},
  year = {2007}
}

@inproceedings{erbsen:pldi:2021,
  abstract = {The interfaces between layers of a system are susceptible to bugs if developers of adjacent layers proceed under subtly different assumptions. Formal verification of two layers against the same formal model of the interface between them can be used to shake out these bugs. Doing so for every interface in the system can, in principle, yield unparalleled assurance of the correctness and security of the system as a whole. However, there have been remarkably few efforts that carry out this exercise, and all of them have simplified the task by restricting interactivity of the application, inventing new simplified instruction sets, and using unrealistic input and output mechanisms. We report on the first verification of a realistic embedded system, with its application software, device drivers, compiler, and RISC-V processor represented inside the Coq proof assistant as one mathematical object, with a machine-checked proof of functional correctness. A key challenge is structuring the proof modularly, so that further refinement of the components or expansion of the system can proceed without revisiting the rest of the system.},
  address = {New York, NY, USA},
  author = {Andres Erbsen and Samuel Gruetter and Joonwon Choi and Clark Wood and Adam Chlipala},
  booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3453483.3454065},
  isbn = {9781450383912},
  keywords = {Hardware-Software Interface, Formal Verification, RISC-V Instruction-Set Family, Proof Assistants, Embedded Systems},
  link = {https://doi.org/10.1145/3453483.3454065},
  location = {Virtual, Canada},
  numpages = {16},
  pages = {604-619},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2021},
  title = {{Integration verification across software and hardware for a simple embedded system}},
  url = {https://doi.org/10.1145/3453483.3454065},
  year = {2021}
}

@inproceedings{ernst:icse:2016,
  author = {Michael D. Ernst and Alberto Lovato and Damiano Macedonio and Fausto Spoto and Javier Thaine},
  booktitle = {2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)},
  doi = {10.1145/2884781.2884882},
  organization = {IEEE},
  pages = {1133-1144},
  title = {{Locking discipline inference and checking}},
  year = {2016}
}

@inproceedings{evans:icse:2020,
  address = {New York, NY, USA},
  author = {Ana Nora Evans and Bradford Campbell and Mary Lou Soffa},
  booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
  doi = {10.1145/3377811.3380413},
  isbn = {9781450371216},
  link = {https://doi.org/10.1145/3377811.3380413},
  location = {Seoul, South Korea},
  numpages = {12},
  pages = {246-257},
  publisher = {Association for Computing Machinery},
  series = {ICSE '20},
  title = {{Is Rust used safely by software developers?}},
  url = {https://doi.org/10.1145/3377811.3380413},
  year = {2020}
}

@inbook{evtyushkin:asplos:2021,
  abstract = {Side-channel attacks such as Spectre rely on properties of modern CPUs that permit discovery of microarchitectural state via timing of various operations. The Weird Machine concept is an increasingly popular model for characterization of emergent execution that arises from side-effects of conventional computing constructs. In this work we introduce Microarchitectural Weird Machines (\mathrm{\mu}WM): code constructions that allow performing computation through the means of side effects and conflicts between microarchitectual entities such as branch predictors and caches. The results of such computations are observed as timing variations. We demonstrate how \mathrm{\mu}WMs can be used as a powerful obfuscation engine where computation operates based on events unobservable to conventional anti-obfuscation tools based on emulation, debugging, static and dynamic analysis techniques. We demonstrate that \mathrm{\mu}WMs can be used to reliably perform arbitrary computation by implementing a SHA-1 hash function. We then present a practical example in which we use a \mathrm{\mu}WM to obfuscate malware code such that its passive operation is invisible to an observer with full power to view the architectural state of the system until the code receives a trigger. When the trigger is received the malware decrypts and executes its payload. To show the effectiveness of obfuscation we demonstrate its use in the concealment and subsequent execution of a payload that exfiltrates a shadow password file, and a payload that creates a reverse shell.},
  address = {New York, NY, USA},
  author = {Dmitry Evtyushkin and Thomas Benjamin and Jesse Elwell and Jeffrey A. Eitel and Angelo Sapello and Abhrajit Ghosh},
  booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  isbn = {9781450383172},
  link = {https://doi.org/10.1145/3445814.3446729},
  numpages = {15},
  pages = {758-772},
  publisher = {Association for Computing Machinery},
  title = {{Computing with time: Microarchitectural weird machines}},
  url = {https://doi.org/10.1145/3445814.3446729},
  year = {2021}
}

@inproceedings{fahndrich:foveoos:2010,
  author = {Manuel Fähndrich and Francesco Logozzo},
  booktitle = {International Conference on Formal Verification of Object-oriented Software},
  doi = {10.1007/978-3-642-18070-5_2},
  organization = {Springer},
  pages = {10-30},
  title = {{Static contract checking with abstract interpretation}},
  year = {2010}
}

@article{falkoff:ibm:1964,
  acmid = {1662345},
  address = {Riverton, NJ, USA},
  author = {Adin D. Falkoff and Kenneth E. Iverson and Edward H. Sussenguth},
  doi = {10.1147/sj.32.0198},
  issn = {0018-8670},
  issue_date = {June 1964},
  journal = {IBM Systems Journal},
  month = {June},
  number = {2},
  numpages = {64},
  pages = {198-261},
  publisher = {IBM Corp.},
  title = {{A formal description of SYSTEM/360}},
  volume = {3},
  year = {1964}
}

@inproceedings{fauth:edtc:1995,
  author = {Andreas Fauth and Johan Van Praet and Markus Freericks},
  booktitle = {Proceedings European Design and Test Conference, 1995. ED\&TC 1995},
  doi = {10.1109/EDTC.1995.470354},
  organization = {IEEE},
  pages = {503-507},
  title = {{Describing instruction set processors using nML}},
  year = {1995}
}

@inproceedings{fernandez:icse:1997,
  address = {New York, NY, USA},
  author = {Mary F. Fernández and Norman Ramsey},
  booktitle = {Proceedings of the 19th International Conference on Software Engineering},
  doi = {10.1145/253228.253300},
  isbn = {0897919149},
  keywords = {machine-code toolkit, application generators, specification testing},
  link = {https://doi.org/10.1145/253228.253300},
  location = {Boston, Massachusetts, USA},
  numpages = {11},
  pages = {326-336},
  publisher = {Association for Computing Machinery},
  series = {ICSE '97},
  title = {{Automatic checking of instruction specifications}},
  url = {https://doi.org/10.1145/253228.253300},
  year = {1997}
}

@inproceedings{ferraiuolo:asplos:2017,
  author = {Andrew Ferraiuolo and Rui Xu and Danfeng Zhang and Andrew C. Myers and G. Edward Suh},
  booktitle = {ACM SIGARCH Computer Architecture News},
  doi = {10.1145/3037697.3037739},
  number = {1},
  organization = {ACM},
  pages = {555-568},
  title = {{Verification of a practical hardware security architecture through static information flow analysis}},
  volume = {45},
  year = {2017}
}

@inproceedings{ferraiuolo:ccs:2018,
  author = {Andrew Ferraiuolo and Mark Zhao and G. Edward Suh and Andrew C. Myers},
  booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and  Communications Security, CCS 2018},
  doi = {10.1145/3243734.3243743},
  title = {{HyperFlow: A processor architecture for nonmalleable, timing-safe information flow security}},
  year = {2018}
}

@inproceedings{ferraiuolo:dac:2017,
  author = {Andrew Ferraiuolo and Weizhe Hua and Andrew C. Myers and G. Edward Suh},
  booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},
  doi = {10.1145/3061639.3062316},
  organization = {ACM},
  pages = {6},
  title = {{Secure information flow verification with mutable dependent types}},
  year = {2017}
}

@inproceedings{ferraiuolo:sosp:2017,
  author = {Andrew Ferraiuolo and Andrew Baumann and Chris Hawblitzel and Bryan Parno},
  booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
  doi = {10.1145/3132747.3132782},
  organization = {ACM},
  pages = {287-305},
  title = {{Komodo: Using verification to disentangle secure-enclave hardware from software}},
  year = {2017}
}

@inproceedings{filliatre:cav:2007,
  author = {Jean-Christophe Filliâtre and Claude Marché},
  booktitle = {International Conference on Computer Aided Verification},
  doi = {10.1007/978-3-540-73368-3_21},
  organization = {Springer},
  pages = {173-177},
  title = {{The Why/Krakatoa/Caduceus platform for deductive program verification}},
  year = {2007}
}

@inproceedings{filliatre:esop:2013,
  author = {Jean-Christophe Filliâtre and Andrei Paskevich},
  booktitle = {European Symposium on Programming},
  doi = {10.1007/978-3-642-37036-6_8},
  organization = {Springer},
  pages = {125-128},
  title = {{Why3 — where programs meet provers}},
  year = {2013}
}

@inproceedings{filliatre:fem:2004,
  author = {Jean-Christophe Filliâtre and Claude Marché},
  booktitle = {Sixth International Conference on Formal Engineering Methods},
  doi = {10.1007/978-3-540-30482-1_10},
  organization = {Springer},
  pages = {15-29},
  series = {LNCS},
  title = {{Multi-prover verification of C programs}},
  volume = {3308},
  year = {2004}
}

@inproceedings{finne:icfp:1999,
  abstract = {The increasing popularity of component-based programming tools offer a big opportunity to designers of advanced programming languages, such as Haskell. If we can package our programs as software components, then it is easy to integrate them into applications written in other languages.In earlier work we described a preliminary integration of Haskell with Microsoft's Component Object Model (COM), focusing on how Haskell can create and invoke COM objects. This paper develops that work, concentrating on the mechanisms that support externally-callable Haskell functions, and the encapsulation of Haskell programs as COM objects.},
  address = {New York, NY, USA},
  author = {Sigbjorn Finne and Daan Leijen and Erik Meijer and Simon Peyton Jones},
  booktitle = {Proceedings of the Fourth ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/317636.317790},
  isbn = {1581131119},
  link = {https://doi.org/10.1145/317636.317790},
  location = {Paris, France},
  numpages = {12},
  pages = {114-125},
  publisher = {Association for Computing Machinery},
  series = {ICFP '99},
  title = {{Calling hell from heaven and heaven from hell}},
  url = {https://doi.org/10.1145/317636.317790},
  year = {1999}
}

@misc{fioraldi:arxiv:2020,
  archiveprefix = {arXiv},
  author = {Andrea Fioraldi},
  eprint = {2012.11182},
  primaryclass = {cs.SE},
  title = {{Program state abstraction for feedback-driven fuzz testing using likely invariants}},
  year = {2020}
}

@inproceedings{fischer:ase:2013,
  author = {Bernd Fischer and Omar Inverso and Gennaro Parlato},
  booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
  doi = {10.1109/ASE.2013.6693139},
  organization = {IEEE Press},
  pages = {710-713},
  title = {{CSeq: a concurrency pre-processor for sequential C verification tools}},
  year = {2013}
}

@inproceedings{fisher:isca:1983,
  acmid = {801649},
  address = {New York, NY, USA},
  author = {Joseph A. Fisher},
  booktitle = {Proceedings of the 10th Annual International Symposium on Computer Architecture},
  doi = {10.1145/800046.801649},
  isbn = {0-89791-101-6},
  location = {Stockholm, Sweden},
  numpages = {11},
  pages = {140-150},
  publisher = {ACM},
  series = {ISCA '83},
  title = {{Very long instruction word architectures and the ELI-512}},
  year = {1983}
}

@article{fluet:jfp:2006,
  author = {Matthew Fluet and Riccardo Pucella},
  doi = {10.1017/S0956796806006046},
  journal = {Journal of Functional Programming},
  number = {6},
  pages = {751-791},
  publisher = {Cambridge University Press},
  title = {{Phantom types and subtyping}},
  volume = {16},
  year = {2006}
}

@inproceedings{flur:popl:2016,
  author = {Shaked Flur and Kathryn E. Gray and Christopher Pulte and Susmit Sarkar and Ali Sezgin and Luc Maranget and Will Deacon and Peter Sewell},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp2.uni-trier.de/rec/bib/conf/popl/FlurGPSSMDS16},
  booktitle = {Proceedings Principles of Programming Languages, POPL 2016},
  doi = {10.1145/2837614.2837615},
  pages = {608-621},
  timestamp = {Wed, 09 Mar 2016 08:11:59 +0100},
  title = {{Modelling the ARMv8 architecture, operationally: concurrency and ISA}},
  year = {2016}
}

@article{flynn:ieeeproc:1966,
  abstract = {Very high-speed computers may be classified as follows: 1) Single Instruction Stream-Single Data Stream (SISD) 2) Single Instruction Stream-Multiple Data Stream (SIMD) 3) Multiple Instruction Stream-Single Data Stream (MISD) 4) Multiple Instruction Stream-Multiple Data Stream (MIMD). "Stream," as used here, refers to the sequence of data or instructions as seen by the machine during the execution of a program. The constituents of a system: storage, execution, and instruction handling (branching) are discussed with regard to recent developments and/or systems limitations. The constituents are discussed in terms of concurrent SISD systems (CDC 6600 series and, in particular, IBM Model 90 series), since multiple stream organizations usually do not require any more elaborate components. Representative organizations are selected from each class and the arrangement of the constituents is shown.},
  added-at = {2012-07-04T12:42:26.000+0200},
  author = {Michael J. Flynn},
  biburl = {http://www.bibsonomy.org/bibtex/2597a6e9a19f4118fc4b89649d820890b/gron},
  description = {IEEE Xplore - Abstract Page},
  doi = {10.1109/PROC.1966.5273},
  interhash = {eb81c018ceeeadf265d931227f8e0461},
  intrahash = {597a6e9a19f4118fc4b89649d820890b},
  issn = {0018-9219},
  journal = {Proceedings of the IEEE},
  keywords = {Flynn MIMD MISD SIMD SISD Taxonomy},
  month = {December},
  number = {12},
  pages = {1901 - 1909},
  timestamp = {2012-07-04T12:42:26.000+0200},
  title = {{Very high-speed computing systems}},
  volume = {54},
  year = {1966}
}

@inproceedings{fonseca:ecs:2017,
  acmid = {3064183},
  address = {New York, NY, USA},
  author = {Pedro Fonseca and Kaiyuan Zhang and Xi Wang and Arvind Krishnamurthy},
  booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},
  doi = {10.1145/3064176.3064183},
  isbn = {978-1-4503-4938-3},
  location = {Belgrade, Serbia},
  numpages = {16},
  pages = {328-343},
  publisher = {ACM},
  series = {EuroSys '17},
  title = {{An empirical study on the correctness of formally verified distributed systems}},
  year = {2017}
}

@techreport{fox:cambridge:2001,
  author = {Anthony C. J. Fox},
  institution = {University of Cambridge, Computer Laboratory},
  link = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-545.pdf},
  month = {June},
  number = {UCAM-CL-TR-545},
  title = {{A HOL specification of the ARM instruction set architecture}},
  url = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-545.pdf},
  year = {2001}
}

@inproceedings{fox:itp:2010,
  author = {Anthony C. J. Fox and Magnus O. Myreen},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/itp/FoxM10},
  booktitle = {Proceedings Interactive Theorem Proving ITP 2010},
  doi = {10.1007/978-3-642-14052-5_18},
  pages = {243-258},
  publisher = {Springer},
  series = {LNCS},
  timestamp = {Tue, 10 Aug 2010 14:34:07 +0200},
  title = {{A trustworthy monadic formalization of the ARMv7 instruction set architecture}},
  volume = {6172},
  year = {2010}
}

@inproceedings{fox:itp:2012,
  abstract = {This rough diamond presents a new domain-specific language (DSL) for producing detailed models of Instruction Set Architectures, such as ARM and x86. The language's design and methodology is discussed and we propose future plans for this work. Feedback is sought from the wider theorem proving community in helping establish future directions for this project. A parser and interpreter for the DSL has been developed in Standard ML, with an ARMv7 model used as a case study.},
  address = {Berlin, Heidelberg},
  author = {Anthony C. J. Fox},
  booktitle = {Interactive Theorem Proving},
  doi = {10.1007/978-3-642-32347-8_23},
  editor = {Beringer, Lennart and Felty, Amy},
  isbn = {978-3-642-32347-8},
  pages = {338-344},
  publisher = {Springer Berlin Heidelberg},
  title = {{Directions in ISA specification}},
  year = {2012}
}

@inproceedings{fox:itps:2015,
  author = {Anthony C. J. Fox},
  booktitle = {Proceedings 6th International Conference Interactive Theorem Proving ITP 2015},
  doi = {10.1007/978-3-319-22102-1},
  location = {Nanjing, China},
  month = {August},
  pages = {187-202},
  publisher = {Springer},
  series = {LNCS},
  title = {{Improved tool support for machine-code decompilation in HOL4}},
  volume = {9236},
  year = {2015}
}

@inproceedings{fox:tphols:2003,
  author = {Anthony C. J. Fox},
  booktitle = {Theorem Proving in Higher Order Logics (TPHOLs '03)},
  doi = {10.1007/10930755_2},
  editor = {David Basin and Burkhart Wolff},
  isbn = {978-3-540-45130-3},
  pages = {25-40},
  publisher = {Springer},
  series = {LNCS},
  title = {{Formal specification and verification of ARM6}},
  volume = {2758},
  year = {2003}
}

@techreport{fox:ucam:2002,
  author = {Anthony C. J. Fox},
  institution = {University of Cambridge, Computer Laboratory},
  link = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-548.pdf},
  month = {November},
  number = {UCAM-CL-TR-548},
  title = {{Formal verification of the ARM6 micro-architecture}},
  url = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-548.pdf},
  year = {2002}
}

@TECHREPORT{franklin:cmu:2008,
  author = {Jason Franklin and Arvind Seshadri and Ning Qu and Sagar Chaki and Anupam Datta},
  institution = {CMU},
  number = {CMU-CyLab-08-008},
  title = {{Attacking, repairing, and verifying SecVisor: A retrospective on the security of a hypervisor}},
  year = {2008}
}

@article{fraser:sigart:1977,
  acmid = {806941},
  address = {New York, NY, USA},
  author = {Christopher W. Fraser},
  doi = {10.1145/872736.806941},
  issn = {0163-5719},
  issue_date = {August 1977},
  journal = {ACM SIGART Bulletin},
  month = {August},
  numpages = {4},
  pages = {126-129},
  publisher = {ACM},
  title = {{A knowledge-based code generator generator}},
  volume = {64},
  year = {1977}
}

@article{freedman:tse:1991,
  author = {R. S. Freedman},
  doi = {10.1109/32.87281},
  issn = {1939-3520},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {formal specification;program testing;software components;domain testability;observability;controllability;domain-testable program;input-output inconsistencies;small test sets;test outputs;program specifications;domain-testable specification;nondomain-testable specification;Software testing;Controllability;Observability;Timing;Computer displays;Software engineering;Hardware;Programming;Computer science;Explosives},
  month = {June},
  number = {6},
  pages = {553-564},
  title = {{Testability of software components}},
  volume = {17},
  year = {1991}
}

@inproceedings{frias:icse:2005,
  acmid = {1062535},
  address = {New York, NY, USA},
  author = {Marcelo F. Frias and Juan P. Galeotti and Carlos G. López Pombo and Nazareno M. Aguirre},
  booktitle = {Proceedings of the 27th International Conference on Software Engineering},
  doi = {10.1145/1062455.1062535},
  isbn = {1-58113-963-2},
  keywords = {alloy, dynamic logic, software specification, software validation},
  location = {St. Louis, MO, USA},
  numpages = {10},
  pages = {442-451},
  publisher = {ACM},
  series = {ICSE '05},
  title = {{DynAlloy: Upgrading Alloy with Actions}},
  year = {2005}
}

@inproceedings{furr:pldi:2005,
  abstract = {We present a multi-lingual type inference system for checking type safety across a foreign function interface. The goal of our system is to prevent foreign function calls from introducing type and memory safety violations into an otherwise safe language. Our system targets OCaml's FFI to C, which is relatively lightweight and illustrates some interesting challenges in multi-lingual type inference. The type language in our system embeds OCaml types in C types and vice-versa, which allows us to track type information accurately even through the foreign language, where the original types are lost. Our system uses representational types that can model multiple OCaml types, because C programs can observe that many OCaml types have the same physical representation. Furthermore, because C has a low-level view of OCaml data, our inference system includes a dataflow analysis to track memory offsets and tag information. Finally, our type system includes garbage collection information to ensure that pointers from the FFI to the OCaml heap are tracked properly. We have implemented our inference system and applied it to a small set of benchmarks. Our results show that programmers do misuse these interfaces, and our implementation has found several bugs and questionable coding practices in our benchmarks.},
  address = {New York, NY, USA},
  author = {Michael Furr and Jeffrey S. Foster},
  booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/1065010.1065019},
  isbn = {1595930566},
  keywords = {OCaml, multi-lingual type inference, foreign function calls, representational type, flow-sensitive type system, FFI, multi-lingual type system, dataflow analysis, foreign function interface},
  link = {https://doi.org/10.1145/1065010.1065019},
  location = {Chicago, IL, USA},
  numpages = {11},
  pages = {62-72},
  publisher = {Association for Computing Machinery},
  series = {PLDI '05},
  title = {{Checking type safety of foreign function calls}},
  url = {https://doi.org/10.1145/1065010.1065019},
  year = {2005}
}

@inproceedings{fuxman:isre:2001,
  author = {Ariel Fuxman and Marco Pistore and John Mylopoulos and Paolo Traverso},
  booktitle = {Requirements Engineering, 2001. Proceedings. Fifth IEEE International Symposium on},
  doi = {10.1109/ISRE.2001.948557},
  organization = {IEEE},
  pages = {174-181},
  title = {{Model checking early requirements specifications in Tropos}},
  year = {2001}
}

@misc{galea:arxiv:2018,
  archiveprefix = {arXiv},
  author = {John Galea and Sean Heelan and Daniel Neville and Daniel Kroening},
  eprint = {1805.03450},
  primaryclass = {cs.SE},
  title = {{Evaluating manual intervention to address the challenges of bug finding with KLEE}},
  year = {2018}
}

@inproceedings{garg:icse:2013,
  abstract = {In industry, software testing and coverage-based metrics are the predominant techniques to check correctness of software. This paper addresses automatic unit test generation for programs written in C/C++. The main idea is to improve the coverage obtained by feedback-directed random test generation methods, by utilizing concolic execution on the generated test drivers. Furthermore, for programs with numeric computations, we employ non-linear solvers in a lazy manner to generate new test inputs. These techniques significantly improve the coverage provided by a feedback-directed random unit testing framework, while retaining the benefits of full automation. We have implemented these techniques in a prototype platform, and describe promising experimental results on a number of C/C++ open source benchmarks.},
  author = {Pranav Garg and Franjo Ivančić and Gogul Balakrishnan and Naoto Maeda and Aarti Gupta},
  booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
  doi = {10.1109/ICSE.2013.6606559},
  isbn = {9781467330763},
  location = {San Francisco, CA, USA},
  numpages = {10},
  pages = {132-141},
  publisher = {IEEE Press},
  series = {ICSE '13},
  title = {{Feedback-directed unit test generation for C/C++ using concolic execution}},
  year = {2013}
}

@inproceedings{gay:pldi:2003,
  acmid = {781133},
  address = {New York, NY, USA},
  author = {David Gay and Philip Levis and Robert von Behren and Matt Welsh and Eric Brewer and David Culler},
  booktitle = {Proceedings of the ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation},
  doi = {10.1145/781131.781133},
  isbn = {1-58113-662-5},
  keywords = {C, TinyOS, components, concurrency, data races, first-order, modules, nesC, programming languages},
  location = {San Diego, California, USA},
  numpages = {11},
  pages = {1-11},
  publisher = {ACM},
  series = {PLDI '03},
  title = {{The nesC language: A holistic approach to networked embedded systems}},
  year = {2003}
}

@article{ge:jce:2016,
  author = {Qian Ge and Yuval Yarom and David Cock and Gernot Heiser},
  doi = {10.1007/s13389-016-0141-6},
  journal = {Journal of Cryptographic Engineering},
  pages = {1-27},
  publisher = {Springer},
  title = {{A survey of microarchitectural timing attacks and countermeasures on contemporary hardware}},
  year = {2016}
}

@inproceedings{gennari:vstte:2018,
  abstract = {Counterexamples--execution traces of the system that illustrate how an error state can be reached from the initial state--are essential for understanding verification failures. They are one of the most salient features of Model Checkers, which distinguish them from Abstract Interpretation and other Static Analysis techniques by providing a user with information on how to debug their system and/or the specification. While in Hardware and Protocol verification, the counterexamples can be replayed in the system, in Software Model Checking (SMC) counterexamples take the form of a textual or semi-structured report. This is problematic since it complicates the debugging process by preventing developers from using existing processes and tools such as debuggers, fault localization, and fault minimization.},
  address = {Cham},
  author = {Jeffrey Gennari and Arie Gurfinkel and Temesghen Kahsai and Jorge A. Navas and Edward J. Schwartz},
  booktitle = {Verified Software. Theories, Tools, and Experiments},
  editor = {Piskac, Ruzica and Rümmer, Philipp},
  isbn = {978-3-030-03592-1},
  pages = {17-37},
  publisher = {Springer International Publishing},
  title = {{Executable counterexamples in software model checking}},
  year = {2018}
}

@article{godefroid:acmq:2012,
  acmid = {2094081},
  address = {New York, NY, USA},
  articleno = {20},
  author = {Patrice Godefroid and Michael Y. Levin and David Molnar},
  doi = {10.1145/2090147.2094081},
  issn = {1542-7730},
  issue_date = {January 2012},
  journal = {ACM Queue},
  month = {January},
  number = {1},
  numpages = {8},
  pages = {20:20-20:27},
  publisher = {ACM},
  title = {{SAGE: Whitebox fuzzing for security testing}},
  volume = {10},
  year = {2012}
}

@inproceedings{godefroid:bugs:2005,
  author = {Patrice Godefroid},
  booktitle = {Proceedings of BUGS 2005 (PLDI 2005 Workshop on the Evaluation of Software Defect Detection Tools)},
  location = {Chicago, IL, USA},
  month = {June},
  title = {{The soundness of bugs is what matters (position statement)}},
  url = {https://patricegodefroid.github.io/public_psfiles/bugs2005.pdf},
  url2 = {http://www.cs.umd.edu/~pugh/SoftwareDefectWorkshop05/BugWorkshop05.pdf},
  year = {2005}
}

@article{godefroid:cacm:2020,
  address = {New York, NY, USA},
  author = {Patrice Godefroid},
  doi = {10.1145/3363824},
  issn = {0001-0782},
  issue_date = {February 2020},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/3363824},
  month = {January},
  number = {2},
  numpages = {7},
  pages = {70-76},
  publisher = {Association for Computing Machinery},
  title = {{Fuzzing: Hack, art, and science}},
  url = {https://doi.org/10.1145/3363824},
  volume = {63},
  year = {2020}
}

@inproceedings{godefroid:icse:2014,
  abstract = {Micro execution is the ability to execute any code fragment without a user-provided test driver or input data. The user simply identifies a function or code location in an exe or dll. A runtime Virtual Machine (VM) customized for testing purposes then starts executing the code at that location, catches all memory operations before they occur, allocates memory on-the-fly in order to perform those read/write memory operations, and provides input values according to a customizable memory policy, which defines what read memory accesses should be treated as inputs. MicroX is a first prototype VM allowing micro execution of x86 binary code. No test driver, no input data, no source code, no debug symbols are required: MicroX automatically discovers dynamically the Input/Output interface of the code being run. Input values are provided as needed along the execution and can be generated in various ways, e.g., randomly or using some other test-generation tool. To our knowledge, MicroX is the first VM designed for test isolation and generation purposes. This paper introduces micro execution and discusses how to implement it, strengths and limitations, applications, related work and long-term goals.},
  address = {New York, NY, USA},
  author = {Patrice Godefroid},
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  doi = {10.1145/2568225.2568273},
  isbn = {9781450327565},
  keywords = {Virtual Machine, Program Execution, Testing},
  link = {https://doi.org/10.1145/2568225.2568273},
  location = {Hyderabad, India},
  numpages = {11},
  pages = {539-549},
  publisher = {Association for Computing Machinery},
  series = {ICSE 2014},
  title = {{Micro execution}},
  url = {https://doi.org/10.1145/2568225.2568273},
  year = {2014}
}

@inproceedings{godefroid:pldi:2005,
  address = {New York, NY, USA},
  author = {Patrice Godefroid and Nils Klarlund and Koushik Sen},
  booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/1065010.1065036},
  isbn = {1595930566},
  keywords = {interfaces, program verification, random testing, software testing, automated test generation},
  link = {https://doi.org/10.1145/1065010.1065036},
  location = {Chicago, IL, USA},
  numpages = {11},
  pages = {213-223},
  publisher = {Association for Computing Machinery},
  series = {PLDI '05},
  title = {{DART: Directed automated random testing}},
  url = {https://doi.org/10.1145/1065010.1065036},
  year = {2005}
}

@inproceedings{godefroid:pldi:2012,
  acmid = {2254116},
  address = {New York, NY, USA},
  author = {Patrice Godefroid and Ankur Taly},
  booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2254064.2254116},
  isbn = {978-1-4503-1205-9},
  keywords = {program synthesis, symbolic execution, x86},
  location = {Beijing, China},
  numpages = {12},
  pages = {441-452},
  publisher = {ACM},
  series = {PLDI '12},
  title = {{Automated synthesis of symbolic instruction encodings from I/O samples}},
  year = {2012}
}

@inproceedings{godefroid:popl:2010,
  abstract = {Program analysis tools typically compute two types of information: (1) may information that is true of all program executions and is used to prove the absence of bugs in the program, and (2) must information that is true of some program executions and is used to prove the existence of bugs in the program. In this paper, we propose a new algorithm, dubbed SMASH, which computes both may and must information compositionally . At each procedure boundary, may and must information is represented and stored as may and must summaries, respectively. Those summaries are computed in a demand driven manner and possibly using summaries of the opposite type. We have implemented SMASH using predicate abstraction (as in SLAM) for the may part and using dynamic test generation (as in DART) for the must part. Results of experiments with 69 Microsoft Windows 7 device drivers show that SMASH can significantly outperform may-only, must-only and non-compositional may-must algorithms. Indeed, our empirical results indicate that most complex code fragments in large programs are actually often either easy to prove irrelevant to the specific property of interest using may analysis or easy to traverse using directed testing. The fine-grained coupling and alternation of may (universal) and must (existential) summaries allows SMASH to easily navigate through these code fragments while traditional may-only, must-only or non-compositional may-must algorithms are stuck in their specific analyses.},
  address = {New York, NY, USA},
  author = {Patrice Godefroid and Aditya V. Nori and Sriram K. Rajamani and Sai Deep Tetali},
  booktitle = {Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/1706299.1706307},
  isbn = {9781605584799},
  keywords = {software model checking, directed testing, abstraction refinement},
  link = {https://doi.org/10.1145/1706299.1706307},
  location = {Madrid, Spain},
  numpages = {14},
  pages = {43-56},
  publisher = {Association for Computing Machinery},
  series = {POPL '10},
  title = {{Compositional may-must program analysis: Unleashing the power of alternation}},
  url = {https://doi.org/10.1145/1706299.1706307},
  year = {2010}
}

@inproceedings{goel:acl2:2013,
  author = {Shilpi Goel and Warren A. Hunt Jr. and Matt Kaufmann},
  booktitle = {Proceedings of the ACL2 Workshop 2013, EPTCS 114},
  doi = {10.4204/EPTCS.114.5},
  pages = {54-69},
  title = {{Abstract stobjs and their application to ISA modeling}},
  year = {2013}
}

@inproceedings{goel:fmcad:2014,
  author = {Shilpi Goel and Warren A. Hunt Jr. and Matt Kaufmann and Soumava Ghosh},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/fmcad/GoelHKG14},
  booktitle = {Formal Methods in Computer-Aided Design, FMCAD},
  doi = {10.1109/FMCAD.2014.6987600},
  pages = {91-98},
  timestamp = {Thu, 08 Jan 2015 12:08:58 +0100},
  title = {{Simulation and formal verification of x86 machine-code programs that make system calls}},
  year = {2014}
}

@inbook{goel:pcs:2017,
  abstract = {Construction of a formal model of a computing system is a necessary practice in formal verification. The results of formal analysis can only be valued to the same degree as the model itself. Model development is error-prone, not only due to the complexity of the system being modeled, but also because it involves addressing disparate requirements. For example, a formal model should be defined using simple constructs to enable efficient reasoning but it should also be optimized to offer fast concrete simulations. Models of large computing systems are themselves large software systems and must be subject to rigorous validation. We describe our formal, executable model of the x86 instruction-set architecture; we use our model to reason about x86 machine-code programs. Validation of our x86 ISA model is done by co-simulating it regularly against a physical x86 machine. We present design decisions made during model development to optimize both validation and verification, i.e., efficiency of both simulation and reasoning. Our engineering process provides insight into the development of a software verification and model animation framework from the points of view of accuracy, efficiency, scalability, maintainability, and usability.},
  address = {Cham},
  author = {Shilpi Goel and Warren A. Hunt Jr. and Matt Kaufmann},
  booktitle = {Provably Correct Systems},
  doi = {10.1007/978-3-319-48628-4_8},
  isbn = {978-3-319-48628-4},
  pages = {173-209},
  publisher = {Springer International Publishing},
  title = {{Engineering a formal, executable x86 ISA simulator for software verification}},
  year = {2017}
}

@phdthesis{goel:phd:2016,
  author = {Shilpi Goel},
  link = {http://www.cs.utexas.edu/users/shigoel/x86isaInfo/Shilpi-Goel-Dissertation.pdf},
  month = {December},
  school = {University of Texas at Austin},
  title = {{Formal verification of application and system programs based on a validated x86 ISA model}},
  url = {http://www.cs.utexas.edu/users/shigoel/x86isaInfo/Shilpi-Goel-Dissertation.pdf},
  year = {2016}
}

@inproceedings{goguen:secpriv:1982,
  author = {Joseph A. Goguen and José Meseguer},
  booktitle = {1982 IEEE Symposium on Security and Privacy},
  doi = {10.1109/SP.1982.10014},
  organization = {IEEE},
  pages = {11-11},
  title = {{Security policies and security models}},
  year = {1982}
}

@inproceedings{goguen:secpriv:1984,
  author = {Joseph A. Goguen and José Meseguer},
  booktitle = {1984 IEEE Symposium on Security and Privacy},
  doi = {10.1109/SP.1984.10019},
  organization = {IEEE},
  pages = {75-75},
  title = {{Unwinding and inference control}},
  year = {1984}
}

@inproceedings{goodman:ndss:2018,
  author = {Peter Goodman and Alex Groce},
  booktitle = {NDSS Workshop on Binary Analysis Research},
  day = {18},
  doi = {10.14722/bar.2018.23009},
  location = {San Diego, California, USA},
  month = {February},
  pages = {7},
  title = {{DeepState: Symbolic unit testing for C and C++}},
  year = {2018}
}

@inproceedings{gordon:asplos:2002,
  author = {Michael I. Gordon and William Thies and Michal Karczmarek and Jasper Lin and Ali S. Meli and Andrew A. Lamb and Chris Leger and Jeremy Wong and Henry Hoffmann and David Maze and Saman P. Amarasinghe},
  booktitle = {Proceedings Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/605397.605428},
  isbn = {1-58113-574-2},
  pages = {291-303},
  title = {{A stream compiler for communication-exposed architectures}},
  year = {2002}
}

@book{gordon:book:1993,
  address = {New York, NY, USA},
  editor = {Gordon, M. J. C. and Melham, T. F.},
  isbn = {0-521-44189-7},
  publisher = {Cambridge University Press},
  title = {{Introduction to HOL: A Theorem Proving Environment for Higher Order Logic}},
  year = {1993}
}

@mastersthesis{gorse:msc:2020,
  author = {Lorenz Gorse},
  location = {Zürich},
  month = {October},
  school = {Programming Methodology Group, Institute for Programming Languages and Systems, ETH Zürich},
  title = {{Extended support for borrowing and lifetimes in Prusti}},
  year = {2020}
}

@inproceedings{gray:micro:2015,
  author = {Kathryn E. Gray and Gabriel Kerneis and Dominic P. Mulligan and Christopher Pulte and Susmit Sarkar and Peter Sewell},
  booktitle = {MICRO 2015: Proceedings of the 48th International Symposium on Microarchitecture (MICRO 2015)},
  doi = {10.1145/2830772.2830775},
  location = {Waikiki, Hawaii, USA},
  month = {December},
  pages = {635-646},
  title = {{An integrated concurrency and core-ISA architectural envelope definition, and test oracle, for IBM POWER multiprocessors}},
  year = {2015}
}

@inproceedings{green:pandc:1990,
  address = {USA},
  author = {Thomas R. G. Green},
  booktitle = {Proceedings of the Fifth Conference of the British Computer Society, Human-Computer Interaction Specialist Group on People and Computers V},
  isbn = {0521384303},
  location = {Univ. of Nottingham},
  numpages = {18},
  pages = {443-460},
  publisher = {Cambridge University Press},
  title = {{Cognitive dimensions of notations}},
  year = {1990}
}

@inproceedings{green:tutorial:1998,
  author = {Thomas R. G. Green and Alan F. Blackwell},
  booktitle = {BCS HCI Conference},
  pages = {1-75},
  title = {{Cognitive dimensions of information artefacts: a tutorial}},
  volume = {98},
  year = {1998}
}

@inbook{greve:fmcad:1998,
  abstract = {Symbolic simulation is the simulation of the execution of a computer system on an incompletely defined, or symbolic, state. This process results in a set of expressions that define the final machine state symbolically in terms of the initial machine state. We describe our use of symbolic simulation in conjunction with the development of the JEM1, the world's first Java processor. We demonstrate that symbolic simulation can be used to detect microcode design errors and that it can be integrated into our current design process.},
  address = {Berlin, Heidelberg},
  author = {David A. Greve},
  booktitle = {Formal Methods in Computer-Aided Design: Second International Conference, FMCAD' 98 Palo Alto, CA, USA, November 4-6, 1998 Proceedings},
  doi = {10.1007/3-540-49519-3_21},
  isbn = {978-3-540-49519-2},
  pages = {321-333},
  publisher = {Springer},
  title = {{Symbolic simulation of the JEM1 microprocessor}},
  year = {1998}
}

@inproceedings{groce:issta:2012,
  abstract = {Swarm testing is a novel and inexpensive way to improve the diversity of test cases generated during random testing. Increased diversity leads to improved coverage and fault detection. In swarm testing, the usual practice of potentially including all features in every test case is abandoned. Rather, a large "swarm" of randomly generated configurations, each of which omits some features, is used, with configurations receiving equal resources. We have identified two mechanisms by which feature omission leads to better exploration of a system's state space. First, some features actively prevent the system from executing interesting behaviors; e.g., "pop" calls may prevent a stack data structure from executing a bug in its overflow detection logic. Second, even when there is no active suppression of behaviors, test features compete for space in each test, limiting the depth to which logic driven by features can be explored. Experimental results show that swarm testing increases coverage and can improve fault detection dramatically; for example, in a week of testing it found 42\% more distinct ways to crash a collection of C compilers than did the heavily hand-tuned default configuration of a random tester.},
  address = {New York, NY, USA},
  author = {Alex Groce and Chaoqiang Zhang and Eric Eide and Yang Chen and John Regehr},
  booktitle = {Proceedings of the 2012 International Symposium on Software Testing and Analysis},
  doi = {10.1145/2338965.2336763},
  isbn = {9781450314541},
  link = {https://doi.org/10.1145/2338965.2336763},
  location = {Minneapolis, MN, USA},
  numpages = {11},
  pages = {78-88},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2012},
  title = {{Swarm testing}},
  url = {https://doi.org/10.1145/2338965.2336763},
  year = {2012}
}

@inproceedings{groce:issta:2017,
  address = {New York, NY, USA},
  author = {Alex Groce and Josie Holmes and Kevin Kellar},
  booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  doi = {10.1145/3092703.3092704},
  isbn = {9781450350761},
  keywords = {test case reduction, semantic simplification, fuzzer taming},
  link = {https://doi.org/10.1145/3092703.3092704},
  location = {Santa Barbara, CA, USA},
  numpages = {11},
  pages = {1-11},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2017},
  title = {{One test to rule them all}},
  url = {https://doi.org/10.1145/3092703.3092704},
  year = {2017}
}

@article{gross:micro:2016,
  author = {Thomas R. Gross and Norman P. Jouppi and John L. Hennessy and Steven Przybylski and Christopher Rowen},
  doi = {10.1109/MM.2016.66},
  issn = {0272-1732},
  journal = {IEEE Micro},
  month = {July},
  number = {4},
  pages = {70-85},
  title = {{A retrospective on `MIPS: A microprocessor architecture'}},
  volume = {36},
  year = {2016}
}

@inproceedings{grossman:esop:2002,
  abstract = {We integrate existential types into a strongly typed C-like language. In particular, we show how a bad combination of existential types, mutation, and aliasing can cause a subtle violation of type safety. We explore two independent ways to strengthen the type system to restore safety. One restricts the mutation of existential packages. The other restricts the types of aliases of existential packages. We use our framework to explain why other languages with existential types are safe.},
  address = {Berlin, Heidelberg},
  author = {Dan Grossman},
  booktitle = {Programming Languages and Systems},
  doi = {10.1007/3-540-45927-8_3},
  editor = {Le Métayer, Daniel},
  isbn = {978-3-540-45927-9},
  pages = {21-35},
  publisher = {Springer Berlin Heidelberg},
  title = {{Existential types for imperative languages}},
  year = {2002}
}

@inproceedings{grossman:pldi:2002,
  abstract = {Cyclone is a type-safe programming language derived from C. The primary design goal of Cyclone is to let programmers control data representation and memory management without sacrificing type-safety. In this paper, we focus on the region-based memory management of Cyclone and its static typing discipline. The design incorporates several advancements, including support for region subtyping and a coherent integration with stack allocation and a garbage collector. To support separate compilation, Cyclone requires programmers to write some explicit region annotations, but a combination of default annotations, local type inference, and a novel treatment of region effects reduces this burden. As a result, we integrate C idioms in a region-based framework. In our experience, porting legacy C to Cyclone has required altering about 8\% of the code; of the changes, only 6\% (of the 8\%) were region annotations.},
  address = {New York, NY, USA},
  author = {Dan Grossman and Greg Morrisett and Trevor Jim and Michael Hicks and Yanling Wang and James Cheney},
  booktitle = {Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation},
  doi = {10.1145/512529.512563},
  isbn = {1581134630},
  link = {https://doi.org/10.1145/512529.512563},
  location = {Berlin, Germany},
  numpages = {12},
  pages = {282-293},
  publisher = {Association for Computing Machinery},
  series = {PLDI '02},
  title = {{Region-based memory management in Cyclone}},
  url = {https://doi.org/10.1145/512529.512563},
  year = {2002}
}

@inproceedings{gu:osdi:2016,
  author = {Ronghui Gu and Zhong Shao and Hao Chen and Xiongnan Newman Wu and Jieung Kim and Vilhelm Sjöberg and David Costanzo},
  booktitle = {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
  pages = {653-669},
  title = {{CertiKOS: An extensible architecture for building certified concurrent OS Kernels}},
  year = {2016}
}

@inproceedings{guanciale:ccs:2020,
  abstract = {The recent Spectre attacks have demonstrated the fundamental insecurity of current computer microarchitecture. The attacks use features like pipelining, out-of-order and speculation to extract arbitrary information about the memory contents of a process. A comprehensive formal microarchitectural model capable of representing the forms of out-of-order and speculative behavior that can meaningfully be implemented in a high performance pipelined architecture has not yet emerged. Such a model would be very useful, as it would allow the existence and non-existence of vulnerabilities, and soundness of countermeasures to be formally established. This paper presents such a model targeting single core processors. The model is intentionally very general and provides an infrastructure to define models of real CPUs. It incorporates microarchitectural features that underpin all known Spectre vulnerabilities. We use the model to elucidate the security of existing and new vulnerabilities, as well as to formally analyze the effectiveness of proposed countermeasures. Specifically, we discover three new (potential) vulnerabilities, including a new variant of Spectre v4, a vulnerability on speculative fetching, and a vulnerability on out-of-order execution, and analyze the effectiveness of existing countermeasures including constant time and serializing instructions.},
  address = {New York, NY, USA},
  author = {Roberto Guanciale and Musard Balliu and Mads Dam},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  doi = {10.1145/3372297.3417246},
  isbn = {9781450370899},
  keywords = {countermeasures, out-of-order, speculation, vulnerabilities, microarchitecture, verification, formal models},
  link = {https://doi.org/10.1145/3372297.3417246},
  location = {Virtual Event, USA},
  numpages = {17},
  pages = {1853-1869},
  publisher = {Association for Computing Machinery},
  series = {CCS '20},
  title = {{InSpectre: Breaking and fixing microarchitectural vulnerabilities by formal analysis}},
  url = {https://doi.org/10.1145/3372297.3417246},
  year = {2020}
}

@inproceedings{guarnieri:sandp:2020,
  address = {Los Alamitos, CA, USA},
  author = {Marco Guarnieri and Boris Köpf and José F. Morales and Jan Reineke and Andrés Sánchez},
  booktitle = {2020 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP40000.2020.00011},
  issn = {},
  keywords = {semantics;security;microarchitecture;registers;standards;syntactics;optimization},
  link = {https://doi.ieeecomputersociety.org/10.1109/SP40000.2020.00011},
  month = {may},
  pages = {1-19},
  publisher = {IEEE Computer Society},
  title = {{Spectector: Principled detection of speculative information flows}},
  url = {https://doi.ieeecomputersociety.org/10.1109/SP40000.2020.00011},
  volume = {},
  year = {2020}
}

@inproceedings{gurfinkel:cav:2015,
  abstract = {In this paper, we present SeaHorn, a software verification framework. The key distinguishing feature of SeaHorn is its modular design that separates the concerns of the syntax of the programming language, its operational semantics, and the verification semantics. SeaHorn encompasses several novelties: it (a) encodes verification conditions using an efficient yet precise inter-procedural technique, (b) provides flexibility in the verification semantics to allow different levels of precision, (c) leverages the state-of-the-art in software model checking and abstract interpretation for verification, and (d) uses Horn-clauses as an intermediate language to represent verification conditions which simplifies interfacing with multiple verification tools based on Horn-clauses. SeaHorn provides users with a powerful verification tool and researchers with an extensible and customizable framework for experimenting with new software verification techniques. The effectiveness and scalability of SeaHorn are demonstrated by an extensive experimental evaluation using benchmarks from SV-COMP 2015 and real avionics code.},
  address = {Cham},
  author = {Arie Gurfinkel and Temesghen Kahsai and Anvesh Komuravelli and Jorge A. Navas},
  booktitle = {Computer Aided Verification},
  doi = {10.1007/978-3-319-21690-4_20},
  editor = {Kroening, Daniel and Păsăreanu, Corina S.},
  isbn = {978-3-319-21690-4},
  pages = {343-361},
  publisher = {Springer International Publishing},
  title = {{The SeaHorn verification framework}},
  year = {2015}
}

@inproceedings{gurfinkel:fmcad:2017,
  abstract = {We present a flexible algorithmic framework KIC3 that combines IC3 and k-induction. The key underlying observation is that k-induction can be easily simulated by existing IC3 implementations by following a slightly different counterexample-queue management strategy.},
  address = {Austin, Texas},
  author = {Arie Gurfinkel and Alexander Ivrii},
  booktitle = {Proceedings of the 17th Conference on Formal Methods in Computer-Aided Design},
  isbn = {9780983567875},
  location = {Vienna, Austria},
  numpages = {8},
  pages = {148-155},
  publisher = {FMCAD Inc},
  series = {FMCAD '17},
  title = {{K-induction without unrolling}},
  year = {2017}
}

@inproceedings{guyer:dsl:1999,
  acmid = {1267940},
  address = {Berkeley, CA, USA},
  author = {Samuel Z. Guyer and Calvin Lin},
  booktitle = {Proceedings of the 2nd Conference on Domain-Specific Languages - Volume 2},
  doi = {10.1007/3-540-45574-4_15},
  location = {Austin, Texas},
  publisher = {USENIX Association},
  series = {DSL'99},
  title = {{An annotation language for optimizing software libraries}},
  year = {1999}
}

@inproceedings{hardin:acl2:2006,
  acmid = {1217978},
  address = {New York, NY, USA},
  author = {David S. Hardin and Eric W. Smith and William D. Young},
  booktitle = {Proceedings of the Sixth International Workshop on the ACL2 Theorem Prover and Its Applications},
  doi = {10.1145/1217975.1217978},
  isbn = {0-9788493-0-2},
  keywords = {ACL2, certification, cryptography, high-assurance, processor modeling, symbolic simulation, theorem proving},
  location = {Seattle, Washington, USA},
  numpages = {10},
  pages = {11-20},
  publisher = {ACM},
  series = {ACL2 '06},
  title = {{A robust machine code proof framework for highly secure applications}},
  year = {2006}
}

@article{hatcliff:compsurv:2012,
  address = {New York, NY, USA},
  articleno = {Article 16},
  author = {John Hatcliff and Gary T. Leavens and K. Rustan M. Leino and Peter Müller and Matthew Parkinson},
  doi = {10.1145/2187671.2187678},
  issn = {0360-0300},
  issue_date = {June 2012},
  journal = {ACM Computing Surveys},
  keywords = {postcondition, frame conditions, SPARK, assertion, separation logic, invariant, JML, interface specification language, precondition, Spec\#, behavioral subtyping, Abstraction},
  month = {June},
  number = {3},
  numpages = {58},
  publisher = {Association for Computing Machinery},
  title = {{Behavioral interface specification languages}},
  url = {https://doi.org/10.1145/2187671.2187678},
  volume = {44},
  year = {2012}
}

@inproceedings{hawblitzel:osdi:2014,
  author = {Chris Hawblitzel and Jon Howell and Jacob R. Lorch and Arjun Narayan and Bryan Parno and Danfeng Zhang and Brian Zill},
  booktitle = {11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 14)},
  pages = {165-181},
  title = {{Ironclad apps: End-to-end security via automated full-system verification}},
  year = {2014}
}

@mastersthesis{heelan:msc:2009,
  author = {Sean Heelan},
  location = {Oxford, England},
  month = {September},
  school = {Computing Laboratory, University of Oxford},
  title = {{Automatic generation of control flow hijacking exploits for software vulnerabilities}},
  year = {2009}
}

@inproceedings{heelan:sec:2018,
  address = {Baltimore, MD},
  author = {Sean Heelan and Tom Melham and Daniel Kroening},
  booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
  isbn = {978-1-939133-04-5},
  link = {https://www.usenix.org/conference/usenixsecurity18/presentation/heelan},
  month = {August},
  pages = {763-779},
  publisher = {USENIX Association},
  title = {{Automatic heap layout manipulation for exploitation}},
  url = {https://www.usenix.org/conference/usenixsecurity18/presentation/heelan},
  year = {2018}
}

@inbook{hehner:vstte:2008,
  abstract = {This paper argues that specified blocks have every advantage over the combination of assertions, preconditions, postconditions, invariants, and variants, both for verifying programs, and for program development. They are simpler, more general, easier to write, and they make proofs easier.},
  address = {Berlin, Heidelberg},
  author = {Eric C. R. Hehner},
  booktitle = {Verified Software: Theories, Tools, Experiments: First IFIP TC 2/WG 2.3 Conference, VSTTE 2005, Zurich, Switzerland, October 10-13, 2005, Revised Selected Papers and Discussions},
  doi = {10.1007/978-3-540-69149-5\_41},
  editor = {Meyer, Bertrand and Woodcock, Jim},
  isbn = {978-3-540-69149-5},
  pages = {384-391},
  publisher = {Springer Berlin Heidelberg},
  title = {{Specified blocks}},
  url = {https://doi.org/10.1007/978-3-540-69149-5\_41},
  year = {2008}
}

@book{hennessy:book:2011,
  address = {San Francisco, CA, USA},
  author = {John L. Hennessy and David A. Patterson},
  edition = {5th},
  isbn = {012383872X, 9780123838728},
  publisher = {Morgan Kaufmann Publishers Inc.},
  title = {{Computer architecture: A quantitative approach (Fifth edition)}},
  year = {2011}
}

@inproceedings{hennessy:micro:1982,
  acmid = {800930},
  address = {Piscataway, NJ, USA},
  author = {John L. Hennessy and Norman P. Jouppi and Steven Przybylski and Christopher Rowen and Thomas R. Gross and Forest Baskett and John Gill},
  booktitle = {Proceedings of the 15th Annual Workshop on Microprogramming},
  doi = {10.1145/1014194.800930},
  location = {Palo Alto, California, USA},
  numpages = {6},
  pages = {17-22},
  publisher = {IEEE Press},
  series = {MICRO 15},
  title = {{MIPS: A microprocessor architecture}},
  year = {1982}
}

@inproceedings{henzinger:spin:2003,
  abstract = {Blast (the Berkeley Lazy Abstraction Software verification Tool) is a verification system for checking safety properties of C programs using automatic property-driven construction and model checking of software abstractions. Blast implements an abstract-model check-refine loop to check for reachability of a specified label in the program. The abstract model is built on the fly using predicate abstraction. This model is then checked for reachability. If there is no (abstract) path to the specified error label, Blast reports that the system is safe and produces a succinct proof. Otherwise, it checks if the path is feasible using symbolic execution of the program. If the path is feasible, Blast outputs the path as an error trace, otherwise, it uses the infeasibility of the path to refine the abstract model. Blast short-circuits the loop from abstraction to verification to refinement, integrating the three steps tightly through ``lazy abstraction'' [5]. This integration can offer significant advantages in performance by avoiding the repetition of work from one iteration of the loop to the next.},
  address = {Berlin, Heidelberg},
  author = {Thomas A. Henzinger and Ranjit Jhala and Rupak Majumdar and Grégoire Sutre},
  booktitle = {Model Checking Software},
  doi = {10.1007/3-540-44829-2_17},
  editor = {Ball, Thomas and Rajamani, Sriram K.},
  isbn = {978-3-540-44829-7},
  pages = {235-239},
  publisher = {Springer Berlin Heidelberg},
  title = {{Software verification with BLAST}},
  year = {2003}
}

@inproceedings{hertz:oopsla:2005,
  abstract = {Garbage collection yields numerous software engineering benefits, but its quantitative impact on performance remains elusive. One can compare the cost of conservative garbage collection to explicit memory management in C/C++ programs by linking in an appropriate collector. This kind of direct comparison is not possible for languages designed for garbage collection (e.g., Java), because programs in these languages naturally do not contain calls to free. Thus, the actual gap between the time and space performance of explicit memory management and precise, copying garbage collection remains unknown.We introduce a novel experimental methodology that lets us quantify the performance of precise garbage collection versus explicit memory management. Our system allows us to treat unaltered Java programs as if they used explicit memory management by relying on oracles to insert calls to free. These oracles are generated from profile information gathered in earlier application runs. By executing inside an architecturally-detailed simulator, this "oracular" memory manager eliminates the effects of consulting an oracle while measuring the costs of calling malloc and free. We evaluate two different oracles: a liveness-based oracle that aggressively frees objects immediately after their last use, and a reachability-based oracle that conservatively frees objects just after they are last reachable. These oracles span the range of possible placement of explicit deallocation calls.We compare explicit memory management to both copying and non-copying garbage collectors across a range of benchmarks using the oracular memory manager, and present real (non-simulated) runs that lend further validity to our results. These results quantify the time-space tradeoff of garbage collection: with five times as much memory, an Appel-style generational collector with a non-copying mature space matches the performance of reachability-based explicit memory management. With only three times as much memory, the collector runs on average 17\% slower than explicit memory management. However, with only twice as much memory, garbage collection degrades performance by nearly 70\%. When physical memory is scarce, paging causes garbage collection to run an order of magnitude slower than explicit memory management.},
  address = {New York, NY, USA},
  author = {Matthew Hertz and Emery D. Berger},
  booktitle = {Proceedings of the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
  doi = {10.1145/1094811.1094836},
  isbn = {1595930310},
  keywords = {explicit memory management, garbage collection, oracular memory management, performance analysis, paging, throughput, time-space tradeoff},
  link = {https://doi.org/10.1145/1094811.1094836},
  location = {San Diego, CA, USA},
  numpages = {14},
  pages = {313-326},
  publisher = {Association for Computing Machinery},
  series = {OOPSLA '05},
  title = {{Quantifying the performance of garbage collection vs. explicit memory management}},
  url = {https://doi.org/10.1145/1094811.1094836},
  year = {2005}
}

@inproceedings{heule:ftfjp:2011,
  address = {New York, NY, USA},
  articleno = {Article 1},
  author = {Stefan Heule and K. Rustan M. Leino and Peter Müller and Alexander J. Summers},
  booktitle = {Proceedings of the 13th Workshop on Formal Techniques for Java-Like Programs},
  doi = {10.1145/2076674.2076675},
  isbn = {9781450308939},
  keywords = {static verification, concurrency, fractional permissions},
  location = {Lancaster, United Kingdom},
  numpages = {6},
  publisher = {Association for Computing Machinery},
  series = {FTfJP '11},
  title = {{Fractional permissions without the fractions}},
  url = {https://doi.org/10.1145/2076674.2076675},
  year = {2011}
}

@inproceedings{heule:pldi:2016,
  acmid = {2908121},
  address = {New York, NY, USA},
  author = {Stefan Heule and Eric Schkufza and Rahul Sharma and Alex Aiken},
  booktitle = {Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2908080.2908121},
  isbn = {978-1-4503-4261-2},
  keywords = {ISA specification, program synthesis, x86-64},
  location = {Santa Barbara, CA, USA},
  numpages = {14},
  pages = {237-250},
  publisher = {ACM},
  series = {PLDI '16},
  title = {{Stratified synthesis: Automatically learning the x86-64 instruction set}},
  year = {2016}
}

@inproceedings{heule:vmcai:2013,
  abstract = {Fractional Permissions are a popular approach to reasoning about programs that use shared-memory concurrency, because they provide a way of proving data race freedom while permitting concurrent read access. However, specification using fractional permissions typically requires the user to pick concrete mathematical values for partial permissions, making specifications overly low-level, tedious to write, and harder to adapt and re-use. This paper introduces abstract read permissions: a flexible and expressive specification methodology that supports fractional permissions while allowing the user to work at the abstract level of read and write permissions. The methodology is flexible, modular, and sound. It has been implemented in the verification tool Chalice.},
  address = {Berlin, Heidelberg},
  author = {Stefan Heule and K. Rustan M. Leino and Peter Müller and Alexander J. Summers},
  booktitle = {Verification, Model Checking, and Abstract Interpretation},
  doi = {10.1007/978-3-642-35873-9_20},
  editor = {Giacobazzi, Roberto and Berdine, Josh and Mastroeni, Isabella},
  isbn = {978-3-642-35873-9},
  pages = {315-334},
  publisher = {Springer Berlin Heidelberg},
  title = {{Abstract read permissions: Fractional permissions without the fractions}},
  year = {2013}
}

@inproceedings{higgins:hldvt:2004,
  acmid = {1256106},
  address = {Washington, DC, USA},
  author = {J. Thomas Higgins and Mark D. Aagaard},
  booktitle = {Proceedings of the High-Level Design Validation and Test Workshop, 2004. Ninth IEEE International},
  doi = {10.1109/HLDVT.2004.1431229},
  isbn = {0-7803-8714-7},
  numpages = {6},
  pages = {31-36},
  publisher = {IEEE Computer Society},
  series = {HLDVT '04},
  title = {{Simplifying design and verification for structural hazards and datapaths in pipelined circuits}},
  year = {2004}
}

@inproceedings{hobor:popl:2013,
  address = {New York, NY, USA},
  author = {Aquinas Hobor and Jules Villard},
  booktitle = {Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/2429069.2429131},
  isbn = {9781450318327},
  keywords = {modularity, heap/shape, aliasing, separation logic},
  location = {Rome, Italy},
  numpages = {14},
  pages = {523-536},
  publisher = {Association for Computing Machinery},
  series = {POPL '13},
  title = {{The ramifications of sharing in data structures}},
  url = {https://doi.org/10.1145/2429069.2429131},
  year = {2013}
}

@inbook{hochschild:hotos:2021,
  abstract = {We are accustomed to thinking of computers as fail-stop, especially the cores that execute instructions, and most system software implicitly relies on that assumption. During most of the VLSI era, processors that passed manufacturing tests and were operated within specifications have insulated us from this fiction. As fabrication pushes towards smaller feature sizes and more elaborate computational structures, and as increasingly specialized instruction-silicon pairings are introduced to improve performance, we have observed ephemeral computational errors that were not detected during manufacturing tests. These defects cannot always be mitigated by techniques such as microcode updates, and may be correlated to specific components within the processor, allowing small code changes to effect large shifts in reliability. Worse, these failures are often "silent" - the only symptom is an erroneous computation.We refer to a core that develops such behavior as "mercurial." Mercurial cores are extremely rare, but in a large fleet of servers we can observe the disruption they cause, often enough to see them as a distinct problem - one that will require collaboration between hardware designers, processor vendors, and systems software architects.This paper is a call-to-action for a new focus in systems research; we speculate about several software-based approaches to mercurial cores, ranging from better detection and isolating mechanisms, to methods for tolerating the silent data corruption they cause.},
  address = {New York, NY, USA},
  author = {Peter H. Hochschild and Paul Turner and Jeffrey C. Mogul and Rama Govindaraju and Parthasarathy Ranganathan and David E. Culler and Amin Vahdat},
  booktitle = {Proceedings of the Workshop on Hot Topics in Operating Systems},
  isbn = {9781450384384},
  link = {https://doi.org/10.1145/3458336.3465297},
  numpages = {8},
  pages = {9-16},
  publisher = {Association for Computing Machinery},
  title = {{Cores that don't count}},
  url = {https://doi.org/10.1145/3458336.3465297},
  year = {2021}
}

@article{hohmuth:plos:2005,
  author = {Michael Hohmuth and Hendrik Tews},
  journal = {2nd PLOS},
  title = {{The VFiasco approach for a verified operating system}},
  year = {2005}
}

@inproceedings{hohmuth:sigops:2002,
  author = {Michael Hohmuth and Hendrik Tews and Shane G. Stephens},
  booktitle = {Proceedings of the 10th workshop on ACM SIGOPS European workshop},
  doi = {10.1145/1133373.1133405},
  organization = {ACM},
  pages = {165-169},
  title = {{Applying source-code verification to a microkernel: the VFiasco project}},
  year = {2002}
}

@inproceedings{holzer:cav:2008,
  abstract = {Although the principal analogy between counterexample generation and white box testing has been repeatedly addressed, the usage patterns and performance requirements for software testing are quite different from formal verification. Our tool FShell provides a versatile testing environment for C programs which supports both interactive explorative use and a rich scripting language. More than a frontend for software model checkers, FShell is designed as a database engine which dispatches queries about the program to program analysis tools. We report on the integration of CBMC into FShell and describe architectural modifications which support efficient test case generation.},
  address = {Berlin, Heidelberg},
  author = {Andreas Holzer and Christian Schallhart and Michael Tautschnig and Helmut Veith},
  booktitle = {Computer Aided Verification},
  doi = {10.1007/978-3-540-70545-1_20},
  editor = {Gupta, Aarti and Malik, Sharad},
  isbn = {978-3-540-70545-1},
  pages = {209-213},
  publisher = {Springer Berlin Heidelberg},
  title = {{FShell: Systematic test case generation for dynamic analysis and measurement}},
  year = {2008}
}

@inproceedings{holzer:hvc:2010,
  abstract = {In a recent series of papers, we introduced a new framework for white-box testing which aims at a separation of concerns between test specifications and test generation engines. We believe that establishing a common language for test criteria will have similar benefits to testing as temporal logic had to model checking and SQL had to databases. The main challenge was to find a specification language which is expressive, simple, and precise. This paper gives an introduction to the test specification language FQL and its tool environment.},
  address = {Berlin, Heidelberg},
  author = {Andreas Holzer and Michael Tautschnig and Christian Schallhart and Helmut Veith},
  booktitle = {Hardware and Software: Verification and Testing},
  doi = {10.1007/978-3-642-19583-9_5},
  editor = {Barner, Sharon and Harris, Ian and Kroening, Daniel and Raz, Orna},
  isbn = {978-3-642-19583-9},
  pages = {9-22},
  publisher = {Springer Berlin Heidelberg},
  title = {{An introduction to test specification in FQL}},
  year = {2011}
}

@article{holzmann:ieeetse:2011,
  abstract = {The range of verification problems that can be solved with logic model checking tools has increased significantly in the last few decades. This increase in capability is based on algorithmic advances and new theoretical insights, but it has also benefitted from the steady increase in processing speeds and main memory sizes on standard computers. The steady increase in processing speeds, though, ended when chip-makers started redirecting their efforts to the development of multicore systems. For the near-term future, we can anticipate the appearance of systems with large numbers of CPU cores, but without matching increases in clock-speeds. We will describe a model checking strategy that can allow us to leverage this trend and that allows us to tackle significantly larger problem sizes than before.},
  author = {Gerard J. Holzmann and Rajeev Joshi and Alex Groce},
  doi = {10.1109/TSE.2010.110},
  issn = {0098-5589},
  issue_date = {November 2011},
  journal = {IEEE Trans. Softw. Eng.},
  keywords = {distributed algorithms, software verification., logic model checking, Software engineering tools and techniques},
  link = {https://doi.org/10.1109/TSE.2010.110},
  month = {November},
  number = {6},
  numpages = {13},
  pages = {845-857},
  publisher = {IEEE Press},
  title = {{Swarm verification techniques}},
  url = {https://doi.org/10.1109/TSE.2010.110},
  volume = {37},
  year = {2011}
}

@inproceedings{hritcu:icfp:2013,
  acmid = {2500574},
  address = {New York, NY, USA},
  author = {Cătǎlin Hriţcu and John Hughes and Benjamin C. Pierce and Antal Spector-Zabusky and Dimitrios Vytiniotis and Arthur Azevedo de Amorim and Leonidas Lampropoulos},
  booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/2500365.2500574},
  isbn = {978-1-4503-2326-0},
  keywords = {abstract machine, design, dynamic information flow control, noninterference, quickcheck, random testing, security},
  location = {Boston, Massachusetts, USA},
  numpages = {14},
  pages = {455-468},
  publisher = {ACM},
  series = {ICFP'13},
  title = {{Testing noninterference, quickly}},
  url = {http://doi.acm.org/10.1145/2500365.2500574},
  year = {2013}
}

@article{huang:todaes:2019,
  author = {Bo-Yuan Huang and Hongce Zhang and Pramod Subramanyan and Yakir Vizel and Aarti Gupta and Sharad Malik},
  doi = {10.1145/3282444},
  journal = {ACM Transactions on Design Automation of Electronic Systems},
  title = {{Instruction-level abstraction (ILA): A uniform specification for system-on-chip (SoC) verification}},
  year = {2019}
}

@article{hunt:jar:1989,
  acmid = {83476},
  address = {Secaucus, NJ, USA},
  author = {Warren A. Hunt Jr.},
  issn = {0168-7433},
  issue_date = {Dec. 1989},
  journal = {Journal of Automated Reasoning},
  month = {November},
  number = {4},
  numpages = {32},
  pages = {429-460},
  publisher = {Springer-Verlag New York, Inc.},
  title = {{Microprocessor design verification}},
  volume = {5},
  year = {1989}
}

@book{hunt:lncs:1994,
  author = {Warren A. Hunt Jr.},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/books/sp/Hunt94},
  doi = {10.1007/3-540-57960-5},
  isbn = {3-540-57960-5},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  timestamp = {Fri, 24 Jun 2011 20:39:24 +0200},
  title = {{FM8501: A verified microprocessor}},
  volume = {795},
  year = {1994}
}

@article{hunt:micro:1999,
  acmid = {624272},
  address = {Los Alamitos, CA, USA},
  author = {Warren A. Hunt Jr. and Jun Sawada},
  doi = {10.1109/40.768503},
  issn = {0272-1732},
  issue_date = {May 1999},
  journal = {IEEE Micro},
  month = {May},
  number = {3},
  numpages = {9},
  pages = {47-55},
  publisher = {IEEE Computer Society Press},
  title = {{Verifying the FM9801 microarchitecture}},
  volume = {19},
  year = {1999}
}

@inproceedings{ivankovic:fse:2019,
  address = {New York, NY, USA},
  author = {Marko Ivanković and Goran Petrović and René Just and Gordon Fraser},
  booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3338906.3340459},
  isbn = {9781450355728},
  keywords = {test infrastructure, industrial study, coverage},
  link = {https://doi.org/10.1145/3338906.3340459},
  location = {Tallinn, Estonia},
  numpages = {9},
  pages = {955-963},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2019},
  title = {{Code coverage at Google}},
  url = {https://doi.org/10.1145/3338906.3340459},
  year = {2019}
}

@article{jackson:tosem:2002,
  acmid = {505149},
  address = {New York, NY, USA},
  author = {Daniel Jackson},
  doi = {10.1145/505145.505149},
  issn = {1049-331X},
  issue_date = {April 2002},
  journal = {ACM Transactions on Software Engineering and Methodology (TOSEM)},
  keywords = {Object models, Z specification language, first-order logic},
  month = {April},
  number = {2},
  numpages = {35},
  pages = {256-290},
  publisher = {ACM},
  title = {{Alloy: A lightweight object modelling notation}},
  volume = {11},
  year = {2002}
}

@inproceedings{jacobs:nfm:2011,
  author = {Bart Jacobs and Jan Smans and Pieter Philippaerts and Frédéric Vogels and Willem Penninckx and Frank Piessens},
  booktitle = {NASA Formal Methods Symposium},
  doi = {10.1007/978-3-642-20398-5_4},
  organization = {Springer},
  pages = {41-55},
  title = {{VeriFast: A powerful, sound, predictable, fast verifier for C and Java}},
  year = {2011}
}

@inproceedings{jacobs:vstte:2010,
  author = {Bart Jacobs and Jan Smans and Frank Piessens},
  booktitle = {VSTTE workshop on Tools and Experiments},
  title = {{VeriFast: Imperative programs as proofs}},
  year = {2010}
}

@misc{jaffar:arxiv:2020,
  archiveprefix = {arXiv},
  author = {Joxan Jaffar and Rasool Maghareh and Sangharatna Godboley and Xuan-Linh Ha},
  eprint = {2012.00556},
  primaryclass = {cs.PL},
  title = {{TracerX: Dynamic symbolic execution with interpolation}},
  year = {2020}
}

@incollection{jhala:cav:2001,
  author = {Ranjit Jhala and Kenneth L. McMillan},
  booktitle = {Computer Aided Verification},
  doi = {10.1007/3-540-44585-4_40},
  editor = {Berry, Gérard and Comon, Hubert and Finkel, Alain},
  isbn = {978-3-540-42345-4},
  language = {English},
  pages = {396-410},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  title = {{Microarchitecture verification by compositional model checking}},
  volume = {2102},
  year = {2001}
}

@article{jhala:compsurv:2009,
  address = {New York, NY, USA},
  articleno = {21},
  author = {Ranjit Jhala and Rupak Majumdar},
  doi = {10.1145/1592434.1592438},
  issn = {0360-0300},
  issue_date = {October 2009},
  journal = {ACM Computing Surveys},
  keywords = {abstraction, counterexample-guided refinement, liveness, safety, enumerative and symbolic model checking, Software model checking},
  link = {https://doi.org/10.1145/1592434.1592438},
  month = {October},
  number = {4},
  numpages = {54},
  publisher = {Association for Computing Machinery},
  title = {{Software model checking}},
  url = {https://doi.org/10.1145/1592434.1592438},
  volume = {41},
  year = {2009}
}

@article{jia:ieeetse:2010,
  abstract = {Mutation Testing is a fault-based software testing technique that has been widely studied for over three decades. The literature on Mutation Testing has contributed a set of approaches, tools, developments, and empirical results. This paper provides a comprehensive analysis and survey of Mutation Testing. The paper also presents the results of several development trend analyses. These analyses provide evidence that Mutation Testing techniques and tools are reaching a state of maturity and applicability, while the topic of Mutation Testing itself is the subject of increasing interest.},
  author = {Yue Jia and Mark Harman},
  doi = {10.1109/TSE.2010.62},
  issn = {1939-3520},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {fault diagnosis;program testing;mutation testing development;fault-based software testing technique;empirical results;comprehensive analysis;development trend analysis;mutation testing technique;mutation testing tool;Genetic mutations;Software testing;Fault detection;History;Books;Programming profession;Computer languages;Java;Educational institutions;Automata;Mutation testing;survey.},
  month = {Sep.},
  number = {5},
  pages = {649-678},
  title = {{An analysis and survey of the development of mutation testing}},
  volume = {37},
  year = {2011}
}

@misc{jiang:arxiv:2021,
  archiveprefix = {arXiv},
  author = {Muhui Jiang and Tianyi Xu and Yajin Zhou and Yufeng Hu and Ming Zhong and Lei Wu and Xiapu Luo and Kui Ren},
  eprint = {2105.14273},
  primaryclass = {cs.CR},
  title = {{Examiner: Automatically locating inconsistent instructions between real devices and CPU emulators for Arm}},
  year = {2021}
}

@inproceedings{jin:icst:2010,
  abstract = {When a program is modified during software evolution, developers typically run the new version of the program against its existing test suite to validate that the changes made on the program did not introduce unintended side effects (i.e., regression faults). This kind of regression testing can be effective in identifying some regression faults, but it is limited by the quality of the existing test suite. Due to the cost of testing, developers build test suites by finding acceptable tradeoffs between cost and thoroughness of the tests. As a result, these test suites tend to exercise only a small subset of the program's functionality and may be inadequate for testing the changes in a program. To address this issue, we propose a novel approach called Behavioral Regression Testing (BERT). Given two versions of a program, BERT identifies behavioral differences between the two versions through dynamical analysis, in three steps. First, it generates a large number of test inputs that focus on the changed parts of the code. Second, it runs the generated test inputs on the old and new versions of the code and identifies differences in the tests' behavior. Third, it analyzes the identified differences and presents them to the developers. By focusing on a subset of the code and leveraging differential behavior, BERT can provide developers with more (and more detailed) information than traditional regression testing techniques. To evaluate BERT, we implemented it as a plug-in for Eclipse, a popular Integrated Development Environment, and used the plug-in to perform a preliminary study on two programs. The results of our study are promising, in that BERT was able to identify true regression faults in the programs.},
  author = {Wei Jin and Alessandro Orso and Tao Xie},
  booktitle = {2010 Third International Conference on Software Testing, Verification and Validation},
  doi = {10.1109/ICST.2010.64},
  issn = {2159-4848},
  keywords = {},
  month = {April},
  number = {},
  pages = {137-146},
  title = {{Automated behavioral regression testing}},
  volume = {},
  year = {2010}
}

@inproceedings{johnson:icse:2013,
  abstract = {Using static analysis tools for automating code inspections can be beneficial for software engineers. Such tools can make finding bugs, or software defects, faster and cheaper than manual inspections. Despite the benefits of using static analysis tools to find bugs, research suggests that these tools are underused. In this paper, we investigate why developers are not widely using static analysis tools and how current tools could potentially be improved. We conducted interviews with 20 developers and found that although all of our participants felt that use is beneficial, false positives and the way in which the warnings are presented, among other things, are barriers to use. We discuss several implications of these results, such as the need for an interactive mechanism to help developers fix defects.},
  author = {Brittany Johnson and Yoonki Song and Emerson Murphy-Hill and Robert Bowdidge},
  booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
  isbn = {9781467330763},
  location = {San Francisco, CA, USA},
  numpages = {10},
  pages = {672-681},
  publisher = {IEEE Press},
  series = {ICSE '13},
  title = {{Why don't software developers use static analysis tools to find bugs?}},
  year = {2013}
}

@article{johnson:osr:1995,
  acmid = {224073},
  address = {New York, NY, USA},
  author = {Kirk L. Johnson and M. Frans Kaashoek and Deborah A. Wallach},
  doi = {10.1145/224057.224073},
  issn = {0163-5980},
  issue_date = {Dec. 3, 1995},
  journal = {SIGOPS Operating Systems Review},
  month = {December},
  number = {5},
  numpages = {14},
  pages = {213-226},
  publisher = {ACM},
  title = {{CRL: High-performance all-software distributed shared memory}},
  volume = {29},
  year = {1995}
}

@misc{jones:hasklang:1999,
  ar_shortname = {Haskell Report},
  author = {Simon L. Peyton Jones and Lennart Augustsson and Dave Barton and Brian Boutel and Warren Burton and Joseph Fasel and Kevin Hammond and Ralf Hinze and Paul Hudak and John Hughes and Thomas Johnsson and Mark Jones and John Launchbury and Erik Meijer and John Peterson and Alastair D. Reid and Colin Runciman and Philip Wadler},
  link = {https://www.haskell.org/definition/},
  title = {{Haskell 98: A non-strict, purely functional language}},
  url = {https://www.haskell.org/definition/},
  year = {1999}
}

@misc{jones:hasklib:1999,
  ar_shortname = {Haskell Lib},
  author = {Simon L. Peyton Jones and Lennart Augustsson and Dave Barton and Brian Boutel and Warren Burton and Joseph Fasel and Kevin Hammond and Ralf Hinze and Paul Hudak and John Hughes and Thomas Johnsson and Mark Jones and John Launchbury and Erik Meijer and John Peterson and Alastair D. Reid and Colin Runciman and Philip Wadler},
  link = {https://www.haskell.org/definition/},
  title = {{Standard libraries for the Haskell 98 programming language}},
  url = {https://www.haskell.org/definition/},
  year = {1999}
}

@inproceedings{jones:hw:1997,
  affiliation = {Yale University and Oregon Graduate Institute},
  ar_shortname = {Haskell 97},
  author = {Simon L. Peyton Jones and Thomas Nordin and Alastair D. Reid},
  booktitle = {Proceedings of the Haskell Workshop},
  location = {Amsterdam, Netherlands},
  month = {June},
  title = {{Green Card: a foreign-language interface for Haskell}},
  year = {1997}
}

@inproceedings{jones:microsoft:2001,
  abstract = {We describe a facility for improving optimization of Haskell programs using rewrite rules. Library authors can use rules to express domain-specific optimizations that the compiler cannot discover for itself. The compiler can also generate rules internally to propagate information obtained from automated analyses. The rewrite mechanism is fully implemented in the released Glasgow Haskell Compiler.  Our system is very simple, but can be effective in optimizing real programs. We describe two practical applications involving short-cut deforestation, for lists and for rose trees, and document substantial performance improvements on a range of programs.},
  address = {},
  author = {Simon L. Peyton Jones and Andrew Tolmach and C. A. R. Hoare},
  booktitle = {Proceedings of the 2001 Haskell Workshop},
  chapter = {},
  isbn = {},
  journal = {},
  link = {https://www.microsoft.com/en-us/research/publication/playing-by-the-rules-rewriting-as-a-practical-optimisation-technique-in-ghc/},
  month = {September},
  pages = {},
  publisher = {},
  title = {{Playing by the rules: rewriting as a practical optimisation technique in GHC}},
  url = {https://www.microsoft.com/en-us/research/publication/playing-by-the-rules-rewriting-as-a-practical-optimisation-technique-in-ghc/},
  volume = {},
  year = {2001}
}

@inproceedings{jones:pldi:1999,
  abstract = {Some modern superscalar microprocessors provide only imprecise exceptions. That is, they do not guarantee to report the same exception that would be encountered by a straightforward sequential execution of the program. In exchange, they offer increased performance or decreased area (which amount to much the same thing).  This performance/precision tradeoff has not so far been much explored at the programming language level. In this paper we propose a design for imprecise exceptions in the lazy functional programming language Haskell. We discuss various simpler designs, and conclude that imprecision is essential if the language is still to enjoy its current rich algebra of transformations. We sketch a precise semantics for the language extended with exceptions.  From the functional programming point of view, the paper shows how to extend Haskell with exceptions without crippling the language or its compilers. From the point of view of the wider programming language community, we pose the question of whether precision and performance can be traded off in other languages too.},
  acceptance = {20},
  affiliation = {Yale University and Microsoft Research and Cambridge University and University of Melbourne},
  ar_shortname = {PLDI 99},
  author = {Simon L. Peyton Jones and Alastair D. Reid and Fergus Henderson and C. A. R. Hoare and Simon Marlow},
  booktitle = {Proceedings of the 1999 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI '99)},
  day = {1-4},
  doi = {10.1145/301618.301637},
  editor = {Barbara G. Ryder and Benjamin G. Zorn},
  location = {Atlanta, Georgia, USA},
  month = {May},
  pages = {25-36},
  publisher = {ACM},
  title = {{A semantics for imprecise exceptions}},
  year = {1999}
}

@inproceedings{joshi:pldi:2002,
  address = {New York, NY, USA},
  author = {Rajeev Joshi and Greg Nelson and Keith Randall},
  booktitle = {Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation},
  doi = {10.1145/512529.512566},
  isbn = {1581134630},
  keywords = {optimizing compiler, superoptimizer},
  link = {https://doi.org/10.1145/512529.512566},
  location = {Berlin, Germany},
  numpages = {11},
  pages = {304-314},
  publisher = {Association for Computing Machinery},
  series = {PLDI '02},
  title = {{Denali: A goal-directed superoptimizer}},
  url = {https://doi.org/10.1145/512529.512566},
  year = {2002}
}

@article{jung:cacm:2021,
  author = {Ralf Jung and Jacques-Henri Jourdan and Robbert Krebbers and Derek Dreyer},
  hal_id = {hal-03021536},
  hal_version = {v1},
  journal = {Communications of the ACM},
  keywords = {type systems ; control ; programming language ; Rust ; safety},
  link = {https://hal.archives-ouvertes.fr/hal-03021536},
  pdf = {https://hal.archives-ouvertes.fr/hal-03021536/file/jung2020safe.pdf},
  publisher = {Association for Computing Machinery},
  title = {{Safe systems programming in Rust: The promise and the challenge}},
  url = {https://hal.archives-ouvertes.fr/hal-03021536},
  year = {2021}
}

@article{jung:popl:2017,
  address = {New York, NY, USA},
  articleno = {Article 66},
  author = {Ralf Jung and Jacques-Henri Jourdan and Robbert Krebbers and Derek Dreyer},
  doi = {10.1145/3158154},
  issue_date = {December 2017},
  journal = {Proc. ACM Program. Lang.},
  keywords = {logical relations, concurrency, type systems, Rust, separation logic},
  month = {December},
  number = {POPL},
  numpages = {34},
  publisher = {Association for Computing Machinery},
  title = {{RustBelt: Securing the foundations of the Rust programming language}},
  url = {https://doi.org/10.1145/3158154},
  volume = {2},
  year = {2017}
}

@article{jung:popl:2020,
  address = {New York, NY, USA},
  articleno = {Article 41},
  author = {Ralf Jung and Hoang-Hai Dang and Jeehoon Kang and Derek Dreyer},
  doi = {10.1145/3371109},
  issue_date = {January 2020},
  journal = {Proc. ACM Program. Lang.},
  keywords = {program transformation, Rust, operational semantics, alias analysis},
  month = {December},
  number = {POPL},
  numpages = {32},
  publisher = {Association for Computing Machinery},
  title = {{Stacked borrows: An aliasing model for Rust}},
  url = {https://doi.org/10.1145/3371109},
  volume = {4},
  year = {2019}
}

@inproceedings{kaivola:cav:2009,
  acmid = {1575095},
  address = {Berlin, Heidelberg},
  author = {Roope Kaivola and Rajnish Ghughal and Naren Narasimhan and Amber Telfer and Jesse Whittemore and Sudhindra Pandav and Anna Slobodová and Christopher Taylor and Vladimir Frolov and Erik Reeber and Armaghan Naik},
  booktitle = {Proceedings of the 21st International Conference on Computer Aided Verification},
  doi = {10.1007/978-3-642-02658-4_32},
  isbn = {978-3-642-02657-7},
  location = {Grenoble, France},
  numpages = {16},
  pages = {414-429},
  publisher = {Springer-Verlag},
  series = {CAV '09},
  title = {{Replacing testing with formal verification in Intel Core i7 processor execution engine validation}},
  year = {2009}
}

@inproceedings{kapus:fse:2019,
  abstract = {Symbolic execution is an effective technique for exploring paths in a program and reasoning about all possible values on those paths. However, the technique still struggles with code that uses complex heap data structures, in which a pointer is allowed to refer to more than one memory object. In such cases, symbolic execution typically forks execution into multiple states, one for each object to which the pointer could refer. In this paper, we propose a technique that avoids this expensive forking by using a segmented memory model. In this model, memory is split into segments, so that each symbolic pointer refers to objects in a single segment. The size of the segments are bound by a threshold, in order to avoid expensive constraints. This results in a memory model where forking due to symbolic pointer dereferences is significantly reduced, often completely. We evaluate our segmented memory model on a mix of whole program benchmarks (such as m4 and make) and library benchmarks (such as SQLite), and observe significant decreases in execution time and memory usage.},
  address = {New York, NY, USA},
  author = {Timotej Kapus and Cristian Cadar},
  booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3338906.3338936},
  isbn = {9781450355728},
  keywords = {Symbolic execution, memory models, pointer alias analysis, KLEE},
  link = {https://doi.org/10.1145/3338906.3338936},
  location = {Tallinn, Estonia},
  numpages = {11},
  pages = {774-784},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2019},
  title = {{A segmented memory model for symbolic execution}},
  url = {https://doi.org/10.1145/3338906.3338936},
  year = {2019}
}

@inproceedings{kassios:fm:2006,
  abstract = {This paper addresses the frame problem for programming theories that support both sharing and encapsulation through specification variables. The concept of dynamic frames is introduced. It is shown how a programming theory with dynamic frames supports both features, without the use of alias control or any other kind of restriction. In contrast, other approaches introduce a number of restrictions to the programs to ensure soundness.},
  address = {Berlin, Heidelberg},
  author = {Ioannis T. Kassios},
  booktitle = {FM 2006: Formal Methods},
  doi = {10.1007/11813040_19},
  editor = {Misra, Jayadev and Nipkow, Tobias and Sekerinski, Emil},
  isbn = {978-3-540-37216-5},
  pages = {268-283},
  publisher = {Springer Berlin Heidelberg},
  title = {{Dynamic frames: Support for framing, dependencies and sharing without restrictions}},
  year = {2006}
}

@article{kaufmann:ieeetse:1997,
  author = {Matt Kaufmann and J. Strother Moore},
  doi = {10.1109/32.588534},
  issn = {0098-5589},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {LISP;digital signal processing chips;floating point arithmetic;program verification;theorem proving;ACL2;AMD5K86 microprocessor;Advanced Micro Devices;Common Lisp;Motorola CAP digital signal processing chip;Nqthm;Pc-Nqthm;floating point division algorithm;formal logic;formal models;industrial strength programming language;industrial strength theorem prover;large applicative subset;large scale verification projects;proof of correctness;reimplemented extended version;Automatic logic units;Digital signal processing chips;Functional programming;Kernel;Large-scale systems;Logic devices;Logic programming;Mathematics;Microprocessors;Signal processing algorithms},
  month = {April},
  number = {4},
  pages = {203-213},
  title = {{An industrial strength theorem prover for a logic based on Common Lisp}},
  volume = {23},
  year = {1997}
}

@article{kaufmann:utaustin:2012,
  author = {Matt Kaufmann and Warren A. Hunt Jr.},
  journal = {Department of Computer Science, University of Texas at Austin, Tech. Rep. TR-12-07},
  title = {{Towards a formal model of the x86 ISA}},
  year = {2012}
}

@inproceedings{khakpour:cpp:2013,
  author = {Narges Khakpour and Oliver Schwarz and Mads Dam},
  booktitle = {International Conference on Certified Programs and Proofs},
  doi = {10.1007/978-3-319-03545-1_18},
  organization = {Springer},
  pages = {276-291},
  title = {{Machine assisted proof of ARMv7 instruction level isolation properties}},
  year = {2013}
}

@inproceedings{khurshid:tacas:2003,
  abstract = {Modern software systems, which often are concurrent and manipulate complex data structures must be extremely reliable. We present a novel framework based on symbolic execution, for automated checking of such systems. We provide a two-fold generalization of traditional symbolic execution based approaches. First, we define a source to source translation to instrument a program, which enables standard model checkers to perform symbolic execution of the program. Second, we give a novel symbolic execution algorithm that handles dynamically allocated structures (e.g., lists and trees), method preconditions (e.g., acyclicity), data (e.g., integers and strings) and concurrency. The program instrumentation enables a model checker to automatically explore different program heap configurations and manipulate logical formulae on program data (using a decision procedure). We illustrate two applications of our framework: checking correctness of multi-threaded programs that take inputs from unbounded domains with complex structure and generation of non-isomorphic test inputs that satisfy a testing criterion. Our implementation for Java uses the Java PathFinder model checker.},
  address = {Berlin, Heidelberg},
  author = {Sarfraz Khurshid and Corina S. Păsăreanu and Willem Visser},
  booktitle = {Proceedings of the 9th International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
  isbn = {3540008985},
  location = {Warsaw, Poland},
  numpages = {16},
  pages = {553-568},
  publisher = {Springer-Verlag},
  series = {TACAS'03},
  title = {{Generalized symbolic execution for model checking and testing}},
  year = {2003}
}

@inproceedings{kiczales:iwoos:1991,
  author = {Gregor Kiczales},
  booktitle = {Proceedings of the 1991 International Workshop on Object Orientation in Operating Systems},
  doi = {10.1109/IWOOOS.1991.183036},
  organization = {IEEE},
  pages = {127-128},
  title = {{Towards a new model of abstraction in software engineering}},
  year = {1991}
}

@inproceedings{kim:isca:2014,
  acmid = {2665726},
  address = {Piscataway, NJ, USA},
  author = {Yoongu Kim and Ross Daly and Jeremie Kim and Chris Fallin and Ji Hye Lee and Donghyuk Lee and Chris Wilkerson and Konrad Lai and Onur Mutlu},
  booktitle = {Proceeding of the 41st Annual International Symposium on Computer Architecuture},
  doi = {10.1145/2678373.2665726},
  isbn = {978-1-4799-4394-4},
  location = {Minneapolis, Minnesota, USA},
  numpages = {12},
  pages = {361-372},
  publisher = {IEEE Press},
  series = {ISCA '14},
  title = {{Flipping bits in memory without accessing them: An experimental study of DRAM disturbance errors}},
  year = {2014}
}

@inproceedings{kirankumar:fmcad:2012,
  author = {V. M. Achutha KiranKumar and Arpan Gupta and Rajnish Ghughal},
  booktitle = {Formal Methods in Computer-Aided Design (FMCAD), 2012},
  organization = {IEEE},
  pages = {149-156},
  title = {{Symbolic trajectory evaluation: The primary validation vehicle for next generation Intel processor graphics FPU}},
  year = {2012}
}

@book{klabnik:book:2018,
  address = {USA},
  author = {Steve Klabnik and Carol Nichols},
  isbn = {9781593278281},
  publisher = {No Starch Press},
  title = {{The Rust programming language}},
  year = {2018}
}

@inproceedings{klein:sosp:2009,
  address = {New York, NY, USA},
  author = {Gerwin Klein and Kevin Elphinstone and Gernot Heiser and June Andronick and David Cock and Philip Derrin and Dhammika Elkaduwe and Kai Engelhardt and Rafal Kolanski and Michael Norrish and Thomas Arthur Leck Sewell and Harvey Tuch and Simon Winwood},
  booktitle = {Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles},
  doi = {10.1145/1629575.1629596},
  isbn = {9781605587523},
  keywords = {l4, microkernel, isabelle/hol, sel4},
  location = {Big Sky, Montana, USA},
  numpages = {14},
  pages = {207-220},
  publisher = {Association for Computing Machinery},
  series = {SOSP '09},
  title = {{SeL4: Formal verification of an OS kernel}},
  url = {https://doi.org/10.1145/1629575.1629596},
  year = {2009}
}

@article{kocher:arxiv:2018,
  archiveprefix = {arXiv},
  author = {Paul Kocher and Daniel Genkin and Daniel Gruss and Werner Haas and Mike Hamburg and Moritz Lipp and Stefan Mangard and Thomas Prescher and Michael Schwarz and Yuval Yarom},
  eprint = {1801.01203},
  journal = {ArXiv e-prints},
  month = {January},
  title = {{Spectre attacks: Exploiting speculative execution}},
  year = {2018}
}

@inproceedings{kocher:crypto:1999,
  abstract = {Cryptosystem designers frequently assume that secrets will be manipulated in closed, reliable computing environments. Unfortunately, actual computers and microchips leak information about the operations they process. This paper examines specific methods for analyzing power consumption measurements to find secret keys from tamper resistant devices. We also discuss approaches for building cryptosystems that can operate securely in existing hardware that leaks information.},
  author = {Paul Kocher and Joshua Jaffe and Benjamin Jun},
  booktitle = {Advances in Cryptology -- CRYPTO' 99},
  doi = {10.1007/3-540-48405-1_25},
  editor = {Wiener, Michael},
  isbn = {978-3-540-48405-9},
  pages = {388-397},
  publisher = {Springer},
  title = {{Differential power analysis}},
  year = {1999}
}

@inproceedings{korencik:qrs:2020,
  abstract = {In this paper, we present a combination of existing and new tools that together make it possible to apply formal verification methods to programs in the form of \texttimes 86_64 machine code. Our approach first uses a decompilation tool (remill) to extract low-level intermediate representation (LLVM) from the machine code. This step consists of instruction translation (i.e. recovery of operation semantics), control flow extraction and address identification.The main contribution of this paper is the second step, which builds on data flow analysis and refinement of indirect (i.e. data-dependent) control flow. This step makes the processed bitcode much more amenable to formal analysis.To demonstrate the viability of our approach, we have compiled a set of benchmark programs into native executables and analysed them using two LLVM-based tools: DIVINE, a software model checker and KLEE, a symbolic execution engine. We have compared the outcomes to direct analysis of the same programs.},
  author = {Lukáš Korenčik and Petr Ročkai and Henrich Lauko and Jiří Barnat},
  booktitle = {2020 IEEE 20th International Conference on Software Quality, Reliability and Security (QRS)},
  doi = {10.1109/QRS51102.2020.00044},
  issn = {},
  keywords = {},
  month = {Dec},
  number = {},
  pages = {265-272},
  title = {{On symbolic execution of decompiled programs}},
  volume = {},
  year = {2020}
}

@inproceedings{kostyukov:pldi:2021,
  abstract = {First-order logic is a natural way of expressing properties of computation. It is traditionally used in various program logics for expressing the correctness properties and certificates. Although such representations are expressive for some theories, they fail to express many interesting properties of algebraic data types (ADTs). In this paper, we explore three different approaches to represent program invariants of ADT-manipulating programs: tree automata, and first-order formulas with or without size constraints. We compare the expressive power of these representations and prove the negative definability of both first-order representations using the pumping lemmas. We present an approach to automatically infer program invariants of ADT-manipulating programs by a reduction to a finite model finder. The implementation called RInGen has been evaluated against state-of-the-art invariant synthesizers and has been experimentally shown to be competitive. In particular, program invariants represented by automata are capable of expressing more complex properties of computation and their automatic construction is often less expensive.},
  address = {New York, NY, USA},
  author = {Yurii Kostyukov and Dmitry Mordvinov and Grigory Fedyukovich},
  booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3453483.3454055},
  isbn = {9781450383912},
  keywords = {algebraic data types, finite models, first-order definability, invariant representation, invariants, tree automata},
  link = {https://doi.org/10.1145/3453483.3454055},
  location = {Virtual, Canada},
  numpages = {15},
  pages = {451-465},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2021},
  title = {{Beyond the elementary representations of program invariants over algebraic data types}},
  url = {https://doi.org/10.1145/3453483.3454055},
  year = {2021}
}

@phdthesis{kozyrakis:phd:2002,
  author = {Christoforos Kozyrakis},
  month = {May},
  school = {University of California, Berkeley},
  title = {{Scalable vector media processors for embedded systems}},
  year = {2002}
}

@inproceedings{krishnamurthi:fm:2019,
  abstract = {Formal methods are invaluable for reasoning about complex systems. As these techniques and tools have improved in expressiveness and scale, their adoption has grown rapidly. Sustaining this growth, however, requires attention to not only the technical but also the human side. In this paper (and accompanying talk), we discuss some of the challenges and opportunities for human factors in formal methods.},
  address = {Cham},
  author = {Shriram Krishnamurthi and Tim Nelson},
  booktitle = {Formal Methods - The Next 30 Years},
  editor = {ter Beek, Maurice H. and McIver, Annabelle and Oliveira, José N.},
  isbn = {978-3-030-30942-8},
  pages = {3-10},
  publisher = {Springer International Publishing},
  title = {{The human in formal methods}},
  year = {2019}
}

@inproceedings{krishnamurthi:snapl:2019,
  author = {Shriram Krishnamurthi and Benjamin S. Lerner and Liam Elberty},
  booktitle = {Summit on Advances in Programming Languages (SNAPL)},
  doi = {10.4230/LIPIcs.SNAPL.2019.9},
  isbn = {},
  title = {{The next 700 semantics: A research challenge}},
  year = {2019}
}

@inproceedings{krishnaswami:tldi:2010,
  address = {New York, NY, USA},
  author = {Neel R. Krishnaswami and Lars Birkedal and Jonathan Aldrich},
  booktitle = {Proceedings of the 5th ACM SIGPLAN Workshop on Types in Language Design and Implementation},
  doi = {10.1145/1708016.1708025},
  isbn = {9781605588919},
  keywords = {frame rule, functional reactive programming, ramification problem, separation logic, dataflow, subject-observer},
  location = {Madrid, Spain},
  numpages = {14},
  pages = {63-76},
  publisher = {Association for Computing Machinery},
  series = {TLDI '10},
  title = {{Verifying event-driven programs using ramified frame properties}},
  url = {https://doi.org/10.1145/1708016.1708025},
  year = {2010}
}

@inproceedings{kroening:dac:2001,
  author = {Daniel Kroening and Wolfgang J. Paul},
  booktitle = {Proceedings of the 38th Design Automation Conference},
  doi = {10.1145/378239.379071},
  isbn = {1-58113-297-2},
  pages = {810-815},
  publisher = {ACM Press},
  title = {{Automated pipeline design}},
  year = {2001}
}

@inproceedings{kroening:itg:2000,
  author = {Daniel Kroening and Wolfgang J. Paul and Silvia Mueller},
  booktitle = {Proceedings of ITG/GI/GMM-Workshop ''Methoden und Beschreibungssprachen zur Modellierung und Verifikation von Schaltungen und Systemen''},
  editor = {Waldschmidt, Klaus and Grimm, Christoph},
  isbn = {3-8007-2524-X},
  pages = {89-98},
  publisher = {VDE Verlag},
  title = {{Proving the correctness of pipelined micro-architectures}},
  year = {2000}
}

@inproceedings{krohn:sosp:2007,
  address = {New York, NY, USA},
  author = {Maxwell Krohn and Alexander Yip and Micah Brodsky and Natan Cliffer and M. Frans Kaashoek and Eddie Kohler and Robert Morris},
  booktitle = {Proceedings of Twenty-first ACM SIGOPS Symposium on Operating Systems Principles},
  doi = {10.1145/1294261.1294293},
  isbn = {978-1-59593-591-5},
  keywords = {DIFC, decentralized information flow control, endpoints, reference monitor, system call interposition, web services},
  location = {Stevenson, Washington, USA},
  numpages = {14},
  pages = {321-334},
  publisher = {ACM},
  series = {SOSP'07},
  title = {{Information flow control for standard OS abstractions}},
  year = {2007}
}

@inproceedings{kuhne:fmcad:2010,
  acmid = {1998521},
  address = {Austin, TX},
  author = {Ulrich Kühne and Sven Beyer and Jörg Bormann and John Barstow},
  booktitle = {Proceedings of the 2010 Conference on Formal Methods in Computer-Aided Design},
  location = {Lugano, Switzerland},
  numpages = {8},
  pages = {129-136},
  publisher = {FMCAD Inc},
  series = {FMCAD '10},
  title = {{Automated formal verification of processors based on architectural models}},
  year = {2010}
}

@inproceedings{kumar:isca:2004,
  abstract = {A single-ISA heterogeneous multi-core architecture is a chip multiprocessor composed of cores of varying size, performance, and complexity. This paper demonstrates that this architecture can provide significantly higher performance in the same area than a conventional chip multiprocessor. It does so by matching the various jobs of a diverse workload to the various cores. This type of architecture covers a spectrum of workloads particularly well, providing high single-thread performance when thread parallelism is low, and high throughput when thread parallelism is high. This paper examines two such architectures in detail, demonstrating dynamic core assignment policies that provide significant performance gains over naive assignment, and even outperform the best static assignment. It examines policies for heterogeneous architectures both with and without multithreading cores. One heterogeneous architecture we examine outperforms the comparable-area homogeneous architecture by up to 63\%, and our best core assignment strategy achieves up to 31\% speedup over a naive policy.},
  author = {Rakesh Kumar and Dean M. Tullsen and Parthasarathy Ranganathan and Norman P. Jouppi and Keith I. Farkas},
  booktitle = {Proceedings. 31st Annual International Symposium on Computer Architecture, 2004.},
  doi = {10.1109/ISCA.2004.1310764},
  issn = {1063-6897},
  keywords = {multiprocessing systems;parallel architectures;multi-threading;microprocessor chips;instruction sets;single-ISA heterogeneous multicore architectures;multithreaded workload performance;chip multiprocessor;job matching;single-thread performance;thread parallelism;dynamic core assignment policies;static assignment;heterogeneous architectures;multithreading cores;comparable-area homogeneous architecture;naive policy;Computer architecture;Throughput;Yarn;Parallel processing;Performance gain;Multithreading;Delay;Computer science;Milling machines;Microprocessors},
  month = {June},
  number = {},
  pages = {64-75},
  title = {{Single-ISA heterogeneous multi-core architectures for multithreaded workload performance}},
  volume = {},
  year = {2004}
}

@inproceedings{kumar:popl:2014,
  author = {Ramana Kumar and Magnus O. Myreen and Michael Norrish and Scott Owens},
  booktitle = {Principles of Programming Languages (POPL)},
  doi = {10.1145/2535838.2535841},
  pages = {179-192},
  publisher = {ACM},
  title = {{CakeML: A verified implementation of ML}},
  year = {2014}
}

@inproceedings{kupferman:concur:2006,
  abstract = {One of the advantages of temporal-logic model-checking tools is their ability to accompany a negative answer to the correctness query by a counterexample to the satisfaction of the specification in the system. On the other hand, when the answer to the correctness query is positive, most model-checking tools provide no additional information. In the last few years there has been growing awareness to the importance of suspecting the system or the specification of containing an error also in the case model checking succeeds. The main justification of such suspects are possible errors in the modeling of the system or of the specification. The goal of sanity checks is to detect such errors by further automatic reasoning. Two leading sanity checks are vacuity and coverage. In vacuity, the goal is to detect cases where the system satisfies the specification in some unintended trivial way. In coverage, the goal is to increase the exhaustiveness of the specification by detecting components of the system that do not play a role in verification process. For both checks, the challenge is to define vacuity and coverage formally, develop algorithms for detecting vacuous satisfaction and low coverage, and suggest methods for returning to the user helpful information. We survey existing work on vacuity and coverage and argue that, in many aspects, the two checks are essentially the same: both are based on repeating the verification process on some mutant input. In vacuity, mutations are in the specifications, whereas in coverage, mutations are in the system. This observation enables us to adopt work done in the context of vacuity to coverage, and vise versa.},
  address = {Berlin, Heidelberg},
  author = {Orna Kupferman},
  booktitle = {CONCUR 2006 - Concurrency Theory},
  editor = {Baier, Christel and Hermanns, Holger},
  isbn = {978-3-540-37377-3},
  pages = {37-51},
  publisher = {Springer Berlin Heidelberg},
  title = {{Sanity checks in formal verification}},
  year = {2006}
}

@inproceedings{kuznetsov:pldi:2012,
  abstract = {Symbolic execution has proven to be a practical technique for building automated test case generation and bug finding tools. Nevertheless, due to state explosion, these tools still struggle to achieve scalability. Given a program, one way to reduce the number of states that the tools need to explore is to merge states obtained on different paths. Alas, doing so increases the size of symbolic path conditions (thereby stressing the underlying constraint solver) and interferes with optimizations of the exploration process (also referred to as search strategies). The net effect is that state merging may actually lower performance rather than increase it.We present a way to automatically choose when and how to merge states such that the performance of symbolic execution is significantly increased. First, we present query count estimation, a method for statically estimating the impact that each symbolic variable has on solver queries that follow a potential merge point; states are then merged only when doing so promises to be advantageous. Second, we present dynamic state merging, a technique for merging states that interacts favorably with search strategies in automated test case generation and bug finding tools.Experiments on the 96 GNU Coreutils show that our approach consistently achieves several orders of magnitude speedup over previously published results. Our code and experimental data are publicly available at http://cloud9.epfl.ch.},
  address = {New York, NY, USA},
  author = {Volodymyr Kuznetsov and Johannes Kinder and Stefan Bucur and George Candea},
  booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2254064.2254088},
  isbn = {9781450312059},
  keywords = {state merging, bounded software model checking, testing, symbolic execution, verification},
  link = {https://doi.org/10.1145/2254064.2254088},
  location = {Beijing, China},
  numpages = {12},
  pages = {193-204},
  publisher = {Association for Computing Machinery},
  series = {PLDI '12},
  title = {{Efficient state merging in symbolic execution}},
  url = {https://doi.org/10.1145/2254064.2254088},
  year = {2012}
}

@inproceedings{lahiri:cav:2003,
  author = {Shuvendu K. Lahiri and Randal E. Bryant},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/cav/LahiriB03},
  booktitle = {Computer Aided Verification, 15th International Conference, CAV 2003, Boulder, CO, USA, July 8-12, 2003, Proceedings},
  doi = {10.1007/978-3-540-45069-6_33},
  pages = {341-353},
  timestamp = {Fri, 22 Nov 2013 12:57:23 +0100},
  title = {{Deductive verification of advanced out-of-order microprocessors}},
  year = {2003}
}

@inproceedings{lahiri:hldvt:2001,
  author = {Shuvendu K. Lahiri and Carl Pixley and Kenneth L. Albin},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/hldvt/LahiriPA01},
  booktitle = {Proceedings of the Sixth IEEE International High-Level Design Validation and Test Workshop 2001, Monterey, California, USA, November 7-9, 2001},
  doi = {10.1109/HLDVT.2001.972816},
  pages = {109-114},
  timestamp = {Tue, 12 May 2015 17:11:46 +0200},
  title = {{Experience with term level modeling and verification of the M* CORE microprocessor core}},
  year = {2001}
}

@inproceedings{lal:cav:2012,
  abstract = {Consider a sequential programming language with control flow constructs such as assignments, choice, loops, and procedure calls. We restrict the syntax of expressions in this language to one that can be efficiently decided by a satisfiability-modulo-theories solver. For such a language, we define the problem of deciding whether a program can reach a particular control location as the reachability-modulo-theories problem. This paper describes the architecture of Corral, a semi-algorithm for the reachability-modulo-theories problem. Corraluses novel algorithms for inlining procedures on demand (Stratified Inlining) and abstraction refinement (Hierarchical Refinement). The paper also presents an evaluation of Corralagainst other related tools. Corralconsistently outperforms its competitors on most benchmarks.},
  address = {Berlin, Heidelberg},
  author = {Akash Lal and Shaz Qadeer and Shuvendu K. Lahiri},
  booktitle = {Computer Aided Verification},
  doi = {10.1007/978-3-642-31424-7_32},
  editor = {Madhusudan, P. and Seshia, Sanjit A.},
  isbn = {978-3-642-31424-7},
  pages = {427-443},
  publisher = {Springer Berlin Heidelberg},
  title = {{A solver for reachability modulo theories}},
  year = {2012}
}

@inproceedings{lal:fse:2014,
  author = {Akash Lal and Shaz Qadeer},
  booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  doi = {10.1145/2635868.2635894},
  organization = {ACM},
  pages = {202-212},
  title = {{Powering the static driver verifier using Corral}},
  year = {2014}
}

@inproceedings{lal:pldi:2015,
  acmid = {2737987},
  address = {New York, NY, USA},
  author = {Akash Lal and Shaz Qadeer},
  booktitle = {Programming Language Design and Implementation (PLDI)},
  doi = {10.1145/2813885.2737987},
  issn = {0362-1340},
  issue_date = {June 2015},
  keywords = {Bounded Model Checking, Procedure Inlining, Reachability modulo theories, Satisfiability modulo theories, Verification Condition generation},
  month = {June},
  number = {6},
  numpages = {11},
  pages = {280-290},
  publisher = {ACM},
  title = {{DAG inlining: A decision procedure for reachability-modulo-theories in hierarchical programs}},
  volume = {50},
  year = {2015}
}

@inproceedings{lattner:cgo:2004,
  abstract = {We describe LLVM (low level virtual machine), a compiler framework designed to support transparent, lifelong program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in static single assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.},
  author = {Chris Lattner and Vikram Adve},
  booktitle = {International Symposium on Code Generation and Optimization, 2004. CGO 2004.},
  doi = {10.1109/CGO.2004.1281665},
  issn = {},
  keywords = {program diagnostics;virtual machines;C language;exception handling;optimising compilers;program analysis;program transformation;low level virtual machine;compiler framework;compiler transformations;code representation;static single assignment form;language-independent type-system;typed address arithmetic;exception handling;compiler performance;Information analysis;Program processors;Performance analysis;High level languages;Virtual machining;Runtime;Arithmetic;Application software;Software safety;Algorithm design and analysis},
  month = {March},
  number = {},
  pages = {75-86},
  title = {{LLVM: a compilation framework for lifelong program analysis and transformation}},
  volume = {},
  year = {2004}
}

@article{lauer:osr:1979,
  acmid = {850658},
  address = {New York, NY, USA},
  author = {Hugh C. Lauer and Roger M. Needham},
  doi = {10.1145/850657.850658},
  issn = {0163-5980},
  issue_date = {April 1979},
  journal = {SIGOPS Operating System Review},
  month = {April},
  number = {2},
  numpages = {17},
  pages = {3-19},
  publisher = {ACM},
  title = {{On the duality of operating system structures}},
  volume = {13},
  year = {1979}
}

@inproceedings{lauinger:trustcom:2020,
  abstract = {The Go programming language aims to provide memory and thread safety through measures such as automated memory management with garbage collection and a strict type system. However, it also offers a way of circumventing this safety net through the use of the unsafe package. While there are legitimate use cases for unsafe, developers must exercise caution to avoid introducing vulnerabilities like buffer overflows or memory corruption in general. In this work, we present go-geiger, a novel tool for Go developers to quantify unsafe usages in a project's source code and all of its dependencies. Using go-geiger, we conducted a study on the usage of unsafe in the top 500 most popular open-source Go projects on GitHub, including a manual analysis of 1,400 code samples on how unsafe is used. From the projects using Go's module system, 38\% directly contain at least one unsafe usage, and 91\% contain at least one unsafe usage in the project itself or one of its transitive dependencies. Based on the usage patterns found, we present possible exploit vectors in different scenarios. Finally, we present go-safer, a novel static analysis tool to identify dangerous and common usage patterns that were previously undetected with existing tools.},
  author = {Johannes Lauinger and Lars Baumgärtner and Anna-Katharina Wickert and Mira Mezini},
  booktitle = {2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
  doi = {10.1109/TrustCom50675.2020.00063},
  issn = {2324-9013},
  keywords = {},
  month = {Dec},
  number = {},
  pages = {410-417},
  title = {{Uncovering the hidden dangers: Finding unsafe Go code in the wild}},
  volume = {},
  year = {2020}
}

@article{lee:micro:1996,
  acmid = {624025},
  address = {Los Alamitos, CA, USA},
  author = {Ruby B. Lee},
  doi = {10.1109/40.526925},
  issn = {0272-1732},
  issue_date = {August 1996},
  journal = {IEEE Micro},
  keywords = {subword parallelism, MAX-2, multimedia acceleration, instruction set extensions, SIMD, media processing, subword rearrangement, data parallelism.},
  month = {August},
  number = {4},
  numpages = {9},
  pages = {51-59},
  publisher = {IEEE Computer Society Press},
  title = {{Subword parallelism with MAX-2}},
  volume = {16},
  year = {1996}
}

@inproceedings{legoues:sefm:2011,
  abstract = {The Boogie Verification Debugger (BVD) is a tool that lets users explore the potential program errors reported by a deductive program verifier. The user interface is like that of a dynamic debugger, but the debugging happens statically without executing the program. BVD integrates with the program-verification engine Boogie. Just as Boogie supports multiple language front-ends, BVD can work with those front-ends through a plug-in architecture. BVD plugins have been implemented for two state-of-the-art verifiers, VCC and Dafny.},
  address = {Berlin, Heidelberg},
  author = {Claire Le Goues and K. Rustan M. Leino and Michał Moskal},
  booktitle = {Software Engineering and Formal Methods},
  editor = {Barthe, Gilles and Pardo, Alberto and Schneider, Gerardo},
  isbn = {978-3-642-24690-6},
  pages = {407-414},
  publisher = {Springer Berlin Heidelberg},
  title = {{The Boogie verification debugger}},
  year = {2011}
}

@inproceedings{leinenbach:fm:2009,
  author = {Dirk Leinenbach and Thomas Santen},
  booktitle = {International Symposium on Formal Methods},
  doi = {10.1007/978-3-642-05089-3_51},
  organization = {Springer},
  pages = {806-809},
  title = {{Verifying the Microsoft Hyper-V hypervisor with VCC}},
  year = {2009}
}

@inbook{leino:fosad:2007,
  abstract = {A program verifier is a tool that allows developers to prove that their code satisfies its specification for every possible input and every thread schedule. These lecture notes describe a verifier for concurrent programs called Chalice.},
  address = {Berlin, Heidelberg},
  author = {K. Rustan M. Leino and Peter Müller and Jan Smans},
  booktitle = {Foundations of Security Analysis and Design V: FOSAD 2007/2008/2009 Tutorial Lectures},
  doi = {10.1007/978-3-642-03829-7_7},
  editor = {Aldini, Alessandro and Barthe, Gilles and Gorrieri, Roberto},
  isbn = {978-3-642-03829-7},
  pages = {195-222},
  publisher = {Springer Berlin Heidelberg},
  title = {{Verification of concurrent programs with Chalice}},
  url = {https://doi.org/10.1007/978-3-642-03829-7_7},
  year = {2009}
}

@inproceedings{leino:icse:2013,
  author = {K. Rustan M. Leino},
  booktitle = {2013 35th International Conference on Software Engineering (ICSE)},
  doi = {10.1109/ICSE.2013.6606754},
  issn = {1558-1225},
  keywords = {program verification;specification languages;Dafny programs;specification langauge;program verifier;programming language;Arrays;Tutorials;Reactive power;Cognition;Security;Educational institutions;Computer languages},
  month = {May},
  number = {},
  pages = {1488-1490},
  title = {{Developing verified programs with Dafny}},
  volume = {},
  year = {2013}
}

@inbook{leino:informatics:2001,
  abstract = {A powerful approach to finding errors in computer software is to translate a given program into a verification condition, a logical formula that is valid if and only if the program is free of the classes of errors under consideration. Finding errors in the program is then done by mechanically searching for counterexamples to the verification condition. This paper gives an overview of the technology that goes into such program checkers, reports on some of the progress and lessons learned in the past ten years, and identifies some remaining challenges.},
  address = {Berlin, Heidelberg},
  author = {K. Rustan M. Leino},
  booktitle = {Informatics: 10 Years Back, 10 Years Ahead},
  doi = {10.1007/3-540-44577-3_11},
  editor = {Wilhelm, Reinhard},
  isbn = {978-3-540-44577-7},
  link = {https://doi.org/10.1007/3-540-44577-3_11},
  pages = {157-175},
  publisher = {Springer Berlin Heidelberg},
  title = {{Extended static checking: A ten-year perspective}},
  url = {https://doi.org/10.1007/3-540-44577-3_11},
  year = {2001}
}

@inproceedings{leino:lpair:2010,
  author = {K. Rustan M. Leino},
  booktitle = {International Conference on Logic for Programming Artificial Intelligence and Reasoning},
  doi = {10.1007/978-3-642-17511-4_20},
  organization = {Springer},
  pages = {348-370},
  title = {{Dafny: An automatic program verifier for functional correctness}},
  year = {2010}
}

@inproceedings{leino:sac:2009,
  address = {New York, NY, USA},
  author = {K. Rustan M. Leino and Rosemary Monahan},
  booktitle = {Proceedings of the 2009 ACM Symposium on Applied Computing},
  doi = {10.1145/1529282.1529411},
  isbn = {9781605581668},
  keywords = {SMT solvers, quantifiers, Spec#, matching triggers},
  location = {Honolulu, Hawaii},
  numpages = {8},
  pages = {615-622},
  publisher = {Association for Computing Machinery},
  series = {SAC '09},
  title = {{Reasoning about comprehensions with first-order SMT solvers}},
  url = {https://doi.org/10.1145/1529282.1529411},
  year = {2009}
}

@inproceedings{leino:tacas:2010,
  address = {Berlin, Heidelberg},
  author = {K. Rustan M. Leino and Philipp Rümmer},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  doi = {10.1007/978-3-642-12002-2_26},
  editor = {Esparza, Javier and Majumdar, Rupak},
  isbn = {978-3-642-12002-2},
  pages = {312-327},
  publisher = {Springer Berlin Heidelberg},
  title = {{A polymorphic intermediate verification language: Design and logical encoding}},
  year = {2010}
}

@article{leroy:cacm:2009,
  author = {Xavier Leroy},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/journals/cacm/Leroy09},
  doi = {10.1145/1538788.1538814},
  journal = {Communications of the ACM},
  number = {7},
  pages = {107-115},
  timestamp = {Thu, 02 Jul 2009 13:36:32 +0200},
  title = {{Formal verification of a realistic compiler}},
  volume = {52},
  year = {2009}
}

@inproceedings{levy:apsys:2017,
  address = {New York, NY, USA},
  articleno = {Article 1},
  author = {Amit Levy and Bradford Campbell and Branden Ghena and Pat Pannuto and Prabal Dutta and Philip Levis},
  booktitle = {Proceedings of the 8th Asia-Pacific Workshop on Systems},
  doi = {10.1145/3124680.3124717},
  isbn = {9781450351973},
  location = {Mumbai, India},
  numpages = {7},
  publisher = {Association for Computing Machinery},
  series = {APSys'17},
  title = {{The case for writing a kernel in Rust}},
  url = {https://doi.org/10.1145/3124680.3124717},
  year = {2017}
}

@inproceedings{levy:plos:2015,
  address = {New York, NY, USA},
  author = {Amit Levy and Michael P. Andersen and Bradford Campbell and David Culler and Prabal Dutta and Branden Ghena and Philip Levis and Pat Pannuto},
  booktitle = {Proceedings of the 8th Workshop on Programming Languages and Operating Systems},
  doi = {10.1145/2818302.2818306},
  isbn = {9781450339421},
  keywords = {ownership, rust, embedded operating systems, linear types},
  location = {Monterey, California},
  numpages = {6},
  pages = {21-26},
  publisher = {Association for Computing Machinery},
  series = {PLOS '15},
  title = {{Ownership is theft: Experiences building an embedded OS in Rust}},
  url = {https://doi.org/10.1145/2818302.2818306},
  year = {2015}
}

@inproceedings{levy:sosp:2017,
  address = {New York, NY, USA},
  author = {Amit Levy and Bradford Campbell and Branden Ghena and Daniel B. Giffin and Pat Pannuto and Prabal Dutta and Philip Levis},
  booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
  doi = {10.1145/3132747.3132786},
  isbn = {9781450350853},
  link = {https://doi.org/10.1145/3132747.3132786},
  location = {Shanghai, China},
  numpages = {18},
  pages = {234-251},
  publisher = {Association for Computing Machinery},
  series = {SOSP '17},
  title = {{Multiprogramming a 64kB computer safely and efficiently}},
  url = {https://doi.org/10.1145/3132747.3132786},
  year = {2017}
}

@inproceedings{li:sandp:2021,
  address = {Los Alamitos, CA, USA},
  author = {Shih-Wei Li and Xupeng Li and Ronghui Gu and Jason Nieh and John Zhuang Hui},
  booktitle = {2021 2021 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP40001.2021.00049},
  issn = {2375-1207},
  keywords = {},
  link = {https://doi.ieeecomputersociety.org/10.1109/SP40001.2021.00049},
  month = {may},
  pages = {839-856},
  publisher = {IEEE Computer Society},
  title = {{A secure and formally verified Linux KVM hypervisor}},
  url = {https://doi.ieeecomputersociety.org/10.1109/SP40001.2021.00049},
  volume = {},
  year = {2021}
}

@article{li:tocs:1989,
  acmid = {75105},
  address = {New York, NY, USA},
  author = {Kai Li and Paul Hudak},
  doi = {10.1145/75104.75105},
  issn = {0734-2071},
  issue_date = {Nov. 1989},
  journal = {ACM Transactions on Computer Systems (TOCS)},
  month = {November},
  number = {4},
  numpages = {39},
  pages = {321-359},
  publisher = {ACM},
  title = {{Memory coherence in shared virtual memory systems}},
  volume = {7},
  year = {1989}
}

@inproceedings{lie:secpri:2003,
  author = {David Lie and John C. Mitchell and Chandramohan A. Thekkath and Mark Horowitz},
  booktitle = {2003 Symposium on Security and Privacy, 2003.},
  doi = {10.1109/SECPRI.2003.1199335},
  issn = {},
  keywords = {formal specification;formal verification;operating systems (computers);security of data;hardware specification;hardware verification;tamper-resistant software;hardware architecture;idealized model;cryptographic key embedding;processor chip;access control;adversarial operating system;concrete model;finite-state enumeration tool;model checker;replay attack;security;operating system constraints;liveness guarantee;Hardware;Operating systems;Data security;Computer architecture;Cryptography;Resource management;System testing;Safety;Laboratories;Concrete},
  month = {May},
  number = {},
  pages = {166-177},
  title = {{Specifying and verifying hardware for tamper-resistant software}},
  volume = {},
  year = {2003}
}

@inproceedings{lie:sosp:2003,
  acmid = {945463},
  address = {New York, NY, USA},
  author = {David Lie and Chandramohan A. Thekkath and Mark Horowitz},
  booktitle = {Proceedings of the Nineteenth ACM Symposium on Operating Systems Principles},
  doi = {10.1145/945445.945463},
  isbn = {1-58113-757-5},
  keywords = {XOM, XOMOS, untrusted operating systems},
  location = {Bolton Landing, NY, USA},
  numpages = {15},
  pages = {178-192},
  publisher = {ACM},
  series = {SOSP'03},
  title = {{Implementing an untrusted operating system on trusted hardware}},
  year = {2003}
}

@inproceedings{lietar:ismm:2019,
  abstract = {snmalloc is an implementation of malloc aimed at workloads in which objects are typically deallocated by a different thread than the one that had allocated them. We use the term producer/consumer for such workloads. snmalloc uses a novel message passing scheme which returns deallocated objects to the originating allocator in batches without taking any locks. It also uses a novel bump pointer-free list data structure with which just 64-bits of meta-data are sufficient for each 64 KiB slab. On such producer/consumer benchmarks our approach performs better than existing allocators. Snmalloc is available at https://github.com/Microsoft/snmalloc.},
  address = {New York, NY, USA},
  author = {Paul Liétar and Theodore Butler and Sylvan Clebsch and Sophia Drossopoulou and Juliana Franco and Matthew J. Parkinson and Alex Shamis and Christoph M. Wintersteiger and David Chisnall},
  booktitle = {Proceedings of the 2019 ACM SIGPLAN International Symposium on Memory Management},
  doi = {10.1145/3315573.3329980},
  isbn = {9781450367226},
  keywords = {Memory allocation, message passing},
  link = {https://doi.org/10.1145/3315573.3329980},
  location = {Phoenix, AZ, USA},
  numpages = {14},
  pages = {122-135},
  publisher = {Association for Computing Machinery},
  series = {ISMM 2019},
  title = {{snmalloc: A message passing allocator}},
  url = {https://doi.org/10.1145/3315573.3329980},
  year = {2019}
}

@inproceedings{liew:fse:2019,
  abstract = {We investigate the use of coverage-guided fuzzing as a means of proving satisfiability of SMT formulas over finite variable domains, with specific application to floating-point constraints. We show how an SMT formula can be encoded as a program containing a location that is reachable if and only if the program's input corresponds to a satisfying assignment to the formula. A coverage-guided fuzzer can then be used to search for an input that reaches the location, yielding a satisfying assignment. We have implemented this idea in a tool, Just Fuzz-it Solver (JFS), and we present a large experimental evaluation showing that JFS is both competitive with and complementary to state-of-the-art SMT solvers with respect to solving floating-point constraints, and that the coverage-guided approach of JFS provides significant benefit over naive fuzzing in the floating-point domain. Applied in a portfolio manner, the JFS approach thus has the potential to complement traditional SMT solvers for program analysis tasks that involve reasoning about floating-point constraints.},
  address = {New York, NY, USA},
  author = {Daniel Liew and Cristian Cadar and Alastair F. Donaldson and J. Ryan Stinnett},
  booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3338906.3338921},
  isbn = {9781450355728},
  keywords = {Constraint solving, feedback-directed fuzzing},
  link = {https://doi.org/10.1145/3338906.3338921},
  location = {Tallinn, Estonia},
  numpages = {12},
  pages = {521-532},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2019},
  title = {{Just fuzz it: Solving floating-point constraints using coverage-Guided fuzzing}},
  url = {https://doi.org/10.1145/3338906.3338921},
  year = {2019}
}

@inproceedings{lin:sdr:2006,
  abstract = {High-throughput, low-power Software Defined Radio(SDR) solutions require multi-core SIMD DSP processors to meet real-time performance requirements. Given the difficulty in programming traditional DSPs, these new multi-core signal processors provide even greater challenges for programmers and compilers. In this paper, we describe SPEX, a programming language which is aimed at narrowing the semantic gap between the description of complex SDR systems and their implementations. SPEX supports three different types of programming semantics, allowing SDR solutions to be developed with a divide-and-conquer approach. For DSP algorithm kernels, SPEX is able to support DSP arithmetics and first-class vector and matrix variables with sequential language semantics. From wireless protocol channels, it is able to support sequences of data-processing computations with dataflow language semantics. And for protocol systems, it is able to support real-time deadlines and concurrent executions with synchronous language semantics. The design choices are motivated by our experience implementing W-CDMA protocol on a reprogrammable substrate. In the paper, we also briefly explain SPEX's compilation strategies.},
  affiliation = {ARM Ltd and University of Michigan},
  ar_shortname = {SDR 06},
  author = {Yuan Lin and Robert Mullenix and Mark Woh and Scott A. Mahlke and Trevor N. Mudge and Alastair D. Reid and Krisztián Flautner},
  booktitle = {Software Defined Radio Technical Conference and Product Exposition},
  day = {13-17},
  location = {Orlando, FL, USA},
  month = {November},
  title = {{SPEX: A programming language for software defined radio}},
  year = {2006}
}

@inproceedings{lin:sips:2006,
  abstract = {Software Defined Radio(SDR) is an emerging paradigm for wireless terminals, in which the physical layer of communication protocols is implemented in software rather than by ASICs. Many of the current and next generation wireless protocols include Turbo coding because of its superior performance. However, Turbo decoding is computationally intensive, and its low power implementations have typ- ically been in ASICs. This paper presents a case study of algorithm-architecture co-design of Turbo decoder for SDR. We present a programmable DSP architecture for SDR that includes a set of architectural features to accelerate Turbo decoder computations. We then present a parallel window scheduling for MAX-Log-MAP component decoder that matches well with the DSP architecture. Finally, we present a software implementation of Turbo decoder for W-CDMA on the DSP architecture and show that it achieves 2Mbps decoding throughput.},
  affiliation = {ARM Ltd and University of Michigan and Arizona State University},
  ar_shortname = {SiPS 06},
  author = {Yuan Lin and Scott A. Mahlke and Trevor N. Mudge and Chaitali Chakrabarti and Alastair D. Reid and Krisztián Flautner},
  booktitle = {Proceedings of the IEEE Workshop on Signal Processing Systems (SiPS 2006)},
  day = {2-4},
  doi = {10.1109/SIPS.2006.352549},
  location = {Banff, Alberta, Canada},
  month = {October},
  pages = {22-27},
  publisher = {IEEE},
  title = {{Design and implementation of turbo decoders for software defined radio}},
  year = {2006}
}

@inproceedings{lindner:indin:2018,
  author = {Marcus Lindner and Jorge Aparicius and Per Lindgren},
  booktitle = {2018 IEEE 16th International Conference on Industrial Informatics (INDIN)},
  doi = {10.1109/INDIN.2018.8471992},
  issn = {2378-363X},
  keywords = {object-oriented programming;program compilers;program diagnostics;program verification;Rust programs;Rust language;type system;memory safety;safety conditions;raw array indexing;static analysis;runtime verification;partial correctness guarantees;safety violations;safety-critical applications;static program analysis;generic contract based verification process;KLEE symbolic execution engine;memory model;rustc compiler;panic handling;Safety;Runtime;Contracts;Program processors;Engines;Testing;Data models},
  month = {July},
  number = {},
  pages = {108-114},
  title = {{No panic! Verification of Rust programs by symbolic execution}},
  volume = {},
  year = {2018}
}

@inproceedings{lindner:indin:2019,
  author = {Marcus Lindner and Nils Fitinghoff and Johan Eriksson and Per Lindgren},
  booktitle = {Proceedings : 2019 IEEE 17th International Conference on Industrial Informatics (INDIN)},
  doi = {10.1109/INDIN41052.2019.8972014},
  institution = {Luleå University of Technology, Computer Science},
  note = {ISBN för värdpublikation: 978-1-7281-2927-3, 978-1-7281-2928-0},
  pages = {432-439},
  series = {IEEE International Conference on Industrial Informatics (INDIN)},
  title = {{Verification of safety functions implemented in Rust: A symbolic execution based approach}},
  year = {2019}
}

@article{lipp:arxiv:2018,
  archiveprefix = {arXiv},
  author = {Moritz Lipp and Michael Schwarz and Daniel Gruss and Thomas Prescher and Werner Haas and Stefan Mangard and Paul Kocher and Daniel Genkin and Yuval Yarom and Mike Hamburg},
  eprint = {1801.01207},
  journal = {ArXiv e-prints},
  month = {January},
  title = {{Meltdown}},
  year = {2018}
}

@inproceedings{liu:cpsspc:2018,
  author = {Jed Liu and Joe Corbett-Davies and Andrew Ferraiuolo and Alexander Ivanov and Mulong Luo and G. Edward Suh and Andrew C. Myers and Mark Campbell},
  booktitle = {Proceedings of the 2018 Workshop on Cyber-Physical Systems Security and Privacy,},
  doi = {10.1145/3264888.3264889},
  pages = {48-59},
  publisher = {ACM},
  series = {CPS-SPC '18},
  title = {{Secure autonomous cyber-physical systems through verifiable information flow control}},
  venue = {CPS-SPC},
  year = {2018}
}

@inproceedings{liu:icse:2020,
  abstract = {Rust is a promising systems programming language that embraces both high-level memory safety and low-level resource manipulation. However, the dark side of Rust, unsafe Rust, leaves a large security hole as it bypasses the Rust type system in order to support low-level operations. Recently, several real-world memory corruption vulnerabilities have been discovered in Rust's standard libraries.We present XRust, a new technique that mitigates the security threat of unsafe Rust by ensuring the integrity of data flow from unsafe Rust code to safe Rust code. The cornerstone of XRust is a novel heap allocator that isolates the memory of unsafe Rust from that accessed only in safe Rust, and prevents any cross-region memory corruption. Our design of XRust supports both single-and multi-threaded Rust programs. Our extensive experiments on real-world Rust applications and standard libraries show that XRust is both highly efficient and effective in practice.},
  address = {New York, NY, USA},
  author = {Peiming Liu and Gang Zhao and Jeff Huang},
  booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
  doi = {10.1145/3377811.3380325},
  isbn = {9781450371216},
  link = {https://doi.org/10.1145/3377811.3380325},
  location = {Seoul, South Korea},
  numpages = {12},
  pages = {234-245},
  publisher = {Association for Computing Machinery},
  series = {ICSE '20},
  title = {{Securing unsafe Rust programs with XRust}},
  url = {https://doi.org/10.1145/3377811.3380325},
  year = {2020}
}

@inproceedings{liu:sigcomm:2018,
  abstract = {We present the design and implementation of p4v, a practical tool for verifying data planes described using the P4 programming language. The design of p4v is based on classic verification techniques but adds several key innovations including a novel mechanism for incorporating assumptions about the control plane and domain-specific optimizations which are needed to scale to large programs. We present case studies showing that p4v verifies important properties and finds bugs in real-world programs. We conduct experiments to quantify the scalability of p4v on a wide range of additional examples. We show that with just a few hundred lines of control-plane annotations, p4v is able to verify critical safety properties for switch.p4, a program that implements the functionality of on a modern data center switch, in under three minutes.},
  address = {New York, NY, USA},
  author = {Jed Liu and William Hallahan and Cole Schlesinger and Milad Sharif and Jeongkeun Lee and Robert Soulé and Han Wang and Călin Caşcaval and Nick McKeown and Nate Foster},
  booktitle = {Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication},
  doi = {10.1145/3230543.3230582},
  isbn = {9781450355674},
  keywords = {verification, P4, programmable data planes},
  link = {https://doi.org/10.1145/3230543.3230582},
  location = {Budapest, Hungary},
  numpages = {14},
  pages = {490-503},
  publisher = {Association for Computing Machinery},
  series = {SIGCOMM '18},
  title = {{p4v: Practical verification for programmable data planes}},
  url = {https://doi.org/10.1145/3230543.3230582},
  year = {2018}
}

@inproceedings{lockhart:ispass:2015,
  author = {Derek Lockhart and Berkin Ilbeyi and Christopher Batten},
  booktitle = {2015 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)},
  doi = {10.1109/ISPASS.2015.7095811},
  keywords = {digital simulation;hardware-software codesign;instruction sets;program compilers;ADL-driven toolflows;ADL-generated DBT-ISS;DBT techniques;Pydgin ADL descriptions;Python-based embedded-ADL;dynamic binary translation techniques;executable pseudocode;fast instruction set simulators;general-purpose dynamic programming languages;hardware design;high-level ADL;high-level architectural description languages;high-performance DBT-ISS;metatracing JIT compilers;software design;Encoding;Manuals;Optimization;Productivity;Registers;Semantics;Syntactics},
  month = {March},
  pages = {256-267},
  title = {{Pydgin: generating fast instruction set simulators from simple architecture descriptions with meta-tracing JIT compilers}},
  year = {2015}
}

@inproceedings{logozzo:vmcai:2011,
  author = {Francesco Logozzo},
  booktitle = {International Workshop on Verification, Model Checking, and Abstract Interpretation},
  doi = {10.1007/978-3-642-18275-4_3},
  organization = {Springer},
  pages = {19-22},
  title = {{Practical verification for the working programmer with CodeContracts and abstract interpretation}},
  year = {2011}
}

@inproceedings{loow:pldi:2019,
  author = {Andreas Lööw and Ramana Kumar and Yong Kiam Tan and Magnus O. Myreen and Michael Norrish and Oskar Abrahamsson and Anthony C. J. Fox},
  booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/3314221.3314622},
  organization = {ACM},
  pages = {1041-1053},
  title = {{Verified compilation on a verified processor}},
  year = {2019}
}

@inproceedings{lopes:pldi:2015,
  acmid = {2737965},
  address = {New York, NY, USA},
  author = {Nuno P. Lopes and David Menendez and Santosh Nagarakatte and John Regehr},
  booktitle = {Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2737924.2737965},
  isbn = {978-1-4503-3468-6},
  keywords = {Alive, Compiler Verification, Peephole Optimization},
  location = {Portland, OR, USA},
  numpages = {11},
  pages = {22-32},
  publisher = {ACM},
  series = {PLDI '15},
  title = {{Provably correct peephole optimizations with Alive}},
  year = {2015}
}

@inproceedings{lopes:pldi:2021,
  abstract = {We designed, implemented, and deployed Alive2: a bounded translation validation tool for the LLVM compiler's intermediate representation (IR). It limits resource consumption by, for example, unrolling loops up to some bound, which means there are circumstances in which it misses bugs. Alive2 is designed to avoid false alarms, is fully automatic through the use of an SMT solver, and requires no changes to LLVM. By running Alive2 over LLVM's unit test suite, we discovered and reported 47 new bugs, 28 of which have been fixed already. Moreover, our work has led to eight patches to the LLVM Language Reference-the definitive description of the semantics of its IR-and we have participated in numerous discussions with the goal of clarifying ambiguities and fixing errors in these semantics. Alive2 is open source and we also made it available on the web, where it has active users from the LLVM community.},
  address = {New York, NY, USA},
  author = {Nuno P. Lopes and Juneyoung Lee and Chung-Kil Hur and Zhengyang Liu and John Regehr},
  booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3453483.3454030},
  isbn = {9781450383912},
  keywords = {Compilers, Translation Validation, Automatic Software Verification, IR Semantics},
  link = {https://doi.org/10.1145/3453483.3454030},
  location = {Virtual, Canada},
  numpages = {15},
  pages = {65-79},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2021},
  title = {{Alive2: Bounded translation validation for LLVM}},
  url = {https://doi.org/10.1145/3453483.3454030},
  year = {2021}
}

@inproceedings{lowe:csfw:2015,
  author = {Gavin Lowe},
  booktitle = {Proceedings 15th IEEE Computer Security Foundations Workshop. CSFW-15},
  doi = {10.1109/CSFW.2002.1021804},
  issn = {1063-6900},
  keywords = {communicating sequential processes;information theory;process algebra;CSP;information flow;covert channels;Channel capacity;Algebra;Laboratories;Information security;Books;Performance analysis;Computer security;Conferences},
  month = {June},
  number = {},
  pages = {18-31},
  title = {{Quantifying information flow}},
  volume = {},
  year = {2002}
}

@inproceedings{lustig:asplos:2016,
  author = {Daniel Lustig and Geet Sethi and Margaret Martonosi and Abhishek Bhattacharjee},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/asplos/LustigSMB16},
  booktitle = {Architectural Support for Programming Languages and Operating Systems, ASPLOS},
  doi = {10.1145/2872362.2872399},
  pages = {233-247},
  publisher = {ACM},
  timestamp = {Thu, 31 Mar 2016 18:07:43 +0200},
  title = {{COATCheck: Verifying memory ordering at the hardware-OS interface}},
  year = {2016}
}

@inproceedings{ma:securecomm:2015,
  abstract = {Concolic testing is widely regarded as the state-of-the-art technique in dynamic discovering and analyzing trigger-based behavior in software programs. It uses symbolic execution and an automatic theorem prover to generate new concrete test cases to maximize code coverage for scenarios like software verification and malware analysis. While malicious developers usually try their best to hide malicious executions, there are also circumstances in which legitimate reasons are presented for a program to conceal trigger-based conditions and the corresponding behavior, which leads to the demand of control flow obfuscation techniques. We propose a novel control flow obfuscation design based on the incomprehensibility of artificial neural networks to fight against reverse engineering tools including concolic testing. By training neural networks to simulate conditional behaviors of a program, we manage to precisely replace essential points of a program's control flow with neural network computations. Evaluations show that since the complexity of extracting rules from trained neural networks easily goes beyond the capability of program analysis tools, it is infeasible to apply concolic testing on code obfuscated with our method. Our method also incorporates only basic integer operations and simple loops, thus can be hard to be distinguished from regular programs.},
  address = {Cham},
  author = {Haoyu Ma and Xinjie Ma and Weijie Liu and Zhipeng Huang and Debin Gao and Chunfu Jia},
  booktitle = {International Conference on Security and Privacy in Communication Networks},
  editor = {Tian, Jing and Jing, Jiwu and Srivatsa, Mudhakar},
  isbn = {978-3-319-23829-6},
  pages = {287-304},
  publisher = {Springer International Publishing},
  title = {{Control flow obfuscation using neural network to fight concolic testing}},
  year = {2015}
}

@inproceedings{maas:asplos:2020,
  abstract = {Modern C++ servers have memory footprints that vary widely over time, causing persistent heap fragmentation of up to 2x from long-lived objects allocated during peak memory usage. This fragmentation is exacerbated by the use of huge (2MB) pages, a requirement for high performance on large heap sizes. Reducing fragmentation automatically is challenging because C++ memory managers cannot move objects.This paper presents a new approach to huge page fragmentation. It combines modern machine learning techniques with a novel memory manager (LLAMA) that manages the heap based on object lifetimes and huge pages (divided into blocks and lines). A neural network-based language model predicts lifetime classes using symbolized calling contexts. The model learns context-sensitive per-allocation site lifetimes from previous runs, generalizes over different binary versions, and extrapolates from samples to unobserved calling contexts. Instead of size classes, LLAMA's heap is organized by lifetime classes that are dynamically adjusted based on observed behavior at a block granularity.LLAMA reduces memory fragmentation by up to 78\% while only using huge pages on several production servers. We address ML-specific questions such as tolerating mispredictions and amortizing expensive predictions across application execution. Although our results focus on memory allocation, the questions we identify apply to other system-level problems with strict latency and resource requirements where machine learning could be applied.},
  address = {New York, NY, USA},
  author = {Martin Maas and David G. Andersen and Michael Isard and Mohammad Mahdi Javanmard and Kathryn S. McKinley and Colin Raffel},
  booktitle = {Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/3373376.3378525},
  isbn = {9781450371025},
  keywords = {memory management, profile-guided optimization, lstms, machine learning, lifetime prediction},
  link = {https://doi.org/10.1145/3373376.3378525},
  location = {Lausanne, Switzerland},
  numpages = {16},
  pages = {541-556},
  publisher = {Association for Computing Machinery},
  series = {ASPLOS '20},
  title = {{Learning-based memory allocation for C++ server workloads}},
  url = {https://doi.org/10.1145/3373376.3378525},
  year = {2020}
}

@inproceedings{maciver:ecoop:2020,
  author = {David R. MacIver and Alastair F. Donaldson},
  booktitle = {34th European Conference on Object-Oriented Programming (ECOOP 2020)},
  organization = {Schloss Dagstuhl, Leibniz-Zentrum für Informatik},
  pages = {13:1–13:28},
  title = {{Test-case reduction via test-case generation: Insights from the Hypothesis reducer}},
  year = {2020}
}

@inproceedings{macvean:ppig:2016,
  author = {Andrew Macvean and John Daughtry and Luke Church and Craig Citro},
  booktitle = {Proceedings of the 26th annual workshop of the Psychology of Programming Interest Group},
  title = {{API usability at scale}},
  year = {2016}
}

@inproceedings{mai:asplos:2013,
  author = {Haohui Mai and Edgar Pek and Hui Xue and Samuel Talmadge King and Parthasarathy Madhusudan},
  booktitle = {ASPLOS '13 Proceedings of the eighteenth international conference on Architectural support for programming languages and operating systems},
  doi = {10.1145/2451116.2451148},
  number = {1},
  organization = {ACM},
  pages = {293-304},
  title = {{Verifying security invariants in ExpressOS}},
  volume = {41},
  year = {2013}
}

@inproceedings{majumdar:icse:2007,
  abstract = {We present hybrid concolic testing, an algorithm that interleaves random testing with concolic execution to obtain both a deep and a wide exploration of program state space. Our algorithm generates test inputs automatically by interleaving random testing until saturation with bounded exhaustive symbolic exploration of program points. It thus combines the ability of random search to reach deep program states quickly together with the ability of concolic testing to explore states in a neighborhood exhaustively. We have implemented our algorithm on top of CUTE and applied it to obtain better branch coverage for an editor implementation (VIM 5.7, 150K lines of code) as well as a data structure implementation in C. Our experiments suggest that hybrid concolic testing can handle large programs and provide, for the same testing budget, almost 4\texttimes  the branch coverage than random testing and almost 2\texttimes  that of concolic testing.},
  address = {USA},
  author = {Rupak Majumdar and Koushik Sen},
  booktitle = {Proceedings of the 29th International Conference on Software Engineering},
  doi = {10.1109/ICSE.2007.41},
  isbn = {0769528287},
  keywords = {concolic testing., directed random testing},
  link = {https://doi.org/10.1109/ICSE.2007.41},
  numpages = {11},
  pages = {416-426},
  publisher = {IEEE Computer Society},
  series = {ICSE '07},
  title = {{Hybrid concolic testing}},
  url = {https://doi.org/10.1109/ICSE.2007.41},
  year = {2007}
}

@article{malik:cacm:2009,
  address = {New York, NY, USA},
  author = {Sharad Malik and Lintao Zhang},
  doi = {10.1145/1536616.1536637},
  issn = {0001-0782},
  issue_date = {August 2009},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/1536616.1536637},
  month = {August},
  number = {8},
  numpages = {7},
  pages = {76-82},
  publisher = {Association for Computing Machinery},
  title = {{Boolean satisfiability from theoretical hardness to practical success}},
  url = {https://doi.org/10.1145/1536616.1536637},
  volume = {52},
  year = {2009}
}

@article{manes:ieeetse:2019,
  author = {Valentin J.M. Manès and HyungSeok Han and Choongwoo Han and Sang Kil Cha and Manuel Egele and Edward J. Schwartz and Maverick Woo},
  doi = {10.1109/TSE.2019.2946563},
  journal = {IEEE Transactions on Software Engineering},
  number = {},
  pages = {21},
  title = {{The art, science, and engineering of fuzzing: A survey}},
  volume = {},
  year = {2019}
}

@inproceedings{mangano:crisis:2016,
  author = {Frédéric Mangano and Simon Duquennoy and Nikolai Kosmatov},
  booktitle = {International Conference on Risks and Security of Internet and Systems},
  doi = {10.1007/978-3-319-54876-0_9},
  organization = {Springer},
  pages = {114-120},
  title = {{Formal verification of a memory allocation module of Contiki with Frama-C: a case study}},
  year = {2016}
}

@misc{mansur:arxiv:2020,
  archiveprefix = {arXiv},
  author = {Muhammad Numair Mansur and Maria Christakis and Valentin Wüstholz and Fuyuan Zhang},
  eprint = {2004.05934},
  primaryclass = {cs.SE},
  title = {{Detecting critical bugs in SMT solvers using blackbox mutational fuzzing}},
  year = {2020}
}

@inproceedings{mantel:pls:2007,
  author = {Heiko Mantel and Alexander Reinhard},
  booktitle = {Programming Languages and Systems},
  doi = {10.1007/978-3-540-71316-6_11},
  editor = {De Nicola, Rocco},
  isbn = {978-3-540-71316-6},
  pages = {141-156},
  publisher = {Springer},
  title = {{Controlling the what and where of declassification in language-based security}},
  year = {2007}
}

@inproceedings{mantel:sp:2001,
  author = {Heiko Mantel},
  booktitle = {Proceedings 2001 IEEE Symposium on Security and Privacy. S\&P 2001},
  doi = {10.1109/SECPRI.2001.924289},
  organization = {IEEE},
  pages = {78-91},
  title = {{Preserving information flow properties under refinement}},
  year = {2000}
}

@inproceedings{martignoni:asplos:2012,
  acmid = {2151012},
  address = {New York, NY, USA},
  author = {Lorenzo Martignoni and Stephen McCamant and Pongsin Poosankam and Dawn Song and Petros Maniatis},
  booktitle = {Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/2150976.2151012},
  isbn = {978-1-4503-0759-8},
  keywords = {CPU emulators, cross validation, symbolic binary execution},
  location = {London, England, UK},
  numpages = {12},
  pages = {337-348},
  publisher = {ACM},
  series = {ASPLOS XVII},
  title = {{Path-exploration lifting: Hi-fi tests for lo-fi emulators}},
  year = {2012}
}

@inproceedings{massalin:asplos:1987,
  address = {Washington, DC, USA},
  author = {Alexia Massalin},
  booktitle = {Proceedings of the Second International Conference on Architectual Support for Programming Languages and Operating Systems},
  doi = {10.1145/36206.36194},
  isbn = {0818608056},
  link = {https://doi.org/10.1145/36206.36194},
  location = {Palo Alto, California, USA},
  numpages = {5},
  pages = {122-126},
  publisher = {IEEE Computer Society Press},
  series = {ASPLOS II},
  title = {{Superoptimizer: A look at the smallest program}},
  url = {https://doi.org/10.1145/36206.36194},
  year = {1987}
}

@inproceedings{matsakis:hilt:2014,
  abstract = {Rust is a new programming language for developing reliable and efficient systems. It is designed to support concurrency and parallelism in building applications and libraries that take full advantage of modern hardware. Rust's static type system is safe1 and expressive and provides strong guarantees about isolation, concurrency, and memory safety.Rust also offers a clear performance model, making it easier to predict and reason about program efficiency. One important way it accomplishes this is by allowing fine-grained control over memory representations, with direct support for stack allocation and contiguous record storage. The language balances such controls with the absolute requirement for safety: Rust's type system and runtime guarantee the absence of data races, buffer overflows, stack overflows, and accesses to uninitialized or deallocated memory.},
  address = {New York, NY, USA},
  author = {Nicholas D. Matsakis and Felix S. Klock},
  booktitle = {Proceedings of the 2014 ACM SIGAda Annual Conference on High Integrity Language Technology},
  doi = {10.1145/2663171.2663188},
  isbn = {9781450332170},
  keywords = {affine type systems, systems programming, memory management, rust},
  link = {https://doi.org/10.1145/2663171.2663188},
  location = {Portland, Oregon, USA},
  numpages = {2},
  pages = {103-104},
  publisher = {Association for Computing Machinery},
  series = {HILT '14},
  title = {{The Rust language}},
  url = {https://doi.org/10.1145/2663171.2663188},
  year = {2014}
}

@inproceedings{matsushita:esop:2020,
  abstract = {Reduction to the satisfiablility problem for constrained Horn clauses (CHCs) is a widely studied approach to automated program verification. The current CHC-based methods for pointer-manipulating programs, however, are not very scalable. This paper proposes a novel translation of pointer-manipulating Rust programs into CHCs, which clears away pointers and heaps by leveraging ownership. We formalize the translation for a simplified core of Rust and prove its correctness. We have implemented a prototype verifier for a subset of Rust and confirmed the effectiveness of our method.},
  address = {Cham},
  author = {Yusuke Matsushita and Takeshi Tsukada and Naoki Kobayashi},
  booktitle = {Programming Languages and Systems},
  doi = {10.1007/978-3-030-44914-8_18},
  editor = {Müller, Peter},
  isbn = {978-3-030-44914-8},
  pages = {484-514},
  publisher = {Springer International Publishing},
  title = {{RustHorn: CHC-based verification for Rust programs}},
  year = {2020}
}

@inbook{maus:amast:2008,
  abstract = {Vx86 is the first static analyzer for sequential Intel x86 assembler code using automated deductive verification. It proves the correctness of assembler code against function contracts, which are expressed in terms of pre-, post-, and frame conditions using first-order predicates. Vx86 takes the annotated assembler code, translates it into C code simulating the processor, and then uses an existing C verifier to either prove the correctness of the assembler program or find errors in it. First experiments on applying Vx86 on the Windows Hypervisor code base are encouraging. Vx86 verified the Windows Hypervisor's memory safety, arithmetic safety, call safety and interrupt safety.},
  address = {Berlin, Heidelberg},
  author = {Stefan Maus and Michał Moskal and Wolfram Schulte},
  booktitle = {Algebraic Methodology and Software Technology: 12th International Conference, AMAST 2008 Urbana, IL, USA, July 28-31, 2008 Proceedings},
  doi = {10.1007/978-3-540-79980-1_22},
  isbn = {978-3-540-79980-1},
  pages = {284-298},
  publisher = {Springer},
  title = {{Vx86: x86 assembler simulated in C powered by automated theorem proving}},
  year = {2008}
}

@inproceedings{mavin:isre:2009,
  author = {Alistair Mavin and Philip Wilkinson and Adrian Harwood and Mark Novak},
  booktitle = {17th IEEE International Requirements Engineering Conference (RE'09)},
  doi = {10.1109/RE.2009.9},
  publisher = {IEEE},
  title = {{Easy approach to requirements syntax (EARS)}},
  year = {2009}
}

@article{mcbride:jfp:2002,
  author = {CONOR McBRIDE},
  doi = {10.1017/S0956796802004355},
  journal = {Journal of Functional Programming},
  number = {4-5},
  pages = {375-392},
  publisher = {Cambridge University Press},
  title = {{Faking it: Simulating dependent types in Haskell}},
  volume = {12},
  year = {2002}
}

@misc{mcilroy:arxiv:2019,
  archiveprefix = {arXiv},
  author = {Ross Mcilroy and Jaroslav Sevcik and Tobias Tebbi and Ben L. Titzer and Toon Verwaest},
  eprint = {1902.05178},
  primaryclass = {cs.PL},
  title = {{Spectre is here to stay: An analysis of side-channels and speculative execution}},
  year = {2019}
}

@inproceedings{mcmillan:cav:1998,
  abstract = {An implementation of an out-of-order processing unit based on Tomasulo's algorithm is formally verified using compositional model checking techniques. This demonstrates that finite-state methods can be applied to such algorithms, without recourse to higher-order proof systems. The paper introduces a novel compositional system that supports cyclic environment reasoning and multiple environment abstractions per signal. A proof of Tomasulo's algorithm is outlined, based on refinement maps, and relying on the novel features of the compositional system. This proof is fully verified by the SMV verifier, using symmetry to reduce the number of assertions that must be verified.},
  address = {Berlin, Heidelberg},
  author = {Kenneth L. McMillan},
  booktitle = {Computer Aided Verification: 10th International Conference, CAV'98 Vancouver, BC, Canada, June 28 - July 2, 1998 Proceedings},
  doi = {10.1007/BFb0028738},
  isbn = {978-3-540-69339-0},
  pages = {110-121},
  publisher = {Springer},
  title = {{Verification of an implementation of Tomasulo's algorithm by compositional model checking}},
  year = {1998}
}

@inbook{mcmillan:ecs:2003,
  address = {GBR},
  author = {Kenneth L. McMillan},
  booktitle = {Encyclopedia of Computer Science},
  isbn = {0470864125},
  numpages = {5},
  pages = {1177-1181},
  publisher = {John Wiley and Sons Ltd.},
  title = {{Model checking}},
  year = {2003}
}

@inproceedings{mcmillan:sigcomm:2019,
  abstract = {QUIC is a new Internet secure transport protocol currently in the process of IETF standardization. It is intended as a replacement for the TLS/TCP stack and will be the basis of HTTP/3, the next official version of the hypertext transfer protocol. As a result, it is likely, in the near future, to carry a substantial fraction of traffic on the Internet. We describe our experience applying a methodology of compositional specification-based testing to QUIC. We develop a formal specification of the wire protocol, and use this specification to generate automated randomized testers for implementations of QUIC. The testers effectively take one role of the QUIC protocol, interacting with the other role to generate full protocol executions, and verifying that the implementations conform to the formal specification. This form of testing generates significantly more diverse stimuli and stronger correctness criteria than interoperability testing, the primary method used to date to validate QUIC and its implementations. As a result, numerous implementation errors have been found. These include some vulnerabilities at the protocol and implementation levels, such as an off-path denial of service scenario and an information leak similar to the "heartbleed" vulnerability in OpenSSL.},
  address = {New York, NY, USA},
  author = {Kenneth L. McMillan and Lenore D. Zuck},
  booktitle = {Proceedings of the ACM Special Interest Group on Data Communication},
  doi = {10.1145/3341302.3342087},
  isbn = {9781450359566},
  link = {https://doi.org/10.1145/3341302.3342087},
  location = {Beijing, China},
  numpages = {14},
  pages = {227-240},
  publisher = {Association for Computing Machinery},
  series = {SIGCOMM '19},
  title = {{Formal specification and testing of QUIC}},
  url = {https://doi.org/10.1145/3341302.3342087},
  year = {2019}
}

@inproceedings{mechtaev:fse:2018,
  abstract = {Symbolic execution systematically explores program paths by solving path conditions -- formulas over symbolic variables. Typically, the symbolic variables range over numbers, arrays and strings. We introduce symbolic execution with existential second-order constraints -- an extension of traditional symbolic execution that allows symbolic variables to range over functions whose interpretations are restricted by a user-defined language. The aims of this new technique are twofold. First, it offers a general analysis framework that can be applied in multiple domains such as program repair and library modelling. Secondly, it addresses the path explosion problem of traditional first-order symbolic execution in certain applications. To realize this technique, we integrate symbolic execution with program synthesis. Specifically, we propose a method of second-order constraint solving that provides efficient proofs of unsatisfiability, which is critical for the performance of symbolic execution. Our evaluation shows that the proposed technique (1) helps to repair programs with loops by mitigating the path explosion, (2) can enable analysis of applications written against unavailable libraries by modelling these libraries from the usage context.},
  address = {New York, NY, USA},
  author = {Sergey Mechtaev and Alberto Griggio and Alessandro Cimatti and Abhik Roychoudhury},
  booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3236024.3236049},
  isbn = {9781450355735},
  keywords = {Library modelling, Program repair, Program synthesis},
  link = {https://doi.org/10.1145/3236024.3236049},
  location = {Lake Buena Vista, FL, USA},
  numpages = {11},
  pages = {389-399},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2018},
  title = {{Symbolic execution with existential second-order constraints}},
  url = {https://doi.org/10.1145/3236024.3236049},
  year = {2018}
}

@inproceedings{merz:vstte:2012,
  abstract = {Bounded model checking (BMC) of C and C++ programs is challenging due to the complex and intricate syntax and semantics of these programming languages. The BMC tool LLBMC presented in this paper thus uses the LLVM compiler framework in order to translate C and C++ programs into LLVM\textquotesingle s intermediate representation. The resulting code is then converted into a logical representation and simplified using rewrite rules. The simplified formula is finally passed to an SMT solver. In contrast to many other tools, LLBMC uses a flat, bit-precise memory model. It can thus precisely model, e.g., memory-based re-interpret casts as used in C and static/dynamic casts as used in C++. An empirical evaluation shows that LLBMC compares favorable to the related BMC tools CBMC and ESBMC.},
  address = {Berlin, Heidelberg},
  author = {Florian Merz and Stephan Falke and Carsten Sinz},
  booktitle = {Verified Software: Theories, Tools, Experiments},
  doi = {10.1007/978-3-642-27705-4_12},
  editor = {Joshi, Rajeev and Müller, Peter and Podelski, Andreas},
  isbn = {978-3-642-27705-4},
  pages = {146-161},
  publisher = {Springer Berlin Heidelberg},
  title = {{LLBMC: Bounded model checking of C and C++ programs using a compiler IR}},
  year = {2012}
}

@article{miller:cacm:1990,
  address = {New York, NY, USA},
  author = {Barton P. Miller and Louis Fredriksen and Bryan So},
  doi = {10.1145/96267.96279},
  issn = {0001-0782},
  issue_date = {Dec. 1990},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/96267.96279},
  month = {December},
  number = {12},
  numpages = {13},
  pages = {32-44},
  publisher = {Association for Computing Machinery},
  title = {{An empirical study of the reliability of UNIX utilities}},
  url = {https://doi.org/10.1145/96267.96279},
  volume = {33},
  year = {1990}
}

@article{milner:jcss:1978,
  author = {Robin Milner},
  doi = {10.1016/0022-0000(78)90014-4},
  issn = {0022-0000},
  journal = {Journal of Computer and System Sciences},
  number = {3},
  pages = {348 - 375},
  title = {{A theory of type polymorphism in programming}},
  volume = {17},
  year = {1978}
}

@inproceedings{milushev:forte:2012,
  abstract = {Noninterference is a high-level security property that guarantees the absence of illicit information flow at runtime. Noninterference can be enforced statically using information flow type systems; however, these are criticized for being overly conservative and rejecting secure programs. More precision can be achieved by using program logics, but such an approach lacks its own verification tools. In this work we propose a novel, alternative approach: utilizing symbolic execution in combination with ideas from program logics in an attempt to increase the precision of analyses and automate noninterference testing. Dealing with policies incorporating declassification is also explored. The feasibility of the proposal is illustrated using a prototype tool based on the KLEE symbolic execution engine.},
  address = {Berlin, Heidelberg},
  author = {Dimiter Milushev and Wim Beck and Dave Clarke},
  booktitle = {Formal Techniques for Distributed Systems},
  editor = {Giese, Holger and Rosu, Grigore},
  isbn = {978-3-642-30793-5},
  pages = {152-168},
  publisher = {Springer Berlin Heidelberg},
  title = {{Noninterference via symbolic execution}},
  year = {2012}
}

@book{mishra:book:2008,
  address = {San Francisco, CA, USA},
  author = {Prabhat Mishra and Nikil Dutt},
  isbn = {9780080558370, 9780123742872},
  publisher = {Morgan Kaufmann Publishers Inc.},
  title = {{Processor description languages}},
  year = {2008}
}

@article{monteiro:arxiv:2019,
  author = {Felipe R. Monteiro and Mikhail R. Gadelha and Lucas C. Cordeiro},
  journal = {arXiv preprint arXiv:1904.06152},
  title = {{Boost the impact of continuous formal verification in industry}},
  year = {2019}
}

@inproceedings{morrisett:pldi:2012,
  acmid = {2254111},
  address = {New York, NY, USA},
  author = {Greg Morrisett and Gang Tan and Joseph Tassarotti and Jean-Baptiste Tristan and Edward Gan},
  booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2254064.2254111},
  isbn = {978-1-4503-1205-9},
  keywords = {domain-specific languages, software fault isolation},
  location = {Beijing, China},
  numpages = {10},
  pages = {395-404},
  publisher = {ACM},
  series = {PLDI '12},
  title = {{RockSalt: Better, faster, stronger SFI for the x86}},
  year = {2012}
}

@inproceedings{morrisett:wcsss:1999,
  author = {Greg Morrisett and Karl Crary and Neal Glew and Dan Grossman and Richard Samuels and Frederick Smith and David Walker and Stephanie Weirich and Steve Zdancewic},
  booktitle = {In Second Workshop on Compiler Support for System Software},
  pages = {25-35},
  title = {{TALx86: A realistic typed assembly language}},
  year = {1999}
}

@inproceedings{muller:vmcai:2016,
  abstract = {The automation of verification techniques based on first-order logic specifications has benefitted greatly from verification infrastructures such as Boogie and Why. These offer an intermediate language that can express diverse language features and verification techniques, as well as back-end tools: in particular, verification condition generators.},
  address = {Berlin, Heidelberg},
  author = {Peter Müller and Malte Schwerhoff and Alexander J. Summers},
  booktitle = {Verification, Model Checking, and Abstract Interpretation},
  doi = {/10.1007/978-3-662-49122-5_2},
  editor = {Jobstmann, Barbara and Leino, K. Rustan M.},
  isbn = {978-3-662-49122-5},
  pages = {41-62},
  publisher = {Springer Berlin Heidelberg},
  title = {{Viper: A verification infrastructure for permission-based reasoning}},
  year = {2016}
}

@inproceedings{murray:secdev:2018,
  abstract = {Given recent high-profile successes in formal verification of security-related properties (e.g., for seL4), and the rising popularity of applying formal methods to cryptographic libraries and security protocols like TLS, we revisit the meaning of security-related proofs about software. We re-examine old issues, and identify new questions that have escaped scrutiny in the formal methods literature. We consider what value proofs about software systems deliver to end-users (e.g., in terms of net assurance benefits), and at what cost in terms of side effects (such as changes made to software to facilitate the proofs, and assumption-related deployment restrictions imposed on software if these proofs are to remain valid in operation). We consider in detail, for the first time to our knowledge, possible relationships between proofs and side effects. To make our discussion concrete, we draw on tangible examples, experience, and the literature.},
  author = {Toby Murray and Paul van Oorschot},
  booktitle = {2018 IEEE Cybersecurity Development (SecDev)},
  doi = {10.1109/SecDev.2018.00009},
  issn = {},
  keywords = {cryptographic protocols;formal specification;formal verification;security of data;BP;formal proofs;fine print;high-profile successes;formal verification;security-related properties;cryptographic libraries;security protocols;security-related proofs;formal methods literature;software systems;side effects;TLS;Security;Computational modeling;Cognition;Kernel;Arrays;Conferences;formal verification;computer security;software engineering},
  month = {Sep.},
  number = {},
  pages = {1-10},
  title = {{BP: Formal proofs, the fine print and side effects}},
  volume = {},
  year = {2018}
}

@inproceedings{murray:secpriv:2013,
  author = {Toby Murray and Daniel Matichuk and Matthew Brassil and Peter Gammie and Timothy Bourke and Sean Seefried and Corey Lewis and Xin Gao and Gerwin Klein},
  booktitle = {2013 IEEE Symposium on Security and Privacy},
  doi = {10.1109/SP.2013.35},
  organization = {IEEE},
  pages = {415-429},
  title = {{seL4: from general purpose to a proof of information flow enforcement}},
  year = {2013}
}

@inproceedings{mycroft:esop:1999,
  abstract = {We describe a system which decompiles (reverse engineers) C programs from target machine code by type-inference techniques. This extends recent trends in the converse process of compiling high-level languages whereby type information is preserved during compilation. The algorithms remain independent of the particular architecture by virtue of treating target instructions as register-transfer specifications. Target code expressed in such RTL form is then transformed into SSA form (undoing register colouring etc.); this then generates a set of type constraints. Iteration and recursion over data-structures causes synthesis of appropriate recursive C structs; this is triggered by and resolves occurs-check constraint violation. Other constraint violations are resolved by C's casts and unions. In the limit we use heuristics to select between equally suitable C code -- a good GUI would clearly facilitate its professional use.},
  address = {Berlin, Heidelberg},
  author = {Alan Mycroft},
  booktitle = {Programming Languages and Systems},
  editor = {Swierstra, S. Doaitse},
  isbn = {978-3-540-49099-9},
  pages = {208-223},
  publisher = {Springer Berlin Heidelberg},
  title = {{Type-based decompilation (or program reconstruction via type reconstruction)}},
  year = {1999}
}

@article{myers:computer:2016,
  address = {Los Alamitos, CA, USA},
  author = {Brad A. Myers and Amy J. Ko and Thomas D. LaToza and YoungSeok Yoon},
  doi = {10.1109/MC.2016.200},
  issn = {1558-0814},
  journal = {Computer},
  keywords = {human computer interaction;software engineering;programming;human-computer interaction;human-centered computing;data mining;natural language processing},
  month = {jul},
  number = {07},
  pages = {44-52},
  publisher = {IEEE Computer Society},
  title = {{Programmers are users too: Human-centered methods for improving programming tools}},
  volume = {49},
  year = {2016}
}

@inproceedings{myers:csfw:2004,
  author = {Andrew C. Myers and Andrei Sabelfeld and Steve Zdancewic},
  booktitle = {Proceedings 17th IEEE Computer Security Foundations Workshop},
  doi = {10.1109/CSFW.2004.1310740},
  issn = {1063-6900},
  keywords = {data flow analysis;security of data;robust control;data integrity;robust declassification;noninterference;public data;sensitive information;information flow control;information release;downgrading mechanism;program characterization;attackers;type-based program analysis;compile-time program analysis;data integrity;Robustness;Information security;Mechanical factors;Data security;Computer science;Control systems;Computer languages;Computer security;Data flow computing;Information science},
  month = {June},
  number = {},
  pages = {172-186},
  title = {{Enforcing robust declassification}},
  volume = {},
  year = {2004}
}

@inbook{myreen:itp:2012,
  abstract = {This paper presents a method which simplifies verification of deeply embedded functional programs. We present a technique by which proof-certified equations describing the effect of functional programs (shallow embeddings) can be automatically extracted from their operational semantics. Our method can be used in reverse, i.e. from shallow to deep embeddings, and thus for implementing certifying code synthesis: we have implemented a tool which maps HOL functions to equivalent Lisp functions, for which we have a verified Lisp runtime. A key benefit, in both directions, is that the verifier does not need to understand the operational semantics that gives meanings to the deep embeddings.},
  address = {Berlin, Heidelberg},
  author = {Magnus O. Myreen},
  booktitle = {Interactive Theorem Proving: Third International Conference, ITP 2012, Princeton, NJ, USA, August 13-15, 2012. Proceedings},
  doi = {10.1007/978-3-642-32347-8_29},
  isbn = {978-3-642-32347-8},
  pages = {412-417},
  publisher = {Springer},
  title = {{Functional programs: Conversions between deep and shallow embeddings}},
  year = {2012}
}

@inproceedings{myreen:tphols:2009,
  author = {Magnus O. Myreen and Michael J. C. Gordon},
  booktitle = {Theorem Proving in Higher Order Logics (TPHOLs)},
  doi = {10.1007/978-3-642-03359-9_25},
  editor = {Stefan Berghofer and Tobias Nipkow and Christian Urban and Makarius Wenzel},
  pages = {359-374},
  publisher = {Springer},
  title = {{Verified LISP Implementations on ARM, x86 and PowerPC}},
  year = {2009}
}

@inproceedings{naik:popl:2012,
  acmid = {2103701},
  address = {New York, NY, USA},
  author = {Mayur Naik and Hongseok Yang and Ghila Castelnuovo and Mooly Sagiv},
  booktitle = {Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/2103656.2103701},
  isbn = {978-1-4503-1083-3},
  keywords = {necessary-condition problem, parametrised static analysis, points-to analysis, testing, thread-escape analysis},
  location = {Philadelphia, PA, USA},
  numpages = {14},
  pages = {373-386},
  publisher = {ACM},
  series = {POPL '12},
  title = {{Abstractions from tests}},
  year = {2012}
}

@inproceedings{nanevski:icfp:2008,
  address = {New York, NY, USA},
  author = {Aleksandar Nanevski and Greg Morrisett and Avraham Shinnar and Paul Govereau and Lars Birkedal},
  booktitle = {Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/1411204.1411237},
  isbn = {9781595939197},
  keywords = {monads, type theory, Hoare logic, separation logic},
  location = {Victoria, BC, Canada},
  numpages = {12},
  pages = {229–240},
  publisher = {Association for Computing Machinery},
  series = {ICFP '08},
  title = {{Ynot: Dependent types for imperative programs}},
  url = {https://doi.org/10.1145/1411204.1411237},
  year = {2008}
}

@article{nanevski:oopsla:2019,
  address = {New York, NY, USA},
  articleno = {Article 161},
  author = {Aleksandar Nanevski and Anindya Banerjee and Germán Andrés Delbianco and Ignacio Fábregas},
  doi = {10.1145/3360587},
  issue_date = {October 2019},
  journal = {Proc. ACM Program. Lang.},
  keywords = {Program Logics for Concurrency, Hoare/Separation Logics, Coq},
  month = {October},
  number = {OOPSLA},
  numpages = {30},
  publisher = {Association for Computing Machinery},
  title = {{Specifying concurrent programs in separation logic: Morphisms and simulations}},
  url = {https://doi.org/10.1145/3360587},
  volume = {3},
  year = {2019}
}

@inproceedings{narayanan:hotos:2019,
  author = {Vikram Narayanan and Marek S. Baranowski and Leonid Ryzhyk and Zvonimir Rakamarić and Anton Burtsev},
  booktitle = {Proceedings of the Workshop on Hot Topics in Operating Systems},
  doi = {10.1145/3317550.3321449},
  organization = {ACM},
  pages = {37-44},
  title = {{RedLeaf: Towards an operating system for safe and verified firmware}},
  year = {2019}
}

@inproceedings{naumann:fmco:2004,
  abstract = {In object-oriented programming, reentrant method invocations and shared references make it difficult to achieve adequate encapsulation for sound modular reasoning. This tutorial paper surveys recent progress using auxiliary state (ghost fields) to describe and achieve encapsulation. Encapsulation is assessed in terms of modular reasoning about invariants and simulations.},
  address = {Berlin, Heidelberg},
  author = {David A. Naumann},
  booktitle = {Formal Methods for Components and Objects},
  doi = {10.1007/11561163_11},
  editor = {de Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and de Roever, Willem-Paul},
  isbn = {978-3-540-31939-9},
  pages = {251-273},
  publisher = {Springer Berlin Heidelberg},
  title = {{Assertion-based encapsulation, object invariants and simulations}},
  year = {2005}
}

@inproceedings{necula:cc:2002,
  abstract = {This paper describes the C Intermediate Language: a highlevel representation along with a set of tools that permit easy analysis and source-to-source transformation of C programs.},
  address = {Berlin, Heidelberg},
  author = {George C. Necula and Scott McPeak and Shree P. Rahul and Westley Weimer},
  booktitle = {Compiler Construction},
  doi = {10.1007/3-540-45937-5_16},
  editor = {Horspool, R. Nigel},
  isbn = {978-3-540-45937-8},
  pages = {213-228},
  publisher = {Springer Berlin Heidelberg},
  title = {{CIL: Intermediate language and tools for analysis and transformation of C programs}},
  year = {2002}
}

@inproceedings{necula:pldi:2000,
  acmid = {349314},
  author = {George C. Necula},
  booktitle = {Proceedings of the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation},
  doi = {10.1145/349299.349314},
  isbn = {1-58113-199-2},
  location = {Vancouver, British Columbia, Canada},
  numpages = {12},
  pages = {83-94},
  publisher = {ACM},
  series = {PLDI '00},
  title = {{Translation validation for an optimizing compiler}},
  year = {2000}
}

@inproceedings{necula:popl:1997,
  address = {New York, NY, USA},
  author = {George C. Necula},
  booktitle = {Proceedings of the 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/263699.263712},
  isbn = {0897918533},
  link = {https://doi.org/10.1145/263699.263712},
  location = {Paris, France},
  numpages = {14},
  pages = {106-119},
  publisher = {Association for Computing Machinery},
  series = {POPL '97},
  title = {{Proof-carrying code}},
  url = {https://doi.org/10.1145/263699.263712},
  year = {1997}
}

@inproceedings{nelson:sosp:2017,
  author = {Luke Nelson and Helgi Sigurbjarnarson and Kaiyuan Zhang and Dylan Johnson and James Bornholt and Emina Torlak and Xi Wang},
  booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
  doi = {10.1145/3132747.3132748},
  organization = {ACM},
  pages = {252-269},
  title = {{Hyperkernel: Push-button verification of an OS kernel}},
  year = {2017}
}

@inproceedings{nelson:sosp:2019,
  author = {Luke Nelson and James Bornholt and Ronghui Gu and Andrew Baumann and Emina Torlak and Xi Wang},
  booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles (SOSP)},
  doi = {10.1145/3341301.3359641},
  title = {{Scaling symbolic evaluation for automated verification of systems code with Serval}},
  year = {2019}
}

@misc{nicole:arxiv:2020,
  archiveprefix = {arXiv},
  author = {Olivier Nicole and Matthieu Lemerre and Sébastien Bardin and Xavier Rival},
  eprint = {2011.15065},
  primaryclass = {cs.CR},
  title = {{No crash, no exploit: Automated verification of embedded kernels}},
  year = {2020}
}

@article{niemetz:jsat:2015,
  author = {Aina Niemetz and Mathias Preiner and Armin Biere},
  doi = {10.3233/SAT190101},
  journal = {JSAT},
  link = {https://satassociation.org/jsat/index.php/jsat/article/view/120},
  pages = {53-58},
  title = {{Boolector 2.0}},
  url = {https://satassociation.org/jsat/index.php/jsat/article/view/120},
  volume = {9},
  year = {2015}
}

@inproceedings{nienhuis:secpriv:2020,
  address = {Los Alamitos, CA, USA},
  author = {Kyndylan Nienhuis and Alexandre Joannou and Thomas Bauereiss and Anthony C. J. Fox and Michael Roe and Brian Campbell and Matthew Naylor and Robert M. Norton and Simon W. Moore and Peter G. Neumann and Ian Stark and Robert N. M. Watson and Peter Sewell},
  booktitle = {2020 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP40000.2020.00055},
  issn = {2375-1207},
  keywords = {},
  link = {https://doi.ieeecomputersociety.org/10.1109/SP40000.2020.00055},
  month = {May},
  pages = {1007-1024},
  publisher = {IEEE Computer Society},
  title = {{Rigorous engineering for hardware security: Formal modelling and proof in the CHERI design and implementation process}},
  url = {https://doi.ieeecomputersociety.org/10.1109/SP40000.2020.00055},
  volume = {},
  year = {2020}
}

@book{nipkow:book:2002,
  address = {Berlin, Heidelberg},
  author = {Tobias Nipkow and Markus Wenzel and Lawrence C. Paulson},
  doi = {10.1007/3-540-45949-9},
  isbn = {3-540-43376-7},
  publisher = {Springer-Verlag},
  title = {{Isabelle/HOL: A proof assistant for higher-order logic}},
  year = {2002}
}

@inproceedings{noonan:pldi:2016,
  address = {New York, NY, USA},
  author = {Matt Noonan and Alexey Loginov and David R. Cok},
  booktitle = {Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2908080.2908119},
  isbn = {9781450342612},
  keywords = {Binary Analysis, Reverse Engineering, Type Systems, Pushdown Automata, Polymorphism, Static Analyiss},
  link = {https://doi.org/10.1145/2908080.2908119},
  location = {Santa Barbara, CA, USA},
  numpages = {15},
  pages = {27-41},
  publisher = {Association for Computing Machinery},
  series = {PLDI '16},
  title = {{Polymorphic type inference for machine code}},
  url = {https://doi.org/10.1145/2908080.2908119},
  year = {2016}
}

@inproceedings{nyxbrain:sc2:2017,
  author = {Martin Nyx Brain and James H. Davenport and Alberto Griggio},
  booktitle = {Proceedings of the 2nd International Workshop on Satisfiability Checking and Symbolic Computation (SC-Square 2017)},
  month = {July},
  title = {{Benchmarking solvers, SAT-style}},
  url = {http://ceur-ws.org/Vol-1974/},
  year = {2017}
}

@inproceedings{oberg:dac:2010,
  author = {Jason Oberg and Wei Hu and Ali Irturk and Mohit Tiwari and Timothy Sherwood and Ryan Kastner},
  booktitle = {Proceedings of the 47th Design Automation Conference},
  doi = {10.1145/1837274.1837337},
  organization = {ACM},
  pages = {244-247},
  title = {{Theoretical analysis of gate level information flow tracking}},
  year = {2010}
}

@article{ohearn:cacm:2019,
  address = {New York, NY, USA},
  author = {Peter W. O'Hearn},
  doi = {10.1145/3211968},
  issn = {0001-0782},
  issue_date = {January 2019},
  journal = {Communications of the ACM},
  month = {January},
  number = {2},
  numpages = {10},
  pages = {86-95},
  publisher = {Association for Computing Machinery},
  title = {{Separation logic}},
  url = {https://doi.org/10.1145/3211968},
  volume = {62},
  year = {2019}
}

@article{ohearn:popl:2019,
  abstract = {Program correctness and incorrectness are two sides of the same coin. As a programmer, even if you would like to have correctness, you might find yourself spending most of your time reasoning about incorrectness. This includes informal reasoning that people do while looking at or thinking about their code, as well as that supported by automated testing and static analysis tools. This paper describes a simple logic for program incorrectness which is, in a sense, the other side of the coin to Hoare's logic of correctness.},
  address = {New York, NY, USA},
  articleno = {10},
  author = {Peter W. O'Hearn},
  doi = {10.1145/3371078},
  issue_date = {January 2020},
  journal = {Proc. ACM Program. Lang.},
  keywords = {none},
  link = {https://doi.org/10.1145/3371078},
  month = {December},
  number = {POPL},
  numpages = {32},
  publisher = {Association for Computing Machinery},
  title = {{Incorrectness logic}},
  url = {https://doi.org/10.1145/3371078},
  volume = {4},
  year = {2019}
}

@article{ohearn:tcs:2007,
  author = {Peter W. O'Hearn},
  journal = {Theoretical computer science},
  number = {1-3},
  pages = {271-307},
  publisher = {Elsevier},
  title = {{Resources, concurrency, and local reasoning}},
  volume = {375},
  year = {2007}
}

@inproceedings{ousterhout:usenix:1996,
  author = {John Ousterhout},
  booktitle = {USENIX 1996 Technical Conference},
  month = {June},
  title = {{Why threads are a bad idea (for most purposes) (Invited talk)}},
  year = {1996}
}

@inproceedings{ozer:sbacpad:2007,
  abstract = {In this paper, we propose two low-cost and novel branch history buffer handling schemes aiming at skewing the branch prediction accuracy in favor of a real-time thread for a soft real-time embedded multithreaded processor. The processor core accommodates two running threads, one with the highest priority and the other thread is a background thread, and both threads share the branch predictor. The first scheme uses a 3-bit branch history buffer in which the highest priority thread uses the most significant 2 bits to change the prediction state while the background thread uses only the least significant 2 bits. The second scheme uses the shared 2-bit branch history buffer that implements integer updates for the highest priority thread but fractional updates for the background thread in order to achieve relatively higher prediction accuracy in the highest priority thread. The low cost nature of these two schemes, particularly in the second scheme, makes them attractive with moderate improvement in the performance of the highest priority thread.},
  affiliation = {ARM Ltd},
  ar_shortname = {SBAC-PAD 07},
  author = {Emre Özer and Alastair D. Reid and Stuart Biles},
  booktitle = {19th Symposium on Computer Architecture and High Performance Computing (SBAC-PAD 2007)},
  day = {24-27},
  doi = {10.1109/SBAC-PAD.2007.15},
  location = {Gramado, RS, Brazil},
  month = {October},
  pages = {37-44},
  publisher = {IEEE Computer Society},
  title = {{Low-cost techniques for reducing branch context pollution in a soft realtime embedded multithreaded processor}},
  year = {2007}
}

@inproceedings{padhye:issta:2019,
  abstract = {Programs expecting structured inputs often consist of both a syntactic analysis stage, which parses raw input, and a semantic analysis stage, which conducts checks on the parsed input and executes the core logic of the program. Generator-based testing tools in the lineage of QuickCheck are a promising way to generate random syntactically valid test inputs for these programs. We present Zest, a technique which automatically guides QuickCheck-like random input generators to better explore the semantic analysis stage of test programs. Zest converts random-input generators into deterministic parametric input generators. We present the key insight that mutations in the untyped parameter domain map to structural mutations in the input domain. Zest leverages program feedback in the form of code coverage and input validity to perform feedback-directed parameter search. We evaluate Zest against AFL and QuickCheck on five Java programs: Maven, Ant, BCEL, Closure, and Rhino. Zest covers 1.03x-2.81x as many branches within the benchmarks' semantic analysis stages as baseline techniques. Further, we find 10 new bugs in the semantic analysis stages of these benchmarks. Zest is the most effective technique in finding these bugs reliably and quickly, requiring at most 10 minutes on average to find each bug.},
  address = {New York, NY, USA},
  author = {Rohan Padhye and Caroline Lemieux and Koushik Sen and Mike Papadakis and Yves Le Traon},
  booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  doi = {10.1145/3293882.3330576},
  isbn = {9781450362245},
  keywords = {random testing, property-based testing, Structure-aware fuzzing},
  link = {https://doi.org/10.1145/3293882.3330576},
  location = {Beijing, China},
  numpages = {12},
  pages = {329-340},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2019},
  title = {{Semantic fuzzing with Zest}},
  url = {https://doi.org/10.1145/3293882.3330576},
  year = {2019}
}

@article{padhye:oopsla:2019,
  abstract = {Coverage-guided fuzz testing has gained prominence as a highly effective method of finding security vulnerabilities such as buffer overflows in programs that parse binary data. Recently, researchers have introduced various specializations to the coverage-guided fuzzing algorithm for different domain-specific testing goals, such as finding performance bottlenecks, generating valid inputs, handling magic-byte comparisons, etc. Each such solution can require non-trivial implementation effort and produces a distinct variant of a fuzzing tool. We observe that many of these domain-specific solutions follow a common solution pattern. In this paper, we present FuzzFactory, a framework for developing domain-specific fuzzing applications without requiring changes to mutation and search heuristics. FuzzFactory allows users to specify the collection of dynamic domain-specific feedback during test execution, as well as how such feedback should be aggregated. FuzzFactory uses this information to selectively save intermediate inputs, called waypoints, to augment coverage-guided fuzzing. Such waypoints always make progress towards domain-specific multi-dimensional objectives. We instantiate six domain-specific fuzzing applications using FuzzFactory: three re-implementations of prior work and three novel solutions, and evaluate their effectiveness on benchmarks from Google's fuzzer test suite. We also show how multiple domains can be composed to perform better than the sum of their parts. For example, we combine domain-specific feedback about strict equality comparisons and dynamic memory allocations, to enable the automatic generation of LZ4 bombs and PNG bombs.},
  address = {New York, NY, USA},
  articleno = {174},
  author = {Rohan Padhye and Caroline Lemieux and Koushik Sen and Laurent Simon and Hayawardh Vijayakumar},
  doi = {10.1145/3360600},
  issue_date = {October 2019},
  journal = {Proc. ACM Program. Lang.},
  keywords = {domain-specific fuzzing, frameworks, fuzz testing, waypoints},
  link = {https://doi.org/10.1145/3360600},
  month = {October},
  number = {OOPSLA},
  numpages = {29},
  publisher = {Association for Computing Machinery},
  title = {{FuzzFactory: Domain-specific fuzzing with waypoints}},
  url = {https://doi.org/10.1145/3360600},
  volume = {3},
  year = {2019}
}

@inproceedings{palacharla:micro:1995,
  author = {Subbarao Palacharla and James E. Smith},
  booktitle = {MICRO 28: Proceedings of International Symposium on Microarchitecture},
  doi = {10.1109/MICRO.1995.476836},
  isbn = {0-8186-7349-4},
  location = {Ann Arbor, Michigan, United States},
  pages = {285-290},
  title = {{Decoupling integer execution in superscalar processors}},
  year = {1995}
}

@inproceedings{pandey:issta:2019,
  abstract = {Concretization is an effective weapon in the armory of symbolic execution engines. However, concretization can lead to loss in coverage, path divergence, and generation of test-cases on which the intended bugs are not reproduced. In this paper, we propose an algorithm, Deferred Concretization, that uses a new category for values within symbolic execution (referred to as the symcrete values) to pend concretization till they are actually needed. Our tool, COLOSSUS, built around these ideas, was able to gain an average coverage improvement of 66.94\% and reduce divergence by more than 55\% relative to the state-of-the-art symbolic execution engine, KLEE. Moreover, we found that KLEE loses about 38.60\% of the states in the symbolic execution tree that COLOSSUS is able to recover, showing that COLOSSUS is capable of covering a much larger coverage space.},
  address = {New York, NY, USA},
  author = {Awanish Pandey and Phani Raj Goutham Kotcharlakota and Subhajit Roy},
  booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  doi = {10.1145/3293882.3330554},
  isbn = {9781450362245},
  keywords = {Fuzzing, Symbolic Execution, Software Testing},
  link = {https://doi.org/10.1145/3293882.3330554},
  location = {Beijing, China},
  numpages = {11},
  pages = {228-238},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2019},
  title = {{Deferred concretization in symbolic execution via fuzzing}},
  url = {https://doi.org/10.1145/3293882.3330554},
  year = {2019}
}

@incollection{papadakis:advances:2019,
  abstract = {Mutation testing realizes the idea of using artificial defects to support testing activities. Mutation is typically used as a way to evaluate the adequacy of test suites, to guide the generation of test cases, and to support experimentation. Mutation has reached a maturity phase and gradually gains popularity both in academia and in industry. This chapter presents a survey of recent advances, over the past decade, related to the fundamental problems of mutation testing and sets out the challenges and open problems for the future development of the method. It also collects advices on best practices related to the use of mutation in empirical studies of software testing. Thus, giving the reader a "mini-handbook"-style roadmap for the application of mutation testing as experimental methodology.},
  author = {Mike Papadakis and Marinos Kintis and Jie Zhang and Yue Jia and Yves Le Traon and Mark Harman},
  doi = {https://doi.org/10.1016/bs.adcom.2018.03.015},
  editor = {Atif M. Memon},
  issn = {0065-2458},
  keywords = {Mutation testing, Software testing, Survey, Seeded faults},
  link = {https://www.sciencedirect.com/science/article/pii/S0065245818300305},
  pages = {275-378},
  publisher = {Elsevier},
  series = {Advances in Computers},
  title = {{Mutation testing advances: An analysis and survey (chapter 6)}},
  url = {https://www.sciencedirect.com/science/article/pii/S0065245818300305},
  volume = {112},
  year = {2019}
}

@article{papaevripides:acmtps:2021,
  abstract = {Unsafe programming systems are still very popular, despite the shortcomings due to several published memory-corruption vulnerabilities. Toward defending memory corruption, compilers have started to employ advanced software hardening such as Control-flow Integrity (CFI) and SafeStack. However, there is a broad interest for realizing compilers that impose memory safety with no heavy runtime support (e.g., garbage collection). Representative examples of this category are Rust and Go, which enforce memory safety primarily statically at compile time.Software hardening and Rust/Go are promising directions for defending memory corruption, albeit combining the two is questionable. In this article, we consider hardened mixed binaries, i.e., machine code that has been produced from different compilers and, in particular, from hardened C/C++ and Rust/Go (e.g., Mozilla Firefox, Dropbox, npm, and Docker). Our analysis is focused on Mozilla Firefox, which outsources significant code to Rust and is open source with known public vulnerabilities (with assigned CVE). Furthermore, we extend our analysis in mixed binaries that leverage Go, and we derive similar results.The attacks explored in this article do not exploit Rust or Go binaries that depend on some legacy (vulnerable) C/C++ code. In contrast, we explore how Rust/Go compiled code can stand as a vehicle for bypassing hardening in C/C++ code. In particular, we discuss CFI and SafeStack, which are available in the latest Clang. Our assessment concludes that CFI can be completely nullified through Rust or Go code by constructing much simpler attacks than state-of-the-art CFI bypasses.},
  address = {New York, NY, USA},
  articleno = {7},
  author = {Michalis Papaevripides and Elias Athanasopoulos},
  doi = {10.1145/3418898},
  issn = {2471-2566},
  issue_date = {February 2021},
  journal = {ACM Transactions on Privacy and Security},
  keywords = {Memory safety, Go, SafeStack, Rust, CFI},
  link = {https://doi.org/10.1145/3418898},
  month = {January},
  number = {2},
  numpages = {29},
  publisher = {Association for Computing Machinery},
  title = {{Exploiting mixed binaries}},
  url = {https://doi.org/10.1145/3418898},
  volume = {24},
  year = {2021}
}

@article{parkinson:popl:2005,
  address = {New York, NY, USA},
  author = {Matthew Parkinson and Gavin Bierman},
  doi = {10.1145/1047659.1040326},
  issn = {0362-1340},
  issue_date = {January 2005},
  journal = {SIGPLAN Not.},
  keywords = {separation logic, classes, abstract data types, resources, modularity},
  month = {January},
  number = {1},
  numpages = {12},
  pages = {247-258},
  publisher = {Association for Computing Machinery},
  title = {{Separation logic and abstraction}},
  url = {https://doi.org/10.1145/1047659.1040326},
  volume = {40},
  year = {2005}
}

@article{patterson:cacm:1985,
  acmid = {214917},
  address = {New York, NY, USA},
  author = {David A. Patterson},
  doi = {10.1145/2465.214917},
  issn = {0001-0782},
  issue_date = {Jan. 1985},
  journal = {Communications of the ACM},
  month = {January},
  number = {1},
  numpages = {14},
  pages = {8-21},
  publisher = {ACM},
  title = {{Reduced instruction set computers}},
  volume = {28},
  year = {1985}
}

@article{patterson:sigarch:1980,
  acmid = {641917},
  address = {New York, NY, USA},
  author = {David A. Patterson and David R. Ditzel},
  doi = {10.1145/641914.641917},
  issn = {0163-5964},
  issue_date = {October 1980},
  journal = {SIGARCH Computer Architecture News},
  month = {October},
  number = {6},
  numpages = {9},
  pages = {25-33},
  publisher = {ACM},
  title = {{The case for the reduced instruction set computer}},
  volume = {8},
  year = {1980}
}

@book{pdp11:book:1973,
  author = {Digital Equipment Corporation},
  publisher = {Digital Equipment Corporation},
  title = {{PDP-11/45 processor handbook}},
  year = {1973}
}

@article{pearce:compsurv:2013,
  acmid = {2431216},
  address = {New York, NY, USA},
  articleno = {17},
  author = {Michael Pearce and Sherali Zeadally and Ray Hunt},
  doi = {10.1145/2431211.2431216},
  issn = {0360-0300},
  issue_date = {February 2013},
  journal = {ACM Computing Surveys},
  keywords = {Encryption, threat, virtual machine, virtual machine monitor, virtualization},
  month = {March},
  number = {2},
  numpages = {39},
  pages = {17:1-17:39},
  publisher = {ACM},
  title = {{Virtualization: Issues, security threats, and solutions}},
  url = {http://doi.acm.org/10.1145/2431211.2431216},
  volume = {45},
  year = {2013}
}

@article{peleg:micro:1996,
  acmid = {624024},
  address = {Los Alamitos, CA, USA},
  author = {Alex Peleg and Uri Weiser},
  doi = {10.1109/40.526924},
  issn = {0272-1732},
  issue_date = {August 1996},
  journal = {IEEE Micro},
  keywords = {Multimedia, Intel Architecture, MMX, MMX technology, SIMD},
  month = {August},
  number = {4},
  numpages = {9},
  pages = {42-50},
  publisher = {IEEE Computer Society Press},
  title = {{MMX technology extension to the Intel architecture}},
  volume = {16},
  year = {1996}
}

@inproceedings{penninckx:nfm:2012,
  abstract = {Case studies on formal software verification can be divided into two categories: while (i) unsound approaches may miss errors or report false-positive alarms due to coarse abstractions, (ii) sound approaches typically do not handle certain programming constructs like concurrency and/or suffer from scalability issues. This paper presents a case study on successfully verifying the Linux USB BP keyboard driver. Our verification approach is (a) sound, (b) takes into account dynamic memory allocation, complex API rules and concurrency, and (c) is applied on a real kernel driver which was not written with verification in mind. We employ VeriFast, a software verifier based on separation logic. Besides showing that it is possible to verify this device driver, we identify the parts where the verification went smoothly and the parts where the verification approach requires further research to be carried out.},
  address = {Berlin, Heidelberg},
  author = {Willem Penninckx and Jan Tobias Mühlberg and Jan Smans and Bart Jacobs and Frank Piessens},
  booktitle = {NASA Formal Methods},
  doi = {10.1007/978-3-642-28891-3_21},
  editor = {Goodloe, Alwyn E. and Person, Suzette},
  isbn = {978-3-642-28891-3},
  pages = {210-215},
  publisher = {Springer Berlin Heidelberg},
  title = {{Sound formal verification of Linux's USB BP keyboard driver}},
  year = {2012}
}

@inproceedings{person:fse:2008,
  abstract = {Detecting and characterizing the effects of software changes is a fundamental component of software maintenance. Version differencing information can be used to perform version merging, infer change characteristics, produce program documentation, and guide program re-validation. Existing techniques for characterizing code changes, however, are imprecise leading to unnecessary maintenance efforts.In this paper, we introduce a novel extension and application of symbolic execution techniques that computes a precise behavioral characterization of a program change. This technique, which we call differential symbolic execution (DSE), exploits the fact that program versions are largely similar to reduce cost and improve the quality of analysis results. We define the foundational concepts of DSE, describe cost-effective tool support for DSE, and illustrate its potential benefit through an exploratory study that considers version histories of two Java code bases.},
  address = {New York, NY, USA},
  author = {Suzette Person and Matthew B. Dwyer and Sebastian Elbaum and Corina S. Păsăreanu},
  booktitle = {Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  doi = {10.1145/1453101.1453131},
  isbn = {9781595939951},
  keywords = {software evolution, symbolic execution, program differencing},
  link = {https://doi.org/10.1145/1453101.1453131},
  location = {Atlanta, Georgia},
  numpages = {12},
  pages = {226-237},
  publisher = {Association for Computing Machinery},
  series = {SIGSOFT '08/FSE-16},
  title = {{Differential symbolic execution}},
  url = {https://doi.org/10.1145/1453101.1453131},
  year = {2008}
}

@inproceedings{peterson:hw:1995,
  affiliation = {Yale University},
  ar_shortname = {Haskell 95a},
  author = {John Peterson and Alastair D. Reid},
  booktitle = {Proceedings of the Haskell Workshop 1995, Yale University Research Report YALE/DCS/RR-1075},
  link = {https://www.haskell.org/haskell-workshop/1995/HW1995-Proceedings.pdf},
  location = {Portland, Oregon, USA},
  title = {{Adding records to Haskell}},
  url = {https://www.haskell.org/haskell-workshop/1995/HW1995-Proceedings.pdf},
  year = {1995}
}

@inproceedings{peterson:padl:2001,
  abstract = {Functional programming languages are not generally associated with computationally intensive tasks such as computer vision. We show that a declarative programming language like Haskell is effective for describing complex visual tracking systems. We have taken an existing C++ library for computer vision, called XVision, and used it to build FVision (pronounced ``fission''), a library of Haskell types and functions that provides a high-level interface to the lower-level XVision code. Using functional abstractions, users of FVision can build and test new visual tracking systems rapidly and reliably. The use of Haskell does not degrade system performance: computations are dominated by low-level calculations expressed in C++ while the Haskell ``glue code'' has a negligible impact on performance.  FVision is built using functional reactive programming (FRP) to express interaction in a purely functional manner. The resulting system demonstrates the viability of mixed-language programming: visual tracking programs continue to spend most of their time executing low-level image-processing code, while Haskell's advanced features allow us to develop and test systems quickly and with confidence. In this paper, we demonstrate the use of Haskell and FRP to express many basic abstractions of visual tracking.},
  affiliation = {Yale University},
  ar_shortname = {PADL 01},
  author = {John Peterson and Paul Hudak and Alastair D. Reid and Gregory D. Hager},
  booktitle = {Practical Aspects of Declarative Languages, Third International Symposium (PADL 2001)},
  day = {11-12},
  doi = {10.1007/3-540-45241-9_21},
  editor = {I. V. Ramakrishnan},
  location = {Las Vegas, Nevada, USA},
  month = {March},
  pages = {304-321},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  title = {{FVision: A declarative language for visual tracking}},
  volume = {1990},
  year = {2001}
}

@article{philippaerts:scp:2014,
  author = {Pieter Philippaerts and Jan Tobias Mühlberg and Willem Penninckx and Jan Smans and Bart Jacobs and Frank Piessens},
  doi = {10.1016/j.scico.2013.01.006},
  issn = {0167-6423},
  journal = {Science of Computer Programming },
  month = {3},
  number = {1},
  pages = {77-97},
  publisher = {North-Holland Pub. Co.},
  title = {{Software verification with VeriFast: Industrial case studies}},
  url = {https://lirias.kuleuven.be/95711},
  volume = {82},
  year = {2014}
}

@book{pierce:book:2016,
  author = {Benjamin C. Pierce and Arthur Azevedo de Amorim and Chris Casinghino and Marco Gaboardi and Michael Greenberg and Cătǎlin Hriţcu and Vilhelm Sjöberg and Brent Yorgey},
  bcp = {Yes},
  keys = {poplmark,books},
  link = {http://www.cis.upenn.edu/~bcpierce/sf},
  note = {Version 4.0.},
  plclub = {Yes},
  publisher = {Electronic textbook},
  title = {{Software foundations}},
  url = {http://www.cis.upenn.edu/~bcpierce/sf},
  year = {2016}
}

@inproceedings{pnueli:sfcs:1977,
  abstract = {A unified approach to program verification is suggested, which applies to both sequential and parallel programs. The main proof method suggested is that of temporal reasoning in which the time dependence of events is the basic concept. Two formal systems are presented for providing a basis for temporal reasoning. One forms a formalization of the method of intermittent assertions, while the other is an adaptation of the tense logic system Kb, and is particularly suitable for reasoning about concurrent programs.},
  author = {Amir Pnueli},
  booktitle = {18th Annual Symposium on Foundations of Computer Science (sfcs 1977)},
  doi = {10.1109/SFCS.1977.32},
  issn = {0272-5428},
  keywords = {Logic;Operating systems;Real time systems;Reasoning about programs;Stress;Power system modeling;Clocks;Programming profession;Safety;System recovery},
  month = {Oct},
  number = {},
  pages = {46-57},
  title = {{The temporal logic of programs}},
  volume = {},
  year = {1977}
}

@inproceedings{pnueli:tacas:1998,
  author = {Amir Pnueli and Michael Siegel and Eli Singerman},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  doi = {10.1007/BFb0054170},
  editor = {Steffen, Bernhard},
  isbn = {978-3-540-69753-4},
  pages = {151-166},
  publisher = {Springer},
  title = {{Translation validation}},
  year = {1998}
}

@inproceedings{poeplau:acsac:2019,
  abstract = {Symbolic execution has become a popular technique for software testing and vulnerability detection. Most implementations transform the program under analysis to some intermediate representation (IR), which is then used as a basis for symbolic execution. There is a multitude of available IRs, and even more approaches to transform target programs into a respective IR.When developing a symbolic execution engine, one needs to choose an IR, but it is not clear which influence the IR generation process has on the resulting system. What are the respective benefits for symbolic execution of generating IR from source code versus lifting machine code? Does the distinction even matter? What is the impact of not using an IR, executing machine code directly? We feel that there is little scientific evidence backing the answers to those questions. Therefore, we first develop a methodology for systematic comparison of different approaches to symbolic execution; we then use it to evaluate the impact of the choice of IR and IR generation. We make our comparison framework available to the community for future research.},
  address = {New York, NY, USA},
  author = {Sebastian Poeplau and Aurélien Francillon},
  booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
  doi = {10.1145/3359789.3359796},
  isbn = {9781450376280},
  keywords = {symbolic execution, intermediate representation},
  link = {https://doi.org/10.1145/3359789.3359796},
  location = {San Juan, Puerto Rico, USA},
  numpages = {14},
  pages = {163-176},
  publisher = {Association for Computing Machinery},
  series = {ACSAC '19},
  title = {{Systematic comparison of symbolic execution systems: Intermediate representation and its generation}},
  url = {https://doi.org/10.1145/3359789.3359796},
  year = {2019}
}

@inproceedings{poeplau:usenix:2020,
  author = {Sebastian Poeplau and Aurélien Francillon},
  booktitle = {29th USENIX Security Symposium (USENIX Security 20)},
  isbn = {978-1-939133-17-5},
  link = {https://www.usenix.org/conference/usenixsecurity20/presentation/poeplau},
  month = {August},
  pages = {181-198},
  publisher = {USENIX Association},
  title = {{Symbolic execution with SymCC: Don't interpret, compile!}},
  url = {https://www.usenix.org/conference/usenixsecurity20/presentation/poeplau},
  year = {2020}
}

@article{potvin:cacm:2016,
  abstract = {Google's monolithic repository provides a common source of truth for tens of thousands of developers around the world.},
  address = {New York, NY, USA},
  author = {Rachel Potvin and Josh Levenberg},
  doi = {10.1145/2854146},
  issn = {0001-0782},
  issue_date = {July 2016},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/2854146},
  month = {June},
  number = {7},
  numpages = {10},
  pages = {78-87},
  publisher = {Association for Computing Machinery},
  title = {{Why Google stores billions of lines of code in a single repository}},
  url = {https://doi.org/10.1145/2854146},
  volume = {59},
  year = {2016}
}

@inproceedings{qin:pldi:2020,
  address = {New York, NY, USA},
  author = {Boqin Qin and Yilun Chen and Zeming Yu and Linhai Song and Yiying Zhang},
  booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/3385412.3386036},
  isbn = {9781450376136},
  keywords = {Bug Study, Rust, Memory Bug, Concurrency Bug},
  link = {https://doi.org/10.1145/3385412.3386036},
  location = {London, UK},
  numpages = {17},
  pages = {763-779},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2020},
  title = {{Understanding memory and thread safety practices and issues in real-world Rust programs}},
  url = {https://doi.org/10.1145/3385412.3386036},
  year = {2020}
}

@inproceedings{qiu:icse:2017,
  abstract = {Symbolic execution is a systematic program analysis technique that has received a lot of attention in the research community. However, scaling symbolic execution continues to pose a major challenge. This paper introduces Synergise, a novel two-fold integration approach. One, it integrates distributed analysis and constraint re-use to enhance symbolic execution using feasible ranges, which allow sharing of constraint solving results among different workers without communicating or sharing potentially large constraint databases (as required traditionally). Two, it integrates complementary techniques for test input generation, e.g., search-based generation and symbolic execution, for creating higher quality tests using unexplored ranges, which allows symbolic execution to re-use tests created by another technique for effective distribution of exploration of previously unexplored paths.},
  author = {Rui Qiu and Sarfraz Khurshid and Corina S. Păsăreanu and Guowei Yang},
  booktitle = {2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C)},
  doi = {10.1109/ICSE-C.2017.116},
  issn = {},
  keywords = {constraint handling;distributed processing;program diagnostics;program testing;software reusability;distributed symbolic execution;test ranges;systematic program analysis;synergistic approach;two-fold integration;SynergiSE approach;distributed analysis;constraint reuse;feasible ranges;constraint databases;test input generation;search-based generation;unexplored ranges;Tools;Testing;Standards;Databases;Java;Software engineering;Systematics},
  month = {May},
  number = {},
  pages = {130-132},
  title = {{A synergistic approach for distributed symbolic execution using test ranges}},
  volume = {},
  year = {2017}
}

@inproceedings{qiu:nfm:2018,
  abstract = {Symbolic execution is a powerful systematic technique for checking programs, which has received a lot of research attention during the last decade. In practice however, the technique remains hard to scale. This paper introduces SynergiSE, a novel approach to improve symbolic execution by tackling a key bottleneck to its wider adoption: costly and incomplete constraint solving. To mitigate the cost, SynergiSE introduces a succinct encoding of constraint solving results, thereby enabling symbolic execution to be distributed among different workers while sharing and re-using constraint solving results among them without having to communicate databases of constraint solving results. To mitigate the incompleteness, SynergiSE introduces an integration of complementary approaches for testing, e.g., search-based test generation, with symbolic execution, thereby enabling symbolic execution and other techniques to apply in tandem. Experimental results using a suite of Java programs show that SynergiSE presents a promising approach for improving symbolic execution.},
  address = {Cham},
  author = {Rui Qiu and Sarfraz Khurshid and Corina S. Păsăreanu and Junye Wen and Guowei Yang},
  booktitle = {NASA Formal Methods},
  editor = {Dutle, Aaron and Mu{ñ}oz, César and Narkawicz, Anthony},
  isbn = {978-3-319-77935-5},
  pages = {416-434},
  publisher = {Springer International Publishing},
  title = {{Using test ranges to improve symbolic execution}},
  year = {2018}
}

@inproceedings{rakamaric:cav:2014,
  author = {Zvonimir Rakamarić and Michael Emmi},
  booktitle = {International Conference on Computer Aided Verification},
  doi = {10.1007/978-3-319-08867-9_7},
  organization = {Springer},
  pages = {106-113},
  title = {{SMACK: Decoupling source language details from verifier implementations}},
  year = {2014}
}

@inproceedings{ramos:cav:2011,
  abstract = {Verifying code equivalence is useful in many situations, such as checking: yesterday's code against today's, different implementations of the same (standardized) interface, or an optimized routine against a reference implementation. We present a tool designed to easily check the equivalence of two arbitrary C functions. The tool provides guarantees far beyond those possible with testing, yet it often requires less work than writing even a single test case. It automatically synthesizes inputs to the routines and uses bit-accurate, sound symbolic execution to verify that they produce equivalent outputs on a finite number of paths, even for rich, nested data structures. We show that the approach works well, even on heavily-tested code, where it finds interesting errors and gets high statement coverage, often exhausting all feasible paths for a given input size. We also show how the simple trick of checking equivalence of identical code turns the verification tool chain against itself, finding errors in the underlying compiler and verification tool.},
  address = {Berlin, Heidelberg},
  author = {David A Ramos and Dawson R. Engler},
  booktitle = {Proceedings of the 23rd International Conference on Computer Aided Verification},
  isbn = {9783642221095},
  location = {Snowbird, UT},
  numpages = {17},
  pages = {669-685},
  publisher = {Springer-Verlag},
  series = {CAV'11},
  title = {{Practical, low-effort equivalence verification of real code}},
  year = {2011}
}

@inproceedings{ramos:sec:2015,
  abstract = {Software bugs are a well-known source of security vulnerabilities. One technique for finding bugs, symbolic execution, considers all possible inputs to a program but suffers from scalability limitations. This paper uses a variant, under-constrained symbolic execution, that improves scalability by directly checking individual functions, rather than whole programs. We present UC-KLEE, a novel, scalable framework for checking C/C++ systems code, along with two use cases. First, we use UC-KLEE to check whether patches introduce crashes. We check over 800 patches from BIND and OpenSSL and find 12 bugs, including two OpenSSL denial-of-service vulnerabilities. We also verify (with caveats) that 115 patches do not introduce crashes. Second, we use UC-KLEE as a generalized checking framework and implement checkers to find memory leaks, uninitialized data, and unsafe user input. We evaluate the checkers on over 20,000 functions from BIND, OpenSSL, and the Linux kernel, find 67 bugs, and verify that hundreds of functions are leak free and that thousands of functions do not access uninitialized data.},
  address = {USA},
  author = {David A. Ramos and Dawson Engler},
  booktitle = {Proceedings of the 24th USENIX Conference on Security Symposium},
  isbn = {9781931971232},
  location = {Washington, D.C.},
  numpages = {16},
  pages = {49-64},
  publisher = {USENIX Association},
  series = {SEC'15},
  title = {{Under-constrained symbolic execution: Correctness checking for real code}},
  year = {2015}
}

@inproceedings{ramsey:lctes:1998,
  abstract = {Because of poor tools, developing embedded systems can be unnecessarily hard. Machine descriptions based on register-transfer lists (RTLs) have proven useful in building retargetable compilers, but not in building other retargetable tools. Simulators, assemblers, linkers, debuggers, and profilers are built by hand if at all--previous machine descriptions have lacked the detail and precision needed to generate them. This paper presents detailed and precise machine-description techniques that are based on a new formalization of RTLs. Unlike previous notations, these RTLs have a detailed, unambiguous, and machine-independent semantics, which makes them ideal for supporting automatic generation of retargetable tools. The paper also gives examples of \textdollar {\l}ambda\textdollar -RTL, a notation that makes it possible for human beings to read and write RTLs without becoming overwhelmed by machine-dependent detail.},
  address = {Berlin, Heidelberg},
  author = {Norman Ramsey and Jack W. Davidson},
  booktitle = {Languages, Compilers, and Tools for Embedded Systems},
  editor = {Mueller, Frank and Bestavros, Azer},
  isbn = {978-3-540-49673-1},
  pages = {176-192},
  publisher = {Springer Berlin Heidelberg},
  title = {{Machine descriptions to build tools for embedded systems}},
  year = {1998}
}

@article{ramsey:toplas:1997,
  address = {New York, NY, USA},
  author = {Norman Ramsey and Mary F. Fernández},
  doi = {10.1145/256167.256225},
  issn = {0164-0925},
  issue_date = {May 1997},
  journal = {ACM Trans. Program. Lang. Syst.},
  keywords = {decoding, machine description, encoding, object code, compiler generation, relocation, machine code},
  link = {https://doi.org/10.1145/256167.256225},
  month = {May},
  number = {3},
  numpages = {33},
  pages = {492-524},
  publisher = {Association for Computing Machinery},
  title = {{Specifying representations of machine instructions}},
  url = {https://doi.org/10.1145/256167.256225},
  volume = {19},
  year = {1997}
}

@inproceedings{rath:epiq:2018,
  abstract = {The main reason for the standardization of network protocols, like QUIC, is to ensure interoperability between implementations, which poses a challenging task. Manual tests are currently used to test the different existing implementations for interoperability, but given the complex nature of network protocols, it is hard to cover all possible edge cases.State-of-the-art automated software testing techniques, such as Symbolic Execution (SymEx), have proven themselves capable of analyzing complex real-world software and finding hard to detect bugs. We present a SymEx-based method for finding interoperability issues in QUIC implementations, and explore its merit in a case study that analyzes the interoperability of picoquic and QUANT.We find that, while SymEx is able to analyze deep interactions between different implementations and uncovers several bugs, in order to enable efficient interoperability testing, implementations need to provide additional information about their current protocol state.},
  address = {New York, NY, USA},
  author = {Felix Rath and Daniel Schemmel and Klaus Wehrle},
  booktitle = {Proceedings of the Workshop on the Evolution, Performance, and Interoperability of QUIC},
  doi = {10.1145/3284850.3284853},
  isbn = {9781450360821},
  keywords = {QUIC, Symbolic Execution, Interoperability Testing},
  link = {https://doi.org/10.1145/3284850.3284853},
  location = {Heraklion, Greece},
  numpages = {7},
  pages = {15-21},
  publisher = {Association for Computing Machinery},
  series = {EPIQ'18},
  title = {{Interoperability-guided testing of QUIC implementations using symbolic execution}},
  url = {https://doi.org/10.1145/3284850.3284853},
  year = {2018}
}

@inproceedings{recoules:ase:2019,
  author = {Frédéric Recoules and Sébastien Bardin and Richard Bonichon and Laurent Mounier and Marie-Laure Potet},
  booktitle = {2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE.2019.00060},
  number = {},
  pages = {577-589},
  title = {{Get rid of inline assembly through verification-oriented lifting}},
  volume = {},
  year = {2019}
}

@inproceedings{regehr:acp4is:2003,
  abstract = {We have developed task scheduler logic (TSL) to automate reasoning about scheduling and concurrency in systems software. TSL can detect race conditions and other errors as well as supporting lock inference: the derivation of an appropriate lock implementation for each critical section in a system. Lock inference solves a number of problems in creating flexible, reliable, and efficient systems software. TSL is based on a notion of asymmetrical preemption relations and it exploits the hierarchical inheritance of scheduling properties that is common in systems software.},
  affiliation = {University of Utah},
  ar_shortname = {ACP4IS 03},
  author = {John Regehr and Alastair D. Reid},
  booktitle = {Proceedings of the Second AOSD Workshop on Aspects, Components, and Patterns for Infrastructure Software (ACP4IS)},
  day = {17},
  location = {Boston, MA, USA},
  month = {March},
  title = {{Lock inference for systems software}},
  year = {2003}
}

@inproceedings{regehr:asplos:2004,
  abstract = {Embedded software must meet conflicting requirements such as be- ing highly reliable, running on resource-constrained platforms, and being developed rapidly. Static program analysis can help meet all of these goals. People developing analyzers for embedded object code face a difficult problem: writing an abstract version of each instruction in the target architecture(s). This is currently done by hand, resulting in abstract operations that are both buggy and imprecise. We have developed Hoist: a novel system that solves these problems by automatically constructing abstract operations using a microprocessor (or simulator) as its own specification. With almost no input from a human, Hoist generates a collection of C functions that are ready to be linked into an abstract interpreter. We demonstrate that Hoist generates abstract operations that are correct, having been extensively tested, sufficiently fast, and substantially more precise than manually written abstract operations. Hoist is currently limited to eight-bit machines due to costs exponential in the word size of the target architecture. It is essential to be able to analyze software running on these small processors: they are important and ubiquitous, with many embedded and safety-critical systems being based on them.},
  acceptance = {14},
  affiliation = {University of Utah},
  ar_shortname = {ASPLOS 04},
  author = {John Regehr and Alastair D. Reid},
  booktitle = {Proceedings of the 11th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2004)},
  day = {7-13},
  doi = {10.1145/1024393.1024410},
  editor = {Shubu Mukherjee and Kathryn S. McKinley},
  location = {Boston, MA, USA},
  month = {October},
  pages = {133-143},
  publisher = {ACM},
  title = {{HOIST: a system for automatically deriving static analyzers for embedded systems}},
  year = {2004}
}

@inproceedings{regehr:emsoft:2003,
  abstract = {An important correctness criterion for software running on embedded microcontrollers is stack safety: a guarantee that the call stack does not overflow. We address two aspects of the problem of creating stack-safe embedded software that also makes efficient use of memory: statically bounding worst-case stack depth, and automatically reducing stack memory requirements. Our first contribution is a method for statically guaranteeing stack safety by performing whole-program analysis, using an approach based on context-sensitive abstract interpretation of machine code. Abstract interpretation permits our analysis to accurately model when interrupts are enabled and disabled, which is essential for accurately bounding the stack depth of typical embedded systems. We have implemented a stack analysis tool that targets Atmel AVR microcontrollers, and tested it on embedded applications compiled from up to 30,000 lines of C. We experimentally validate the accuracy of the tool, which runs in a few seconds on the largest programs that we tested. The second contribution of this paper is a novel framework for automatically reducing stack memory requirements. We show that goal-directed global function inlining can be used to reduce the stack memory requirements of component-based embedded software, on average, to 40\% of the requirement of a system compiled without inlining, and to 68\% of the requirement of a system compiled with aggressive whole-program inlining that is not directed towards reducing stack usage.},
  affiliation = {University of Utah},
  ar_shortname = {EMSOFT 03},
  author = {John Regehr and Alastair D. Reid and Kirk Webb},
  booktitle = {Embedded Software, Third International Conference (EMSOFT 2003)},
  day = {13-15},
  doi = {10.1007/978-3-540-45212-6_20},
  editor = {Rajeev Alur and Insup Lee},
  location = {Philadelphia, PA, USA},
  month = {October},
  pages = {306-322},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  title = {{Eliminating stack overflow by abstract interpretation}},
  volume = {2855},
  year = {2003}
}

@inproceedings{regehr:lctes:2006,
  acmid = {1134657},
  address = {New York, NY, USA},
  author = {John Regehr and Usit Duongsaa},
  booktitle = {Proceedings of the 2006 ACM SIGPLAN/SIGBED Conference on Language, Compilers, and Tool Support for Embedded Systems},
  doi = {10.1145/1134650.1134657},
  isbn = {1-59593-362-X},
  keywords = {abstract interpretation, embedded software, static analysis, transfer functions},
  location = {Ottawa, Ontario, Canada},
  numpages = {10},
  pages = {34-43},
  publisher = {ACM},
  series = {LCTES '06},
  title = {{Deriving abstract transfer functions for analyzing embedded software}},
  year = {2006}
}

@inproceedings{regehr:pldi:2012,
  address = {New York, NY, USA},
  author = {John Regehr and Yang Chen and Pascal Cuoq and Eric Eide and Chucky Ellison and Xuejun Yang},
  booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2254064.2254104},
  isbn = {9781450312059},
  keywords = {compiler defect, compiler testing, test-case minimization, random testing, bug reporting, automated testing},
  link = {https://doi.org/10.1145/2254064.2254104},
  location = {Beijing, China},
  numpages = {12},
  pages = {335-346},
  publisher = {Association for Computing Machinery},
  series = {PLDI '12},
  title = {{Test-case reduction for C compiler bugs}},
  url = {https://doi.org/10.1145/2254064.2254104},
  year = {2012}
}

@inproceedings{regehr:rtss:2003,
  abstract = {We have developed a new way to look at real-time and embedded software: as a collection of execution environments created by a hierarchy of schedulers. Common schedulers include those that run interrupts, bottom-half handlers, threads, and events. We have created algorithms for deriving response times, scheduling overheads, and blocking terms for tasks in systems containing multiple execution environments. We have also created task scheduler logic, a formalism that permits checking systems for race conditions and other errors. Concurrency analysis of low-level software is challenging because there are typically several kinds of locks, such as thread mutexes and disabling interrupts, and groups of cooperating tasks may need to acquire some, all, or none of the available types of locks to create correct software. Our high level goal is to create systems that are evolvable: they are easier to modify in response to changing requirements than are systems created using traditional techniques. We have applied our approach to two case studies in evolving software for networked sensor nodes.},
  affiliation = {University of Utah},
  ar_shortname = {RTSS 03},
  author = {John Regehr and Alastair D. Reid and Kirk Webb and Michael A. Parker and Jay Lepreau},
  booktitle = {Proceedings of the 24th IEEE Real-Time Systems Symposium (RTSS 2003)},
  day = {3-5},
  doi = {10.1109/REAL.2003.1253251},
  location = {Cancun, Mexico},
  month = {December},
  pages = {25-36},
  publisher = {IEEE Computer Society},
  title = {{Evolving real-time systems using hierarchical scheduling and concurrency analysis}},
  year = {2003}
}

@article{regehr:tecs:2005,
  abstract = {An important correctness criterion for software running on embedded microcontrollers is stack safety: a guarantee that the call stack does not overflow. Our first contribution is a method for statically guaranteeing stack safety of interrupt-driven embedded software using an approach based on context-sensitive dataflow analysis of object code. We have implemented a prototype stack analysis tool that targets software for Atmel AVR microcontrollers and tested it on embedded applications compiled from up to 30,000 lines of C. We experimentally validate the accuracy of the tool, which runs in under 10 sec on the largest programs that we tested. The second contribution of this paper is the development of two novel ways to reduce stack memory requirements of embedded software.},
  affiliation = {University of Utah},
  ar_shortname = {TECS 05},
  author = {John Regehr and Alastair D. Reid and Kirk Webb},
  doi = {10.1145/1113830.1113833},
  journal = {ACM Transactions Embedded Computing Systems},
  number = {4},
  pages = {751-778},
  title = {{Eliminating stack overflow by abstract interpretation}},
  volume = {4},
  year = {2005}
}

@inproceedings{reid:cases:2008,
  abstract = {The architectures of system-on-chip (SoC) platforms found in high-end consumer devices are getting more and more complex as designers strive to deliver increasingly compute-intensive applications on near-constant energy budgets.  Workloads running on these platforms require the exploitation of heterogeneous parallelism and increasingly irregular memory hierarchies.  The conventional approach to programming such hardware is very low-level but this yields software which is intimately and inseparably tied to the details of the platform it was originally designed for, limiting the software's portability, and, ultimately, the architectural choices available to designers of future platform generations.  The key insight of this paper is that many of the problems experienced in mapping applications onto SoC platforms come not from deciding how to map a program onto the hardware but from the need to restructure the program and the number of interdependencies introduced in the process of implementing those decisions.  We tackle this complexity with a set of language extensions which allows the programmer to introduce pipeline parallelism into sequential programs, manage distributed memories, and express the desired mapping of tasks to resources.  The compiler takes care of the complex, error-prone details required to implement that mapping.  We demonstrate the effectiveness of SoC-C and its compiler with a ``software defined radio'' example (the PHY layer of a Digital Video Broadcast receiver) achieving a 3.4x speedup on 4 cores.},
  acceptance = {33},
  affiliation = {ARM Ltd and University of Michigan},
  ar_shortname = {CASES 08},
  author = {Alastair D. Reid and Krisztián Flautner and Edmund Grimley-Evans and Yuan Lin},
  booktitle = {Proceedings of the 2008 International Conference on Compilers, Architecture, and Synthesis for Embedded Systems (CASES 2008)},
  day = {19-24},
  doi = {10.1145/1450095.1450112},
  editor = {Erik R. Altman},
  location = {Atlanta, GA, USA},
  month = {October},
  pages = {95-104},
  publisher = {ACM},
  title = {{SoC-C: efficient programming abstractions for heterogeneous multicore systems on chip}},
  year = {2008}
}

@inproceedings{reid:cav:2016,
  abstract = {Despite 20+ years of research on processor verification, it remains hard to use formal verification techniques in commercial processor development.  There are two significant factors: scaling issues and return on investment.  The scaling issues include the size of modern processor specifications, the size/complexity of processor designs, the size of design/verification teams and the (non)availability of enough formal verification experts.  The return on investment issues include the need to start catching bugs early in development, the need to continue catching bugs throughout development, and the need to be able to reuse verification IP, tools and techniques across a wide range of design styles.  This paper describes how ARM has overcome these issues in our Instruction Set Architecture Formal Verification framework ``ISA-Formal.'' This is an end-to-end framework to detect bugs in the datapath, pipeline control and forwarding/stall logic of processors.  A key part of making the approach scale is use of a mechanical translation of ARM's Architecture Reference Manuals to Verilog allowing the use of commercial model-checkers.  ISA-Formal has proven especially effective at finding micro-architecture specific bugs involving complex sequences of instructions.  An essential feature of our work is that it is able to scale all the way from simple 3-stage microcontrollers, through superscalar in-order processors up to out-of-order processors.  We have applied this method to 8 different ARM processors spanning all stages of development up to release.  In all processors, this has found bugs that would have been hard for conventional simulation-based verification to find and ISA-Formal is now a key part of ARM's formal verification strategy.  To the best of our knowledge, this is the most broadly applicable formal verification technique for verifying processor pipeline control in mainstream commercial use.},
  acceptance = {28},
  affiliation = {ARM Ltd},
  ar_shortname = {CAV 16},
  author = {Alastair D. Reid and Rick Chen and Anastasios Deligiannis and David Gilday and David Hoyes and Will Keen and Ashan Pathirane and Erin Shepherd and Peter Vrabel and Ali Zaidi},
  booktitle = {Proceedings of the 2016 International Conference on Computer Aided Verification (CAV'16)},
  doi = {10.1007/978-3-319-41540-6_3},
  editor = {S. Chaudhuri and A. Farzan},
  isbn = {978-3-319-41539-0},
  journal = {CAV 2016, Part II, Lecture Notes in Computer Science},
  location = {Toronto, Canada},
  month = {July},
  number = {9780},
  pages = {42-58},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  title = {{End-to-end verification of ARM processors with ISA-formal}},
  volume = {9780},
  year = {2016}
}

@inproceedings{reid:fmcad:2016,
  abstract = {Processor specifications are of critical importance for verifying programs, compilers, operating systems/hypervisors, and, of course, for verifying microprocessors themselves.  But to be useful, the scope of these specifications must be sufficient for the task, the specification must be applicable to processors of interest and the specification must be trustworthy.  This paper describes a 5 year project to change ARM's existing architecture specification process so that machine-readable, executable specifications can be automatically generated from the same materials used to generate ARM's conventional architecture documentation.  We have developed executable specifications of both ARM's A-class and M-class processor architectures that are complete enough and trustworthy enough that we have used them to formally verify ARM processors using bounded model checking.  In particular, our specifications include the semantics of the most security sensitive parts of the processor: the memory and register protection mechanisms and the exception mechanisms that trigger transitions between different modes.  Most importantly, we have applied a diverse set of methods including ARM's internal processor test suites to improve our trust in the specification using many other expressions of the architectural specification such as ARM's simulators, testsuites and processors to defend against common-mode failure.  In the process, we have also found bugs in all those artifacts: testing specifications is very much a two-way street.  While there have been previous specifications of ARM processors, their scope has excluded the system architecture, their applicability has excluded newer processors and M-class, and their trustworthiness has not been established as thoroughly.  Our focus has been on enabling the formal verification of ARM processors but, recognising the value of this specification for verifying software, we are currently preparing a public release of the machine-readable specification.},
  affiliation = {ARM Ltd},
  ar_shortname = {FMCAD 16},
  author = {Alastair D. Reid},
  booktitle = {Proceedings of Formal Methods in Computer-Aided Design (FMCAD 2016)},
  doi = {10.1109/FMCAD.2016.7886675},
  isbn = {978-0-9835678-6-8},
  link = {https://alastairreid.github.io/papers/fmcad2016-trustworthy.pdf},
  location = {Mountain View, CA, USA},
  month = {October},
  pages = {161-168},
  title = {{Trustworthy specifications of ARM v8-A and v8-M system level architecture}},
  url = {https://alastairreid.github.io/papers/fmcad2016-trustworthy.pdf},
  year = {2016}
}

@inproceedings{reid:gfpw:1989,
  abstract = {The design (as opposed to the choice and use) of data structures has been the subject of relatively little study in the context of formal methods. In this paper, we introduce our ideas on how data structures are designed.},
  affiliation = {University of Glasgow},
  ar_shortname = {GFPW 89},
  author = {Alastair D. Reid},
  booktitle = {Proceedings of the 1989 Glasgow Workshop on Functional Programming},
  day = {21-23},
  editor = {Kei Davis and John Hughes},
  location = {Fraserburgh, Scotland, UK},
  month = {August},
  pages = {170-181},
  publisher = {Springer},
  series = {Workshops in Computing},
  title = {{Designing data structures}},
  year = {1989}
}

@inbook{reid:gfpw:1993,
  abstract = {Carlsson and Hallgren describe the implementation of a set of "functional widgets" (Fudgets): components for programming graphical user interfaces under the X window system using the non-strict functional programming language Haskell. We describe an alternative implementation based on existing widget sets (currently Openlook and Motif). Our purpose is twofold: to show that the Fudgets approach can be applied to existing widget sets; and to discuss problems experienced with Fudgets during an industrial case study.},
  address = {London},
  affiliation = {University of Glasgow},
  ar_shortname = {GFPW 93},
  author = {Alastair D. Reid and Satnam Singh},
  booktitle = {Proceedings of the 1993 Glasgow Workshop on Functional Programming},
  day = {5-7},
  doi = {10.1007/978-1-4471-3236-3_18},
  editor = {John T. O'Donnell and Kevin Hammond},
  isbn = {978-1-4471-3236-3},
  location = {Ayr, Scotland},
  month = {July},
  pages = {222-235},
  publisher = {Springer London},
  title = {{Implementing Fudgets with standard widget sets}},
  year = {1993}
}

@inproceedings{reid:gfpw:1994,
  affiliation = {University of Glasgow},
  ar_shortname = {GFPW 94},
  author = {Alastair D. Reid},
  booktitle = {Draft Proceedings of the Glasgow Functional Programming Workshop},
  day = {12-14},
  location = {Ayr, Scotland},
  month = {September},
  title = {{Malloc pointers and stable pointers: Improving Haskell's foreign language interface}},
  year = {1994}
}

@misc{reid:hatra:2020,
  abstract = {Formal verification of software is a bit of a niche activity: it is only applied to the most safety-critical or security-critical software and it is typically only performed by specialized verification engineers. This paper considers whether it would be possible to increase adoption of formal methods by integrating formal methods with developers' existing practices and workflows.  We do not believe that widespread adoption will follow from making the prevailing formal methods argument that correctness is more important than engineering teams realize. Instead, our focus is on what we would need to do to enable programmers to make effective use of formal verification tools and techniques. We do this by considering how we might make verification tooling that both serves developers' needs and fits into their existing development lifecycle. We propose a target of two orders of magnitude increase in adoption within a decade driven by ensuring a positive `weekly cost-benefit' ratio for developer time invested.},
  ar_file = {HATRA\_20},
  ar_shortname = {HATRA 20},
  archiveprefix = {arXiv},
  author = {Alastair D. Reid and Luke Church and Shaked Flur and Sarah de Haas and Maritza Johnson and Ben Laurie},
  booktitle = {HATRA 2020: Human Aspects of Types and Reasoning Assistants},
  day = {30},
  eprint = {2010.16345},
  file = {hatra2020.pdf},
  link = {https://research.google/pubs/pub49713/},
  month = {October},
  png = {hatra2020.png},
  primaryclass = {cs.LO},
  slides = {hatra2020-slides.pdf},
  title = {{Towards making formal methods normal: meeting developers where they are}},
  url = {https://research.google/pubs/pub49713/},
  video = {https://youtu.be/fUNYvUMSmq4?t=520},
  year = {2020}
}

@inproceedings{reid:hw:1995,
  affiliation = {Yale University},
  ar_shortname = {Haskell 95b},
  author = {Alastair D. Reid and John Peterson},
  booktitle = {Proceedings of the Haskell Workshop 1995, Yale University Research Report YALE/DCS/RR-1075},
  link = {https://www.haskell.org/haskell-workshop/1995/HW1995-Proceedings.pdf},
  location = {Portland, Oregon, USA},
  page = {69-81},
  title = {{A proposal for the standard Haskell libraries}},
  url = {https://www.haskell.org/haskell-workshop/1995/HW1995-Proceedings.pdf},
  year = {1995}
}

@inproceedings{reid:icse:1999,
  abstract = {We describe the transformation of XVision, a large library of C++ code for real-time vision processing, into FVision (pronounced ``fission''), a fully-featured domain-specific language embedded in Haskell. The resulting prototype system substantiates the claims of increased modularity, effective code reuse, and rapid prototyping that characterize the DSL approach to system design. It also illustrates the need for judicious interface design: relegating computationally expensive tasks to XVision (pre-existing C++ components), and leaving modular compositional tasks to FVision (Haskell). At the same time, our experience demonstrates how Haskell's advanced language features (specifically parametric polymorphism, lazy evaluation, higher order functions and automatic storage reclamation) permit a rapid DSL design that is itself highly modular and easily modified. Overall, the resulting hybrid system exceeded our expectations: visual tracking programs continue to spend most of their time executing low level image-processing code, while Haskell's advanced features allow us to quickly develop and test small prototype systems within a matter of a few days and to develop realistic applications within a few weeks.},
  acceptance = {19},
  affiliation = {Yale University},
  ar_shortname = {ICSE 99},
  author = {Alastair D. Reid and John Peterson and Gregory D. Hager and Paul Hudak},
  booktitle = {Proceedings of the 1999 International Conference on Software Engineering (ICSE '99)},
  day = {16-22},
  doi = {10.1109/icse.1999.841038},
  editor = {Barry W. Boehm and David Garlan and Jeff Kramer},
  location = {Los Angeles, CA, USA},
  month = {May},
  pages = {484-493},
  publisher = {ACM},
  title = {{Prototyping real-time vision systems: An experiment in DSL design}},
  year = {1999}
}

@inproceedings{reid:ifl:1998,
  abstract = {Interrupt handling is a tricky business in lazy functional languages: we have to make sure that thunks that are being evaluated can be halted and later restarted if and when they are required. This is a particular problem for implementations which use black-holing. Black-Holing deliberately makes it impossible to revert such thunks to their original state to avoid a serious space leak. Interactive Haskell implementations such as Hugs and hbi catch interrupts and avoid the problem by omitting or disabling black-holing. Batch mode Haskell implementations such as HBC and the Glasgow Haskell Compiler (GHC) avoid this problem by disabling black-holing or by providing no way to catch interrupts. This paper describes a modification to GHC's abstract machine (the Spineless Tagless G-Machine) which simultaneously supports both interrupts and black-holing.},
  affiliation = {Yale University},
  ar_shortname = {IFL 98},
  author = {Alastair D. Reid},
  booktitle = {Implementation of Functional Languages, 10th International Workshop (IFL'98) Selected Papers},
  day = {9-11},
  doi = {10.1007/3-540-48515-5_12},
  editor = {Kevin Hammond and Antony J. T. Davie and Chris Clack},
  location = {London, UK},
  month = {September},
  pages = {186-199},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  title = {{Putting the spine back in the Spineless Tagless G-Machine: An implementation of resumable black-holes}},
  volume = {1595},
  year = {1998}
}

@mastersthesis{reid:msc:1993,
  abstract = {All formal specifiers face the danger of overspecification: accidentally writing an overly restrictive specification. This problem is particularly acute for axiomatic specifications because it is so easy to write axioms that hold for some of the intended implementations but not for all of them (or, rather, it is hard not to write overly strong axioms).  One of the best developed ways of recovering some of these implementations which do not literally satisfy the specification is to apply a ``behavioural abstraction operator'' to a specification: adding in those implementations which have the same ``behaviour'' as an implementation which does satisfy the specification.  In two recent papers, Broy and Wirsing propose an alternative (and apparently simpler) approach which they call ``ultraloose specification.''  This approach is based on a particular style of writing axioms which avoids certain forms of overspecification.  An important, unanswered question is ``How does the ultraloose approach relate to other solutions?'' The major achievement of this thesis is a proof that the ultraloose approach is semantically equivalent to the use of the ``behavioural abstraction operator.''  This result is rather surprising in the light of a result by Schoett which seems to say that such a result is impossible.},
  affiliation = {University of Glasgow},
  ar_shortname = {MSc 93},
  author = {Alastair D. Reid},
  location = {Glasgow, Scotland},
  school = {Glasgow School of Computing Science},
  title = {{A precise semantics for ultraloose specifications}},
  year = {1993}
}

@inproceedings{reid:oopsla:2017,
  abstract = {Software and hardware are increasingly being formally verified against specifications, but how can we verify the specifications themselves? This talk explores what it means to formally verify a specification. We solve three challenges: (1) How to create a secondary, higher-level specification that can be effectively reviewed by processor designers who are not experts in formal verification; (2) How to avoid common-mode failures between the specifications; and (3) How to automatically verify the two specifications against each other.  One of the most important specifications for software verification is the processor specification since it de nes the behaviour of machine code and of hardware protection features used by operating systems. We demonstrate our approach on ARM's v8-M Processor Specification, which is intended to improve the security of Internet of Things devices. Thus, we focus on establishing the security guarantees the architecture is intended to provide. Despite the fact that the ARM v8-M specification had previously been extensively tested, we found twelve bugs (including two security bugs) that have all been fixed by ARM.},
  address = {New York, NY, USA},
  affiliation = {ARM Ltd},
  ar_shortname = {OOPSLA 17},
  author = {Alastair D. Reid},
  day = {22-27},
  doi = {10.1145/3133912},
  journal = {PACMPL},
  location = {Vancouver, BC, Canada},
  month = {October},
  number = {OOPSLA},
  numpages = {24},
  pages = {88:1-88:24},
  publisher = {ACM},
  title = {{Who guards the guards? Formal validation of the ARM v8-M architecture specification}},
  volume = {1},
  year = {2017}
}

@inproceedings{reid:osdi:2000,
  abstract = {Knit is a new component definition and linking language for systems code. Knit helps make C code more understandable and reusable by third parties, helps eliminate much of the performance overhead of componentization, detects subtle errors in component composition that cannot be caught with normal component type systems, and provides a foundation for developing future analyses over C-based components, such as cross-component optimization. The language is especially designed for use with component kits, where standard linking tools provide inadequate support for component configuration. In particular, we developed Knit for use with the OSKit, a large collection of components for building low-level systems. However, Knit is not OSKit-specific, and we have implemented parts of the Click modular router in terms of Knit components to illustrate the expressiveness and flexibility of our language. This paper provides an overview of the Knit language and its applications.},
  affiliation = {University of Utah},
  ar_shortname = {OSDI 00},
  author = {Alastair D. Reid and Matthew Flatt and Leigh Stoller and Jay Lepreau and Eric Eide},
  booktitle = {4th Symposium on Operating System Design and Implementation (OSDI 2000)},
  day = {23-25},
  editor = {Michael B. Jones and M. Frans Kaashoek},
  link = {http://dl.acm.org/citation.cfm?id=1251253},
  location = {San Diego, California, USA},
  month = {October},
  pages = {347-360},
  publisher = {USENIX Association},
  title = {{Knit: Component composition for systems software}},
  url = {http://dl.acm.org/citation.cfm?id=1251253},
  year = {2000}
}

@phdthesis{reid:phd:2019,
  abstract = {One of the most important interfaces in a computer system is the interface between hardware and software.  This interface is the contract between the hardware designer and the programmer that defines the functional behaviour of the hardware.  This thesis examines two critical aspects of defining the hardware-software interface: quality and performance.  The first aspect is creating a high quality specification of the interface as conventionally defined in an instruction set architecture.  The majority of this thesis is concerned with creating a specification that covers the full scope of the interface; that is applicable to all current implementations of the architecture; and that can be trusted to accurately describe the behaviour of implementations of the architecture.  We describe the development of a formal specification of the two major types of Arm processors: A-class (for mobile devices such as phones and tablets) and M-class (for micro-controllers). These specifications are unparalleled in their scope, applicability and trustworthiness.  This thesis identifies and illustrates what we consider the key ingredient in achieving this goal: creating a specification that is used by many different user groups.  Supporting many different groups leads to improved quality as each group finds different problems in the specification; and, by providing value to each different group, it helps justify the considerable effort required to create a high quality specification of a major processor architecture.  The work described in this thesis led to a step change in Arm's ability to use formal verification techniques to detect errors in their processors; enabled extensive testing of the specification against Arm's official architecture conformance suite; improved the quality of Arm's architecture conformance suite based on measuring the architectural coverage of the tests; supported earlier, faster development of architecture extensions by enabling animation of changes as they are being made; and enabled early detection of problems created from architecture extensions by performing formal validation of the specification against semi-structured natural language specifications.  As far as we are aware, no other mainstream processor architecture has this capability.  The formal specifications are included in Arm's publicly released architecture reference manuals and the A-class specification is also released in machine-readable form.  The second aspect is creating a high performance interface by defining the hardware-software interface of a software-defined radio subsystem using a programming language.  That is, an interface that allows software to exploit the potential performance of the underlying hardware.  While the hardware-software interface is normally defined in terms of machine code, peripheral control registers and memory maps, we define it using a programming language instead.  This higher level interface provides the opportunity for compilers to hide some of the low-level differences between different systems from the programmer: a potentially very efficient way of providing a stable, portable interface without having to add hardware to provide portability between different hardware platforms.  We describe the design and implementation of a set of extensions to the C programming language to support programming high performance, energy efficient, software defined radio systems. The language extensions enable the programmer to exploit the pipeline parallelism typically present in digital signal processing applications and to make efficient use of the asymmetric multiprocessor systems designed to support such applications.  The extensions consist primarily of annotations that can be checked for consistency and that support annotation inference in order to reduce the number of annotations required.  Reducing the number of annotations does not just save programmer effort, it also improves portability by reducing the number of annotations that need to be changed when porting an application from one platform to another.  This work formed part of a project that developed a high-performance, energy-efficient, software defined radio capable of implementing the physical layers of the 4G cellphone standard (LTE), 802.11a WiFi and Digital Video Broadcast (DVB) with a power and silicon area budget that was competitive with a conventional custom ASIC solution.  The Arm architecture is the largest computer architecture by volume in the world.  It behooves us to ensure that the interface it describes is appropriately defined.},
  affiliation = {School of Computing Science, University of Glasgow},
  ar_shortname = {PhD 19},
  author = {Alastair D. Reid},
  location = {Glasgow, Scotland},
  month = {March},
  numpages = {161},
  school = {School of Computing Science, University of Glasgow},
  title = {{Defining interfaces between hardware and software: Quality and performance}},
  year = {2019}
}

@misc{reid:yale:1998,
  affiliation = {Yale University},
  ar_shortname = {StdLib 98},
  author = {Alastair D. Reid and John Peterson},
  title = {{Designing the standard Haskell libraries}},
  year = {1998}
}

@misc{reid:yale:2001,
  affiliation = {Yale University},
  ar_shortname = {GLib 01},
  author = {Alastair D. Reid},
  location = {New Haven, CT, USA},
  title = {{The Hugs graphics library (version 2.0)}},
  year = {2001}
}

@inproceedings{remy:popl:1989,
  abstract = {Strongly typed languages with records may have inclusion rules so that records with more fields can be used instead of records with less fields. But these rules lead to a global treatment of record types as a special case. We solve this problem by giving an ordinary status to records without any ad hoc assertions, replacing inclusion rules by extra information in record types. With this encoding ML naturally extends its polymorphism to records but any other host language will also transmit its power.},
  address = {New York, NY, USA},
  author = {D. Rémy},
  booktitle = {Proceedings of the 16th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/75277.75284},
  isbn = {0897912942},
  link = {https://doi.org/10.1145/75277.75284},
  location = {Austin, Texas, USA},
  numpages = {12},
  pages = {77-88},
  publisher = {Association for Computing Machinery},
  series = {POPL '89},
  title = {{Type checking records and variants in a natural extension of ML}},
  url = {https://doi.org/10.1145/75277.75284},
  year = {1989}
}

@article{reppy:att:1996,
  author = {John H Reppy},
  journal = {Technical memorandum, AT\&T Bell Laboratories},
  title = {{A safe interface to sockets}},
  year = {1996}
}

@inproceedings{reynolds:lics:2002,
  author = {John C. Reynolds},
  booktitle = {Proceedings 17th Annual IEEE Symposium on Logic in Computer Science},
  doi = {10.1109/LICS.2002.1029817},
  issn = {1043-6871},
  keywords = {formal logic;computational complexity;data structures;separation logic;shared mutable data structures;Hoare logic;reasoning;low-level imperative programs;imperative programming language;heap;program logic;address arithmetic;recursive procedures;Data structures;Computer science;Programmable logic arrays;Reflection;Logic programming;Computer languages;Logic arrays;Arithmetic;Artificial intelligence;Bibliographies},
  month = {July},
  number = {},
  pages = {55-74},
  title = {{Separation logic: a logic for shared mutable data structures}},
  volume = {},
  year = {2002}
}

@inproceedings{rieman:chi:1995,
  address = {New York, NY, USA},
  author = {John Rieman and Marita Franzke and David Redmiles},
  booktitle = {Conference Companion on Human Factors in Computing Systems},
  doi = {10.1145/223355.223735},
  isbn = {0897917553},
  link = {https://doi.org/10.1145/223355.223735},
  location = {Denver, Colorado, USA},
  numpages = {2},
  pages = {387-388},
  publisher = {Association for Computing Machinery},
  series = {CHI '95},
  title = {{Usability evaluation with the cognitive walkthrough}},
  url = {https://doi.org/10.1145/223355.223735},
  year = {1995}
}

@inproceedings{roessle:cpp:2019,
  acmid = {3294102},
  address = {New York, NY, USA},
  author = {Ian Roessle and Freek Verbeek and Binoy Ravindran},
  booktitle = {Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs},
  doi = {10.1145/3293880.3294102},
  isbn = {978-1-4503-6222-1},
  keywords = {semantics, theorem proving, x86-64},
  location = {Cascais, Portugal},
  numpages = {15},
  pages = {181-195},
  publisher = {ACM},
  series = {CPP 2019},
  title = {{Formally verified big step semantics out of x86-64 binaries}},
  year = {2019}
}

@phdthesis{romano:phd:2014,
  author = {Anthony Romano},
  publisher = {Stanford University},
  title = {{Methods for binary symbolic execution}},
  year = {2014}
}

@inproceedings{roy:fse:2018,
  abstract = {In spite of decades of research in bug detection tools, there is a surprising dearth of ground-truth corpora that can be used to evaluate the efficacy of such tools. Recently, systems such as LAVA and EvilCoder have been proposed to automatically inject bugs into software to quickly generate large bug corpora, but the bugs created so far differ from naturally occurring bugs in a number of ways. In this work, we propose a new automated bug injection system, Apocalypse, that uses formal techniques-symbolic execution, constraint-based program synthesis and model counting-to automatically inject fair (can potentially be discovered by current bug-detection tools), deep (requiring a long sequence of dependencies to be satisfied to fire), uncorrelated (each bug behaving independent of others), reproducible (a trigger input being available) and rare (can be triggered by only a few program inputs) bugs in large software code bases. In our evaluation, we inject bugs into thirty Coreutils programs as well as the TCAS test suite. We find that bugs synthesized by Apocalypse are highly realistic under a variety of metrics, that they do not favor a particular bug-finding strategy (unlike bugs produced by LAVA), and that they are more difficult to find than manually injected bugs, requiring up around 240\texttimes  more tests to discover with a state-of-the-art symbolic execution tool.},
  address = {New York, NY, USA},
  author = {Subhajit Roy and Awanish Pandey and Brendan Dolan-Gavitt and Yu Hu},
  booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3236024.3236084},
  isbn = {9781450355735},
  keywords = {Symbolic Execution, Program Synthesis, Constraint-based Synthesis, Bug Injection},
  link = {https://doi.org/10.1145/3236024.3236084},
  location = {Lake Buena Vista, FL, USA},
  numpages = {11},
  pages = {224-234},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2018},
  title = {{Bug synthesis: Challenging bug-finding tools with deep faults}},
  url = {https://doi.org/10.1145/3236024.3236084},
  year = {2018}
}

@inproceedings{rozier:vstte:2016,
  abstract = {Advancement of AI-enhanced control in autonomous systems stands on the shoulders of formal methods, which make possible the rigorous safety analysis autonomous systems require. An aircraft cannot operate autonomously unless it has design-time reasoning to ensure correct operation of the autopilot and runtime reasoning to ensure system health management, or the ability to detect and respond to off-nominal situations. Formal methods are highly dependent on the specifications over which they reason; there is no escaping the ``garbage in, garbage out'' reality. Specification is difficult, unglamorous, and arguably the biggest bottleneck facing verification and validation of aerospace, and other, autonomous systems.},
  address = {Cham},
  author = {Kristin Yvonne Rozier},
  booktitle = {Verified Software. Theories, Tools, and Experiments},
  editor = {Blazy, Sandrine and Chechik, Marsha},
  isbn = {978-3-319-48869-1},
  pages = {8-26},
  publisher = {Springer International Publishing},
  title = {{Specification: The biggest bottleneck in formal methods and autonomy}},
  year = {2016}
}

@techreport{rushby:sri:1992,
  author = {Rushby, John},
  publisher = {SRI International, Computer Science Laboratory Menlo Park},
  title = {{Noninterference, transitivity, and channel-control security policies}},
  year = {1992}
}

@article{russell:cacm:1978,
  acmid = {359336},
  address = {New York, NY, USA},
  author = {Richard M. Russell},
  doi = {10.1145/359327.359336},
  issn = {0001-0782},
  issue_date = {Jan. 1978},
  journal = {Communications of the ACM},
  keywords = {architecture, computer systems},
  month = {January},
  number = {1},
  numpages = {10},
  pages = {63-72},
  publisher = {ACM},
  title = {{The CRAY-1 computer system}},
  volume = {21},
  year = {1978}
}

@article{russinovich:acmq:2021,
  abstract = {Although largely driven by economies of scale, the development of the modern cloud also enables increased security. Large data centers provide aggregate availability, reliability, and security assurances. The operational cost of ensuring that operating systems, databases, and other services have secure configurations can be amortized among all tenants, allowing the cloud provider to employ experts who are responsible for security; this is often unfeasible for smaller businesses, where the role of systems administrator is often conflated with many others.},
  address = {New York, NY, USA},
  author = {Mark Russinovich and Manuel Costa and Cédric Fournet and David Chisnall and Antoine Delignat-Lavaud and Sylvan Clebsch and Kapil Vaswani and Vikas Bhatia},
  doi = {10.1145/3454122.3456125},
  issn = {1542-7730},
  issue_date = {January-February 2021},
  journal = {Queue},
  link = {https://doi.org/10.1145/3454122.3456125},
  month = {February},
  number = {1},
  numpages = {28},
  pages = {49-76},
  publisher = {Association for Computing Machinery},
  title = {{Toward confidential cloud computing: Extending hardware-enforced cryptographic protection to data while in use}},
  url = {https://doi.org/10.1145/3454122.3456125},
  volume = {19},
  year = {2021}
}

@inproceedings{rutledge:icse:2019,
  abstract = {In previous work, we introduced zero-overhead profiling (ZOP), a technique that leverages the electromagnetic emissions generated by the computer hardware to profile a program without instrumenting it. Although effective, ZOP has several shortcomings: it requires test inputs that achieve extensive code coverage for its training phase; it predicts path profiles instead of complete execution traces; and its predictions can suffer unrecoverable accuracy losses. In this paper, we present zero-overhead path prediction (ZOP-2), an approach that extends ZOP and addresses its limitations. First, ZOP-2 achieves high coverage during training through progressive symbolic execution (PSE)-symbolic execution of increasingly small program fragments. Second, ZOP-2 predicts complete execution traces, rather than path profiles. Finally, ZOP-2 mitigates the problem of path mispredictions by using a stateless approach that can recover from prediction errors. We evaluated our approach on a set of benchmarks with promising results; for the cases considered, (1) ZOP-2 achieved over 90\% path prediction accuracy, and (2) PSE covered feasible paths missed by traditional symbolic execution, thus boosting ZOP-2's accuracy.},
  author = {Richard Rutledge and Sunjae Park and Haider Khan and Alessandro Orso and Milos Prvulovic and Alenka Zajic},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
  doi = {10.1109/ICSE.2019.00039},
  issn = {1558-1225},
  keywords = {},
  month = {May},
  number = {},
  pages = {234-245},
  title = {{Zero-overhead path prediction with progressive symbolic execution}},
  volume = {},
  year = {2019}
}

@inproceedings{rutledge:icse:2020,
  abstract = {Comprehensive test inputs are an essential ingredient for dynamic software analysis techniques, yet are typically impossible to obtain and maintain. Automated input generation techniques can supplant manual effort in many contexts, but they also exhibit inherent limitations in practical applications. Therefore, the best approach to input generation for a given application task necessarily entails compromise. Most symbolic execution approaches maintain soundness by sacrificing completeness. In this paper, we take the opposite approach and demonstrate PG-KLEE, an input generation tool that over-approximates program behavior to achieve complete coverage. We also summarize some empirical results that validate our claims. Our technique is detailed in an earlier paper [16], and the source code of PG-KLEE is available from [2].Video URL: https://youtu.be/b1ajzW6YWds},
  address = {New York, NY, USA},
  author = {Richard Rutledge and Alessandro Orso},
  booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
  doi = {10.1145/3377812.3382148},
  isbn = {9781450371223},
  keywords = {symbolic execution, program analysis, input generation},
  link = {https://doi.org/10.1145/3377812.3382148},
  location = {Seoul, South Korea},
  numpages = {4},
  pages = {65-68},
  publisher = {Association for Computing Machinery},
  series = {ICSE '20},
  title = {{PG-KLEE: Trading soundness for coverage}},
  url = {https://doi.org/10.1145/3377812.3382148},
  year = {2020}
}

@article{sabelfield:jcs:2009,
  author = {Andrei Sabelfeld and David Sands},
  doi = {10.3233/JCS-2009-0352},
  journal = {Journal of Computer Security},
  number = {5},
  pages = {517-548},
  publisher = {IOS Press},
  title = {{Declassification: Dimensions and principles}},
  volume = {17},
  year = {2009}
}

@article{sadowski:cacm:2018,
  abstract = {For a static analysis project to succeed, developers must feel they benefit from and enjoy using it.},
  address = {New York, NY, USA},
  author = {Caitlin Sadowski and Edward Aftandilian and Alex Eagle and Liam Miller-Cushon and Ciera Jaspan},
  doi = {10.1145/3188720},
  issn = {0001-0782},
  issue_date = {April 2018},
  journal = {Communications of the ACM},
  link = {https://doi.org/10.1145/3188720},
  month = {March},
  number = {4},
  numpages = {9},
  pages = {58-66},
  publisher = {Association for Computing Machinery},
  title = {{Lessons from building static analysis tools at Google}},
  url = {https://doi.org/10.1145/3188720},
  volume = {61},
  year = {2018}
}

@inproceedings{sadowski:icse-seip:2018,
  address = {New York, NY, USA},
  author = {Caitlin Sadowski and Emma Söderberg and Luke Church and Michal Sipko and Alberto Bacchelli},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
  doi = {10.1145/3183519.3183525},
  isbn = {9781450356596},
  link = {https://doi.org/10.1145/3183519.3183525},
  location = {Gothenburg, Sweden},
  numpages = {10},
  pages = {181-190},
  publisher = {Association for Computing Machinery},
  series = {ICSE-SEIP '18},
  title = {{Modern code review: A case study at Google}},
  url = {https://doi.org/10.1145/3183519.3183525},
  year = {2018}
}

@inproceedings{sadowski:icse:2015,
  author = {Caitlin Sadowski and Jeffrey van Gogh and Ciera Jaspan and Emma Söderberg and Collin Winter},
  booktitle = {2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
  doi = {10.1109/ICSE.2015.76},
  issn = {1558-1225},
  keywords = {ecology;program diagnostics;software architecture;program analysis ecosystem;tricorder;static analysis tools;code readability;developer workflow;codebases;scalable architecture;Google;Google;Computer bugs;Buildings;Ecosystems;Java;Libraries;Usability;program analysis;static analysis},
  month = {May},
  number = {},
  pages = {598-608},
  title = {{Tricorder: Building a program analysis ecosystem}},
  volume = {1},
  year = {2015}
}

@article{samet:ieeetse:1977,
  author = {Hanan Samet},
  doi = {10.1109/TSE.1977.231159},
  issn = {0098-5589},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {Compilers;LISP;compiler testing;correctness;data types;machine description languages;program testing;program verification;Application software;Computational modeling;Computer aided instruction;Contracts;High level languages;Performance evaluation;Program processors;Registers;System testing;Wiring;Compilers;LISP;compiler testing;correctness;data types;machine description languages;program testing;program verification},
  month = {September},
  number = {5},
  pages = {343-351},
  title = {{A machine description facility for compiler testing}},
  volume = {SE-3},
  year = {1977}
}

@phdthesis{samet:phd:1975,
  address = {Stanford, CA, USA},
  author = {Hanan Samet},
  note = {AAI7525601},
  school = {Stanford University},
  title = {{Automatically proving the correctness of translations involving optimized code.}},
  year = {1975}
}

@inproceedings{sammler:pldi:2021,
  abstract = {Given the central role that C continues to play in systems software, and the difficulty of writing safe and correct C code, it remains a grand challenge to develop effective formal methods for verifying C programs. In this paper, we propose a new approach to this problem: a type system we call RefinedC, which combines ownership types (for modular reasoning about shared state and concurrency) with refinement types (for encoding precise invariants on C data types and Hoare-style specifications for C functions). RefinedC is both automated (requiring minimal user intervention) and foundational (producing a proof of program correctness in Coq), while at the same time handling a range of low-level programming idioms such as pointer arithmetic. In particular, following the approach of RustBelt, the soundness of the RefinedC type system is justified semantically by interpretation into the Coq-based Iris framework for higher-order concurrent separation logic. However, the typing rules of RefinedC are also designed to be encodable in a new "separation logic programming" language we call Lithium. By restricting to a carefully chosen (yet expressive) fragment of separation logic, Lithium supports predictable, automatic, goal-directed proof search without backtracking. We demonstrate the effectiveness of RefinedC on a range of representative examples of C code.},
  address = {New York, NY, USA},
  author = {Michael Sammler and Rodolphe Lepigre and Robbert Krebbers and Kayvan Memarian and Derek Dreyer and Deepak Garg},
  booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3453483.3454036},
  isbn = {9781450383912},
  keywords = {proof automation, Iris, C programming language, refinement types, separation logic, ownership types, Coq},
  link = {https://doi.org/10.1145/3453483.3454036},
  location = {Virtual, Canada},
  numpages = {17},
  pages = {158-174},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2021},
  title = {{RefinedC: Automating the foundational verification of C code with refined ownership types}},
  url = {https://doi.org/10.1145/3453483.3454036},
  year = {2021}
}

@article{sardar:access:2021,
  abstract = {In August 2020, Intel asked the research community for feedback on the newly offered architecture extensions, called Intel Trust Domain Extensions (TDX), which give more control to Trust Domains (TDs) over processor resources. One of the key features of these extensions is the remote attestation mechanism, which provides a unified report verification mechanism for TDX and its predecessor Software Guard Extensions (SGX). Based on our experience and intuition, we respond to the request for feedback by formally specifying the attestation mechanism in the TDX using ProVerif's specification language. Although the TDX technology seems very promising, the process of formal specification reveals a number of subtle discrepancies in Intel's specifications that could potentially lead to design and implementation flaws. After resolving these discrepancies, we also present fully automated proofs that our specification of TD attestation preserves the confidentiality of the secret and authentication of the report by considering the state-of-the-art Dolev-Yao adversary in the symbolic model using ProVerif. We have submitted the draft to Intel, and Intel is in the process of making the changes.},
  author = {Muhammad Usama Sardar and Saidgani Musaev and Christof Fetzer},
  doi = {10.1109/ACCESS.2021.3087421},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {},
  month = {},
  number = {},
  pages = {83067-83079},
  title = {{Demystifying attestation in Intel Trust Domain Extensions via formal verification}},
  volume = {9},
  year = {2021}
}

@inproceedings{sarkar:pldi:2011,
  author = {Susmit Sarkar and Peter Sewell and Jade Alglave and Luc Maranget and Derek Williams},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/pldi/SarkarSAMW11},
  booktitle = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2011, San Jose, CA, USA, June 4-8, 2011},
  doi = {10.1145/1993498.1993520},
  pages = {175-186},
  timestamp = {Tue, 07 Jun 2011 16:07:38 +0200},
  title = {{Understanding POWER multiprocessors}},
  year = {2011}
}

@inproceedings{sarkar:popl:2009,
  acmid = {1480929},
  address = {New York, NY, USA},
  author = {Susmit Sarkar and Peter Sewell and Francesco Zappa Nardelli and Scott Owens and Tom Ridge and Thomas Braibant and Magnus O. Myreen and Jade Alglave},
  booktitle = {Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/1480881.1480929},
  isbn = {978-1-60558-379-2},
  keywords = {relaxed memory models, semantics},
  location = {Savannah, GA, USA},
  numpages = {13},
  pages = {379-391},
  publisher = {ACM},
  series = {POPL '09},
  title = {{The semantics of x86-CC multiprocessor machine code}},
  year = {2009}
}

@inproceedings{schemmel:cav:2020,
  abstract = {We describe a technique for systematic testing of multi-threaded programs. We combine Quasi-Optimal Partial-Order Reduction, a state-of-the-art technique that tackles path explosion due to interleaving non-determinism, with symbolic execution to handle data non-determinism. Our technique iteratively and exhaustively finds all executions of the program. It represents program executions using partial orders and finds the next execution using an underlying unfolding semantics. We avoid the exploration of redundant program traces using cutoff events. We implemented our technique as an extension of KLEE and evaluated it on a set of large multi-threaded C programs. Our experiments found several previously undiscovered bugs and undefined behaviors in memcached and GNU sort, showing that the new method is capable of finding bugs in industrial-size benchmarks.},
  address = {Cham},
  author = {Daniel Schemmel and Julian Büning and César Rodríguez and David Laprell and Klaus Wehrle},
  booktitle = {Computer Aided Verification},
  editor = {Lahiri, Shuvendu K. and Wang, Chao},
  isbn = {978-3-030-53288-8},
  pages = {376-400},
  publisher = {Springer International Publishing},
  title = {{Symbolic partial-order execution for testing multi-threaded programs}},
  year = {2020}
}

@inproceedings{schmaltz:vstte:2012,
  abstract = {Pervasive formal verification of operating systems and hypervisors is, due to their safety-critical aspects, a highly relevant area of research. Many implementations consist of both assembler and C functions. Formal verification of their correctness must consider the correct interaction of code written in these languages, which is, in practice, ensured by using matching application binary interfaces (ABIs). Also, these programs must be able to interact with hardware. We present an integrated operational small-step semantics model of intermediate-language C and Macro-Assembler code execution for pervasive operating systems and hypervisor verification. Our semantics is based on a compiler calling convention that defines callee- and caller-save registers. We sketch a theory connecting this semantic layer with an ISA-model executing the compiled code for use in a pervasive verification context. This forms a basis for soundness proofs of tools used in the VerisoftXT project and is a crucial step towards arguing formal correctness of execution of the verified code on a gate-level hardware model.},
  address = {Berlin, Heidelberg},
  author = {Sabine Schmaltz and Andrey Shadrin},
  booktitle = {Verified Software: Theories, Tools, Experiments},
  doi = {10.1007/978-3-642-27705-4_3},
  editor = {Joshi, Rajeev and Müller, Peter and Podelski, Andreas},
  isbn = {978-3-642-27705-4},
  pages = {18-33},
  publisher = {Springer Berlin Heidelberg},
  title = {{Integrated semantics of intermediate-language C and macro-assembler for pervasive formal verification of operating systems and hypervisors from VerisoftXT}},
  year = {2012}
}

@inproceedings{schwartz:sp:2010,
  address = {USA},
  author = {Edward J. Schwartz and Thanassis Avgerinos and David Brumley},
  booktitle = {Proceedings of the 2010 IEEE Symposium on Security and Privacy},
  doi = {10.1109/SP.2010.26},
  isbn = {9780769540351},
  keywords = {dynamic analysis, taint analysis, symbolic execution},
  link = {https://doi.org/10.1109/SP.2010.26},
  numpages = {15},
  pages = {317-331},
  publisher = {IEEE Computer Society},
  series = {SP '10},
  title = {{All you ever wanted to know about dynamic taint analysis and forward symbolic execution (but might have been afraid to ask)}},
  url = {https://doi.org/10.1109/SP.2010.26},
  year = {2010}
}

@inproceedings{schwarz:sefm:2016,
  author = {Oliver Schwarz and Mads Dam},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/conf/sefm/SchwarzD16},
  booktitle = {Proceedings Software Engineering and Formal Methods - 14th International Conference, SEFM 2016},
  doi = {10.1007/978-3-319-41591-8_3},
  pages = {27-44},
  timestamp = {Tue, 14 May 2019 10:00:54 +0200},
  title = {{Automatic derivation of platform noninterference properties}},
  year = {2016}
}

@inproceedings{schwerhoff:ecoop:2015,
  author = {Malte Schwerhoff and Alexander J. Summers},
  booktitle = {29th European Conference on Object-Oriented Programming (ECOOP 2015)},
  organization = {Schloss Dagstuhl, Leibniz-Zentrum für Informatik},
  pages = {614-638},
  title = {{Lightweight support for magic wands in an automatic verifier}},
  volume = {37},
  year = {2015}
}

@book{seal:book:2000,
  address = {Boston, MA, USA},
  author = {David Seal},
  edition = {2nd},
  isbn = {0201737191},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  title = {{ARM Architecture Reference Manual (ARMv5 edition)}},
  year = {2000}
}

@article{segar:fmsd:1995,
  author = {Carl-Johan H. Seger and Randal E. Bryant},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/fmsd/SegerB95.bib},
  doi = {10.1007/BF01383966},
  journal = {Formal Methods Syst. Des.},
  link = {https://doi.org/10.1007/BF01383966},
  number = {2},
  pages = {147-189},
  timestamp = {Fri, 13 Mar 2020 10:55:14 +0100},
  title = {{Formal verification by symbolic evaluation of partially-ordered trajectories}},
  url = {https://doi.org/10.1007/BF01383966},
  volume = {6},
  year = {1995}
}

@inproceedings{sen:fse:2005,
  abstract = {In unit testing, a program is decomposed into units which are collections of functions. A part of unit can be tested by generating inputs for a single entry function. The entry function may contain pointer arguments, in which case the inputs to the unit are memory graphs. The paper addresses the problem of automating unit testing with memory graphs as inputs. The approach used builds on previous work combining symbolic and concrete execution, and more specifically, using such a combination to generate test inputs to explore all feasible execution paths. The current work develops a method to represent and track constraints that capture the behavior of a symbolic execution of a unit with memory graphs as inputs. Moreover, an efficient constraint solver is proposed to facilitate incremental generation of such test inputs. Finally, CUTE, a tool implementing the method is described together with the results of applying CUTE to real-world examples of C code.},
  address = {New York, NY, USA},
  author = {Koushik Sen and Darko Marinov and Gul Agha},
  booktitle = {Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  doi = {10.1145/1081706.1081750},
  isbn = {1595930140},
  keywords = {data structure testing, concolic testing, random testing, explicit path model-checking, unit testing, testing C programs},
  link = {https://doi.org/10.1145/1081706.1081750},
  location = {Lisbon, Portugal},
  numpages = {10},
  pages = {263-272},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE-13},
  title = {{CUTE: A concolic unit testing engine for C}},
  url = {https://doi.org/10.1145/1081706.1081750},
  year = {2005}
}

@inproceedings{seshadri:sosp:2007,
  author = {Arvind Seshadri and Mark Luk and Ning Qu and Adrian Perrig},
  booktitle = {SOSP},
  doi = {10.1145/1323293.1294294},
  number = {6},
  organization = {ACM},
  pages = {335-350},
  title = {{SecVisor: A tiny hypervisor to provide lifetime kernel code integrity for commodity OSes}},
  volume = {41},
  year = {2007}
}

@inproceedings{sewell:pldi:2013,
  author = {Thomas Arthur Leck Sewell and Magnus O. Myreen and Gerwin Klein},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/pldi/SewellMK13},
  booktitle = {ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI '13, Seattle, WA, USA, June 16-19, 2013},
  doi = {10.1145/2462156.2462183},
  pages = {471-482},
  timestamp = {Sun, 09 Jun 2013 12:32:52 +0200},
  title = {{Translation validation for a verified OS kernel}},
  year = {2013}
}

@misc{shamis:arxiv:2021,
  archiveprefix = {arXiv},
  author = {Alex Shamis and Peter Pietzuch and Miguel Castro and Edward Ashton and Amaury Chamayou and Sylvan Clebsch and Antoine Delignat-Lavaud and Cedric Fournet and Matthew Kerner and Julien Maffre and Manuel Costa and Mark Russinovich},
  eprint = {2105.13116},
  primaryclass = {cs.DC},
  title = {{PAC: Practical Accountability for CCF}},
  year = {2021}
}

@inproceedings{sharma:oopsla:2012,
  acmid = {2509509},
  address = {New York, NY, USA},
  author = {Rahul Sharma and Eric Schkufza and Berkeley Churchill and Alex Aiken},
  booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages and Applications},
  doi = {10.1145/2509136.2509509},
  isbn = {978-1-4503-2374-1},
  keywords = {binary analysis, compilers, markov chain monte carlo, optimization, smt, superoptimization, verification, x86},
  location = {Indianapolis, Indiana, USA},
  numpages = {16},
  pages = {391-406},
  publisher = {ACM},
  series = {OOPSLA '13},
  title = {{Data-driven equivalence checking}},
  year = {2013}
}

@inproceedings{sharma:pls:2013,
  abstract = {We describe a Guess-and-Check algorithm for computing algebraic equation invariants of the form \wedge {\th}inspaceifi(x1,{\l}dots,xn){\th}inspace={\th}inspace0, where each fiis a polynomial over the variables x1,{\l}dots,xnof the program. The ``guess'' phase is data driven and derives a candidate invariant from data generated from concrete executions of the program. This candidate invariant is subsequently validated in a ``check'' phase by an off-the-shelf SMT solver. Iterating between the two phases leads to a sound algorithm. Moreover, we are able to prove a bound on the number of decision procedure queries which Guess-and-Check requires to obtain a sound invariant. We show how Guess-and-Check can be extended to generate arbitrary boolean combinations of linear equalities as invariants, which enables us to generate expressive invariants to be consumed by tools that cannot handle non-linear arithmetic. We have evaluated our technique on a number of benchmark programs from recent papers on invariant generation. Our results are encouraging - we are able to efficiently compute algebraic invariants in all cases, with only a few tests.},
  address = {Berlin, Heidelberg},
  author = {Rahul Sharma and Saurabh Gupta and Bharath Hariharan and Alex Aiken and Percy Liang and Aditya V. Nori},
  booktitle = {Programming Languages and Systems},
  doi = {10.1007/978-3-642-37036-6_31},
  editor = {Felleisen, Matthias and Gardner, Philippa},
  isbn = {978-3-642-37036-6},
  pages = {574-592},
  publisher = {Springer Berlin Heidelberg},
  title = {{A data driven approach for algebraic loop invariants}},
  year = {2013}
}

@inproceedings{sheeran:fmcad:2000,
  abstract = {We take a fresh look at the problem of how to check safety properties of finite state machines. We are particularly interested in checking safety properties with the help of a SAT-solver. We describe some novel induction-based methods, and show how they are related to more standard fixpoint algorithms for invariance checking. We also present preliminary experimental results in the verification of FPGA cores. This demonstrates the practicality of combining a SAT-solver with induction for safety property checking of hardware in a real design flow.},
  address = {Berlin, Heidelberg},
  author = {Mary Sheeran and Satnam Singh and Gunnar Stålmarck},
  booktitle = {Proceedings of the Third International Conference on Formal Methods in Computer-Aided Design},
  isbn = {3540412190},
  numpages = {18},
  pages = {108-125},
  publisher = {Springer-Verlag},
  series = {FMCAD '00},
  title = {{Checking safety properties using induction and a SAT-solver}},
  year = {2000}
}

@phdthesis{shi:phd:2013,
  author = {Xiaomu Shi},
  hal_id = {tel-00937524},
  hal_version = {v2},
  keywords = {Simulator ; Program proof ; Certification ; Embedded system ; Simulateur ; Preuve de programme ; Syst{\`e}me embarqu{\'e}},
  link = {https://tel.archives-ouvertes.fr/tel-00937524},
  month = {July},
  number = {2013GRENM075},
  pdf = {https://tel.archives-ouvertes.fr/tel-00937524/file/pdf2star-1400242693-32245\_SHI\_2013\_archivage.pdf},
  school = {Université de Grenoble},
  title = {{Certification of an instruction set simulator}},
  url = {https://tel.archives-ouvertes.fr/tel-00937524},
  year = {2013}
}

@inproceedings{shoshitaishvili:sandp:2016,
  abstract = {Finding and exploiting vulnerabilities in binary code is a challenging task. The lack of high-level, semantically rich information about data structures and control constructs makes the analysis of program properties harder to scale. However, the importance of binary analysis is on the rise. In many situations binary analysis is the only possible way to prove (or disprove) properties about the code that is actually executed. In this paper, we present a binary analysis framework that implements a number of analysis techniques that have been proposed in the past. We present a systematized implementation of these techniques, which allows other researchers to compose them and develop new approaches. In addition, the implementation of these techniques in a unifying framework allows for the direct comparison of these apporaches and the identification of their advantages and disadvantages. The evaluation included in this paper is performed using a recent dataset created by DARPA for evaluating the effectiveness of binary vulnerability analysis techniques. Our framework has been open-sourced and is available to the security community.},
  author = {Yan Shoshitaishvili and Ruoyu Wang and Christopher Salls and Nick Stephens and Mario Polino and Andrew Dutcher and John Grosen and Siji Feng and Christophe Hauser and Christopher Kruegel and Giovanni Vigna},
  booktitle = {2016 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP.2016.17},
  issn = {2375-1207},
  keywords = {program diagnostics;security of data;binary vulnerability analysis technique;binary code;data structure;DARPA;Computer bugs;Semantics;Security;Binary codes;Engines;Operating systems;attacks and defenses;security architectures;system security},
  month = {May},
  number = {},
  pages = {138-157},
  title = {{SOK: (State of) the art of war: Offensive techniques in binary analysis}},
  volume = {},
  year = {2016}
}

@inproceedings{shoshitaishvili:sp:2016,
  author = {Yan Shoshitaishvili and Ruoyu Wang and Christopher Salls and Nick Stephens and Mario Polino and Andrew Dutcher and John Grosen and Siji Feng and Christophe Hauser and Christopher Kruegel and Giovanni Vigna},
  booktitle = {2016 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP.2016.17},
  number = {},
  pages = {138-157},
  title = {{SOK: (state of) the art of war: Offensive techniques in binary analysis}},
  volume = {},
  year = {2016}
}

@inproceedings{siddiqui:oopsla:2012,
  abstract = {This paper introduces a novel approach to scale symbolic execution -- a program analysis technique for systematic exploration of bounded execution paths--for test input generation. While the foundations of symbolic execution were developed over three decades ago, recent years have seen a real resurgence of the technique, specifically for systematic bug finding. However, scaling symbolic execution remains a primary technical challenge due to the inherent complexity of the path-based exploration that lies at core of the technique.Our key insight is that the state of the analysis can be represented highly compactly: a test input is all that is needed to effectively encode the state of a symbolic execution run. We present ranged symbolic execution, which embodies this insight and uses two test inputs to define a range, i.e., the beginning and end, for a symbolic execution run. As an application of our approach, we show how it enables scalability by distributing the path exploration--both in a sequential setting with a single worker node and in a parallel setting with multiple workers. As an enabling technology, we leverage the open-source, state-of-the-art symbolic execution tool KLEE. Experimental results using 71 programs chosen from the widely deployed GNU Coreutils set of Unix utilities show that our approach provides a significant speedup over KLEE. For example, using 10 worker cores, we achieve an average speed-up of 6.6X for the 71 programs.},
  address = {New York, NY, USA},
  author = {Junaid Haroon Siddiqui and Sarfraz Khurshid},
  booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
  doi = {10.1145/2384616.2384654},
  isbn = {9781450315616},
  keywords = {test input as analysis state, klee, ranged analysis, parallel symbolic execution},
  link = {https://doi.org/10.1145/2384616.2384654},
  location = {Tucson, Arizona, USA},
  numpages = {14},
  pages = {523-536},
  publisher = {Association for Computing Machinery},
  series = {OOPSLA '12},
  title = {{Scaling symbolic execution using ranged analysis}},
  url = {https://doi.org/10.1145/2384616.2384654},
  year = {2012}
}

@inproceedings{siegel:sc:2015,
  author = {Stephen F. Siegel and Manchun Zheng and Ziqing Luo and Timothy K. Zirkel and Andre V. Marianiello and John G. Edenhofner and Matthew B. Dwyer and Michael S. Rogers},
  booktitle = {SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  doi = {10.1145/2807591.2807635},
  issn = {2167-4337},
  keywords = {concurrency (computers);message passing;multi-threading;program verification;CIVL;concurrency intermediate verification language;parallel programs;message-passing libraries;MPI;multithreading;GPU language extensions;OpenMP;Pthreads;CUDA;software verification tools;back-end verifier;model checking;symbolic execution;deadlock absence;race conditions;assertion violations;illegal pointer dereferences;memory leaks;divisions by zero;out-of-bound array indexing;Concurrent computing;Graphics processing units;Libraries;Model checking;Message systems;Government;Standards},
  month = {Nov},
  number = {},
  pages = {1-12},
  title = {{CIVL: the concurrency intermediate verification language}},
  volume = {},
  year = {2015}
}

@inproceedings{sigurbjarnarson:osdi:2016,
  author = {Helgi Sigurbjarnarson and James Bornholt and Emina Torlak and Xi Wang},
  booktitle = {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
  pages = {1-16},
  title = {{Push-button verification of file systems via crash refinement}},
  year = {2016}
}

@inproceedings{sigurbjarnarson:osdi:2018,
  author = {Helgi Sigurbjarnarson and Luke Nelson and Bruno Castro-Karney and James Bornholt and Emina Torlak and Xi Wang},
  booktitle = {OSDI},
  pages = {287-305},
  publisher = {USENIX Association},
  title = {{Nickel: A framework for design and verification of information flow control systems}},
  year = {2018}
}

@inproceedings{silva:sbac:2016,
  author = {Hércules Cardoso da Silva and Flávia Pisani and Edson Borin},
  booktitle = {2016 International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW)},
  doi = {10.1109/SBAC-PADW.2016.19},
  issn = {},
  keywords = {application program interfaces;C++ language;message passing;parallel programming;program compilers;API methods;API functions;programmability;standard C++ compilation frameworks;C++ programming model;runtime systems;compilers;hardware accelerators;GPU;CPU;heterogeneous computing devices;OpenMP;OpenCL;SYCL;Benchmark testing;Programming;C++ languages;Performance evaluation;Kernel;MOS devices;Program processors;SYCL;OpenCL;OpenMP;parallel programming;performance evaluation;programmability evaluation},
  month = {October},
  number = {},
  pages = {61-66},
  title = {{A comparative study of SYCL, OpenCL, and OpenMP}},
  volume = {},
  year = {2016}
}

@inproceedings{skorstengaard:esop:2018,
  abstract = {Capability machines provide security guarantees at machine level which makes them an interesting target for secure compilation schemes that provably enforce properties such as control-flow correctness and encapsulation of local state. We provide a formalization of a representative capability machine with local capabilities and study a novel calling convention. We provide a logical relation that semantically captures the guarantees provided by the hardware (a form of capability safety) and use it to prove control-flow correctness and encapsulation of local state. The logical relation is not specific to our calling convention and can be used to reason about arbitrary programs.},
  address = {Cham},
  author = {Lau Skorstengaard and Dominique Devriese and Lars Birkedal},
  booktitle = {Programming Languages and Systems},
  doi = {10.1007/978-3-319-89884-1_17},
  editor = {Ahmed, Amal},
  isbn = {978-3-319-89884-1},
  pages = {475-501},
  publisher = {Springer International Publishing},
  title = {{Reasoning about a machine with local capabilities}},
  year = {2018}
}

@article{skorstengaard:popl:2019,
  address = {New York, NY, USA},
  articleno = {Article 19},
  author = {Lau Skorstengaard and Dominique Devriese and Lars Birkedal},
  doi = {10.1145/3290332},
  issue_date = {January 2019},
  journal = {Proc. ACM Program. Lang.},
  keywords = {linear capabilities, fully abstract overlay semantics, secure compilation, well-bracketed control flow, stack frame encapsulation, fully abstract compilation, capability machines},
  month = {January},
  number = {POPL},
  numpages = {28},
  publisher = {Association for Computing Machinery},
  title = {{StkTokens: Enforcing well-bracketed control flow and stack encapsulation using linear capabilities}},
  url = {https://doi.org/10.1145/3290332},
  volume = {3},
  year = {2019}
}

@inproceedings{slobodova:memocode:2011,
  author = {Anna Slobodová and Jared Davis and Sol Swords and Warren A. Hunt Jr.},
  booktitle = {Formal Methods and Models for Codesign (MEMOCODE), 2011 9th IEEE/ACM International Conference on},
  doi = {10.1109/MEMCOD.2011.5970515},
  organization = {IEEE},
  pages = {89-97},
  title = {{A flexible formal verification framework for industrial scale validation}},
  year = {2011}
}

@inproceedings{smans:ecoop:2009,
  abstract = {The dynamic frames approach has proven to be a powerful formalism for specifying and verifying object-oriented programs. However, it requires writing and checking many frame annotations. In this paper, we propose a variant of the dynamic frames approach that eliminates the need to explicitly write and check frame annotations. Reminiscent of separation logic's frame rule, programmers write access assertions inside pre- and postconditions instead of writing frame annotations. From the precondition, one can then infer an upper bound on the set of locations writable or readable by the corresponding method. We implemented our approach in a tool, and used it to automatically verify several challenging programs, including subject-observer, iterator and linked list.},
  address = {Berlin, Heidelberg},
  author = {Jan Smans and Bart Jacobs and Frank Piessens},
  booktitle = {ECOOP 2009 -- Object-Oriented Programming},
  doi = {10.1007/978-3-642-03013-0_8},
  editor = {Drossopoulou, Sophia},
  isbn = {978-3-642-03013-0},
  pages = {148-172},
  publisher = {Springer Berlin Heidelberg},
  title = {{Implicit dynamic frames: Combining dynamic frames and separation logic}},
  year = {2009}
}

@inproceedings{smans:fmood:2010,
  abstract = {Separation logic is a popular specification language for imperative programs where the heap can only be mentioned through points-to assertions. However, separation logic's take on assertions does not match well with the classical view of assertions as boolean, side effect-free, potentially heap-dependent expressions from the host programming language familiar to many developers.},
  address = {Berlin, Heidelberg},
  author = {Jan Smans and Bart Jacobs and Frank Piessens},
  booktitle = {Formal Techniques for Distributed Systems},
  editor = {Hatcliff, John
and Zucca, Elena},
  isbn = {978-3-642-13464-7},
  pages = {170-185},
  publisher = {Springer Berlin Heidelberg},
  title = {{Heap-dependent expressions in separation logic}},
  year = {2010}
}

@inproceedings{smetters:nspw:2002,
  address = {New York, NY, USA},
  author = {Diana K. Smetters and Rebecca E. Grinter},
  booktitle = {Proceedings of the 2002 Workshop on New Security Paradigms},
  doi = {10.1145/844102.844117},
  isbn = {158113598X},
  keywords = {usable security},
  link = {https://doi.org/10.1145/844102.844117},
  location = {Virginia Beach, Virginia},
  numpages = {8},
  pages = {82-89},
  publisher = {Association for Computing Machinery},
  series = {NSPW '02},
  title = {{Moving from the design of usable security technologies to the design of useful secure applications}},
  url = {https://doi.org/10.1145/844102.844117},
  year = {2002}
}

@book{smith:book:1996,
  author = {Brian Cantwell Smith},
  isbn = {9780262193634},
  publisher = {MIT Press},
  title = {{On the origin of objects}},
  year = {1996}
}

@inproceedings{smith:esop:2000,
  abstract = {Linear type systems allow destructive operations such as object deallocation and imperative updates of functional data structures. These operations and others, such as the ability to reuse memory at different types, are essential in low-level typed languages. However, traditional linear type systems are too restrictive for use in low-level code where it is necessary to exploit pointer aliasing. We present a new typed language that allows functions to specify the shape of the store that they expect and to track the flow of pointers through a computation. Our type system is expressive enough to represent pointer aliasing and yet safely permit destructive operations.},
  address = {Berlin, Heidelberg},
  author = {Frederick Smith and David Walker and Greg Morrisett},
  booktitle = {Programming Languages and Systems},
  doi = {10.1007/3-540-46425-5_24},
  editor = {Smolka, Gert},
  isbn = {978-3-540-46425-9},
  pages = {366-381},
  publisher = {Springer Berlin Heidelberg},
  title = {{Alias types}},
  year = {2000}
}

@inproceedings{smith:fossacs:2009,
  author = {Geoffrey Smith},
  booktitle = {International Conference on Foundations of Software Science and Computational Structures},
  doi = {10.1007/978-3-642-00596-1_21},
  organization = {Springer},
  pages = {288-302},
  title = {{On the foundations of quantitative information flow}},
  year = {2009}
}

@article{smith:tocs:1984,
  author = {James E. Smith},
  doi = {10.1145/357401.357403},
  issn = {0734-2071},
  journal = {ACM Transactions on Computer Systems},
  number = {4},
  pages = {289-308},
  publisher = {ACM Press},
  title = {{Decoupled access/execute computer architectures}},
  volume = {2},
  year = {1984}
}

@inproceedings{spencer:security:1999,
  address = {Berkeley, CA, USA},
  author = {Ray Spencer and Stephen Smalley and Peter Loscocco and Mike Hibler and David G. Andersen and Jay Lepreau},
  booktitle = {Proceedings of the 8th Conference on USENIX Security Symposium},
  location = {Washington, D.C.},
  numpages = {1},
  pages = {11-11},
  publisher = {USENIX Association},
  series = {SSYM'99},
  title = {{The Flask security architecture: System support for diverse security policies}},
  year = {1999}
}

@article{srinivasan:ieeetoc:2010,
  address = {Los Alamitos, CA, USA},
  author = {Sudarshan K. Srinivasan},
  doi = {10.1109/TC.2010.18},
  issn = {0018-9340},
  journal = {IEEE Transactions on Computers},
  number = {8},
  pages = {1138-1144},
  publisher = {IEEE Computer Society},
  title = {{Automatic refinement checking of pipelines with out-of-order execution}},
  volume = {59},
  year = {2010}
}

@article{stephens:micro:2017,
  abstract = {In this paper we describe the ARM Scalable Vector Extension (SVE). Several goals guided the design of the architecture. First was the need to extend the vector processing capability associated with the ARM AArch64 execution state to better address the compute requirements in domains such as high performance computing (HPC), data analytics, computer vision and machine learning. Second was the desire to introduce an extension that can scale across multiple implementations, both now and into the future, allowing CPU designers to choose the vector length most suitable for their power, performance and area targets. Finally, the architecture should avoid imposing a software development cost as the vector length changes and where possible reduce it by improving the reach of compiler auto-vectorization technologies.  We believe SVE achieves these goals. It allows implementations to choose a vector register length between 128 and 2048 bits. It supports a vector length agnostic programming model which allows code to run and scale automatically across all vector lengths without recompilation. Finally, it introduces several innovative features that begin to overcome some of the traditional barriers to auto-vectorization.},
  affiliation = {ARM Ltd},
  ar_shortname = {IEEE Micro},
  author = {Nigel Stephens and Stuart Biles and Matthias Boettcher and Jacob Eapen and Mbou Eyole and Giacomo Gabrielli and Matt Horsnell and Grigorios Magklis and Alejandro Martinez and Nathanael Premillieu and Alastair D. Reid and Alejandro Rico and Paul Walker},
  doi = {10.1109/MM.2017.35},
  journal = {IEEE Micro},
  month = {March},
  number = {2},
  pages = {26-39},
  title = {{The ARM scalable vector extension}},
  volume = {37},
  year = {2017}
}

@inproceedings{stephens:ndss:2016,
  author = {Nick Stephens and John Grosen and Christopher Salls and Andrew Dutcher and Ruoyu Wang and Jacopo Corbetta and Yan Shoshitaishvili and Christopher Kruegel and Giovanni Vigna},
  booktitle = {23rd Annual Network and Distributed System Security Symposium, NDSS 2016, San Diego, California, USA, February 21-24, 2016},
  doi = {10.14722/ndss.2016.23368},
  link = {http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2017/09/driller-augmenting-fuzzing-through-selective-symbolic-execution.pdf},
  publisher = {The Internet Society},
  title = {{Driller: Augmenting fuzzing through selective symbolic execution}},
  url = {http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2017/09/driller-augmenting-fuzzing-through-selective-symbolic-execution.pdf},
  year = {2016}
}

@inproceedings{stewart:difts:2014,
  author = {Daryl Stewart and David Gilday and Daniel Nevill and Thomas Roberts},
  booktitle = {International Workshop on Design and Implementation of Formal Tools and Systems},
  series = {DIFTS '14},
  title = {{Processor memory system verification using DOGReL: a language for specifying end-to-end properties}},
  year = {2014}
}

@article{stojmenovic:tpds:2010,
  abstract = {},
  author = {Ivan Stojmenovic},
  doi = {10.1109/TPDS.2010.12},
  issn = {1558-2183},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  keywords = {},
  month = {Feb},
  number = {2},
  pages = {145-147},
  title = {{Editor's note: How to write research articles in computing and engineering disciplines}},
  volume = {21},
  year = {2010}
}

@article{stump:fmsd:2013,
  author = {Aaron Stump and Duckki Oe and Andrew Reynolds and Liana Hadarean and Cesare Tinelli},
  doi = {10.1007/s10703-012-0163-3},
  journal = {Formal Methods in System Design},
  number = {1},
  pages = {91-118},
  publisher = {Springer},
  title = {{SMT proof checking using a logical framework}},
  volume = {42},
  year = {2013}
}

@article{su:computer:1974,
  abstract = {A digital system can be described at several levels. 1) The highest level is the algorithmic level which specifies only the algorithm to be used for solving a design problem. 2) The second level is the PMS (Processor, Memory, Switch) level which describes a system by processors, memory components, peripheral units, and switching networks. 3) The instruction level describes the instructions of a computer. 4) The register transfer or microinstruction level describes operations among registers. 5) The logic level expresses network in terms of gates and flip-flops. 6) The lowest level is the circuit level which implements gates and flip-flops by circuit elements such as transistors, resistors, etc.},
  author = {Stephen Y. H. Su},
  doi = {10.1109/MC.1974.6323411},
  issn = {1558-0814},
  journal = {Computer},
  keywords = {Registers;Hardware;Computers;Algorithm design and analysis;Logic design;Digital systems;Computational modeling},
  month = {Dec},
  number = {12},
  pages = {45-51},
  title = {{A survey of computer hardware description languages in the U.S.A.}},
  volume = {7},
  year = {1974}
}

@inproceedings{subhlok:ppopp:1993,
  acmid = {155334},
  address = {New York, NY, USA},
  author = {Jaspal Subhlok and James M. Stichnoth and David R. O'Hallaron and Thomas R. Gross},
  booktitle = {Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  doi = {10.1145/155332.155334},
  isbn = {0-89791-589-5},
  location = {San Diego, California, USA},
  numpages = {10},
  pages = {13-22},
  publisher = {ACM},
  series = {PPOPP '93},
  title = {{Exploiting task and data parallelism on a multicomputer}},
  year = {1993}
}

@article{sutcliffe:ai:2001,
  abstract = {A key concern of ATP research is the development of more powerful systems, capable of solving more difficult problems within the same resource limits. In order to build more powerful systems, it is important to understand which systems, and hence which techniques, work well for what types of problems. This paper deals with the empirical evaluation of general purpose ATP systems, to determine which systems work well for what types of problems. This requires also dealing with the issues of assigning ATP problems into classes that are reasonably homogeneous with respect to the ATP systems that (attempt to) solve the problems, and assigning ratings to problems based on their difficulty.},
  author = {Geoff Sutcliffe and Christian Suttner},
  doi = {https://doi.org/10.1016/S0004-3702(01)00113-8},
  issn = {0004-3702},
  journal = {Artificial Intelligence},
  keywords = {ATP system evaluation, ATP problem classification, ATP problem evaluation},
  link = {http://www.sciencedirect.com/science/article/pii/S0004370201001138},
  number = {1},
  pages = {39 - 54},
  title = {{Evaluating general purpose automated theorem proving systems}},
  url = {http://www.sciencedirect.com/science/article/pii/S0004370201001138},
  volume = {131},
  year = {2001}
}

@article{systemverilog:ieee:2013,
  author = {IEEE},
  doi = {10.1109/IEEESTD.2013.6469140},
  journal = {IEEE Std. 1800-2012},
  title = {{IEEE standard for SystemVerilog - Unified hardware design, specification, and verification language}},
  volume = {},
  year = {2013}
}

@inproceedings{szekeres:sandp:2013,
  abstract = {Memory corruption bugs in software written in low-level languages like C or C++ are one of the oldest problems in computer security. The lack of safety in these languages allows attackers to alter the program's behavior or take full control over it by hijacking its control flow. This problem has existed for more than 30 years and a vast number of potential solutions have been proposed, yet memory corruption attacks continue to pose a serious threat. Real world exploits show that all currently deployed protections can be defeated. This paper sheds light on the primary reasons for this by describing attacks that succeed on today's systems. We systematize the current knowledge about various protection techniques by setting up a general model for memory corruption attacks. Using this model we show what policies can stop which attacks. The model identifies weaknesses of currently deployed techniques, as well as other proposed protections enforcing stricter policies. We analyze the reasons why protection mechanisms implementing stricter polices are not deployed. To achieve wide adoption, protection mechanisms must support a multitude of features and must satisfy a host of requirements. Especially important is performance, as experience shows that only solutions whose overhead is in reasonable bounds get deployed. A comparison of different enforceable policies helps designers of new protection mechanisms in finding the balance between effectiveness (security) and efficiency. We identify some open research problems, and provide suggestions on improving the adoption of newer techniques.},
  author = {László Szekeres and Mathias Payer and Tao Wei and Dawn Song},
  booktitle = {2013 IEEE Symposium on Security and Privacy},
  doi = {10.1109/SP.2013.13},
  issn = {1081-6011},
  keywords = {},
  month = {May},
  number = {},
  pages = {48-62},
  title = {{SoK: Eternal war in memory}},
  volume = {},
  year = {2013}
}

@article{tahat:fmcad:2019,
  author = {Amer Tahat and Sarang Joshi and Pronnoy Goswami and Binoy Ravindran},
  doi = {10.23919/FMCAD.2019.8894252},
  title = {{Scalable translation validation of unverified legacy OS code}},
  year = {2019}
}

@inproceedings{tang:sec:2017,
  acmid = {3241272},
  address = {Berkeley, CA, USA},
  author = {Adrian Tang and Simha Sethumadhavan and Salvatore Stolfo},
  booktitle = {Proceedings of the 26th USENIX Conference on Security Symposium},
  isbn = {978-1-931971-40-9},
  link = {https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-tang.pdf},
  location = {Vancouver, BC, Canada},
  numpages = {18},
  pages = {1057-1074},
  publisher = {USENIX Association},
  series = {SEC'17},
  title = {{CLKSCREW: Exposing the perils of security-oblivious energy management}},
  url = {https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-tang.pdf},
  year = {2017}
}

@inproceedings{tanter:aosd:2010,
  abstract = {In aspect-oriented programming languages, advice evaluation is usually considered as part of the base program evaluation. This is also the case for certain pointcuts, such as if pointcuts in AspectJ, or simply all pointcuts in higher-order aspect languages like AspectScheme. While viewing aspects as part of base level computation clearly distinguishes AOP from reflection, it also comes at a price: because aspects observe base level computation, evaluating pointcuts and advice at the base level can trigger infinite regression. To avoid these pitfalls, aspect languages propose ad-hoc mechanisms, which increase the complexity for programmers while being insufficient in many cases. After shedding light on the many facets of the issue, this paper proposes to clarify the situation by introducing levels of execution in the programming language, thereby allowing aspects to observe and run at specific, possibly different, levels. We adopt a defensive default that avoids infinite regression in all cases, and give advanced programmers the means to override this default using level shifting operators. We formalize the semantics of our proposal, and provide an implementation. This work recognizes that different aspects differ in their intended nature, and shows that structuring execution contexts helps tame the power of aspects and metaprogramming.},
  address = {New York, NY, USA},
  author = {{\'E}ric Tanter},
  booktitle = {Proceedings of the 9th International Conference on Aspect-Oriented Software Development},
  doi = {10.1145/1739230.1739236},
  isbn = {9781605589589},
  keywords = {meta-programming, execution level, scoping mechanism, aspect-oriented programming, infinite regression, conflation},
  link = {https://doi.org/10.1145/1739230.1739236},
  location = {Rennes and Saint-Malo, France},
  numpages = {12},
  pages = {37-48},
  publisher = {Association for Computing Machinery},
  series = {AOSD '10},
  title = {{Execution levels for aspect-oriented programming}},
  url = {https://doi.org/10.1145/1739230.1739236},
  year = {2010}
}

@inproceedings{thies:micro:2007,
  acmid = {1331731},
  address = {Washington, DC, USA},
  author = {William Thies and Vikram Chandrasekhar and Saman P. Amarasinghe},
  booktitle = {Proceedings of the 40th Annual IEEE/ACM International Symposium on Microarchitecture},
  doi = {10.1109/MICRO.2007.7},
  isbn = {0-7695-3047-8},
  numpages = {14},
  pages = {356-369},
  publisher = {IEEE Computer Society},
  series = {MICRO 40},
  title = {{A practical approach to exploiting coarse-grained pipeline parallelism in C programs}},
  year = {2007}
}

@inproceedings{thies:ppopp:2005,
  author = {William Thies and Michal Karczmarek and Janis Sermulins and Rodric M. Rabbah and Saman P. Amarasinghe},
  booktitle = {PPoPP '05: Proceedings of Symposium on Principles and Practice of Parallel Programming},
  doi = {10.1145/1065944.1065975},
  isbn = {1-59593-080-9},
  pages = {224-235},
  publisher = {ACM Press},
  title = {{Teleport messaging for distributed stream programs}},
  year = {2005}
}

@inproceedings{tillmann:fse:2005,
  address = {New York, NY, USA},
  author = {Nikolai Tillmann and Wolfram Schulte},
  booktitle = {Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  doi = {10.1145/1081706.1081749},
  isbn = {1595930140},
  keywords = {automatic test input generation, unit testing, constraint solving, algebraic data types, symbolic execution},
  link = {https://doi.org/10.1145/1081706.1081749},
  location = {Lisbon, Portugal},
  numpages = {10},
  pages = {253-262},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE-13},
  title = {{Parameterized unit tests}},
  url = {https://doi.org/10.1145/1081706.1081749},
  year = {2005}
}

@inproceedings{tiwari:asplos:2009,
  author = {Mohit Tiwari and Hassan M. G. Wassel and Bita Mazloom and Shashidhar Mysore and Frederic T. Chong and Timothy Sherwood},
  booktitle = {ACM Sigplan Notices},
  doi = {10.1145/1508244.1508258},
  number = {3},
  organization = {ACM},
  pages = {109-120},
  title = {{Complete information flow tracking from the gates up}},
  volume = {44},
  year = {2009}
}

@inproceedings{tiwari:isca:2009,
  author = {Mohit Tiwari and Xun Li and Hassan M. G. Wassel and Frederic T. Chong and Timothy Sherwood},
  booktitle = {Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture},
  doi = {10.1145/1669112.1669174},
  organization = {ACM},
  pages = {493-504},
  title = {{Execution leases: A hardware-supported mechanism for enforcing strong non-interference}},
  year = {2009}
}

@inproceedings{tiwari:isca:2011,
  author = {Mohit Tiwari and Jason K. Oberg and Xun Li and Jonathan Valamehr and Timothy Levin and Ben Hardekopf and Ryan Kastner and Frederic T. Chong and Timothy Sherwood},
  booktitle = {ACM SIGARCH Computer Architecture News},
  doi = {10.1145/2000064.2000087},
  number = {3},
  organization = {ACM},
  pages = {189-200},
  title = {{Crafting a usable microkernel, processor, and I/O system with strict and provable information flow security}},
  volume = {39},
  year = {2011}
}

@article{tofte:inco:1997,
  abstract = {This paper describes a memory management discipline for programs that perform dynamic memory allocation and de-allocation. At runtime, all values are put intoregions. The store consists of a stack of regions. All points of region allocation and de-allocation are inferred automatically, using a type and effect based program analysis. The scheme does not assume the presence of a garbage collector. The scheme was first presented in 1994 (M. Tofte and J.-P. Talpin,in"Proceedings of the 21st ACM SIGPLAN SIGACT Symposium on Principles of Programming Languages," pp. 188 201); subsequently, it has been tested in The ML Kit with Regions, a region-based, garbage-collection free implementation of the Standard ML Core language, which includes recursive datatypes, higher-order functions and updatable references L. Birkedal, M. Tofte, and M. Vejlstrup, (1996),in"Proceedings of the 23 rd ACM SIGPLAN SIGACT Symposium on Principles of Programming Languages," pp. 171 183. This paper defines a region-based dynamic semantics for a skeletal programming language extracted from Standard ML. We present the inference system which specifies where regions can be allocated and de-allocated and a detailed proof that the system is sound with respect to a standard semantics. We conclude by giving some advice on how to write programs that run well on a stack of regions, based on practical experience with the ML Kit.},
  address = {USA},
  author = {Mads Tofte and Jean-Pierre Talpin},
  doi = {10.1006/inco.1996.2613},
  issn = {0890-5401},
  issue_date = {Feb. 1, 1997},
  journal = {Inf. Comput.},
  link = {https://doi.org/10.1006/inco.1996.2613},
  month = {February},
  number = {2},
  numpages = {68},
  pages = {109-176},
  publisher = {Academic Press, Inc.},
  title = {{Region-based memory management}},
  url = {https://doi.org/10.1006/inco.1996.2613},
  volume = {132},
  year = {1997}
}

@inproceedings{toman:ase:2015,
  author = {John Toman and Stuart Pernsteiner and Emina Torlak},
  booktitle = {2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE.2015.77},
  keywords = {data structures;formal verification;program compilers;program debugging;program diagnostics;program testing;software libraries;CRUST;Rust;static analysis;compiler;pointer aliasing invariants;data structure implementations;memory safety violations;exhaustive test generation;bounded model checking;unsafe library code;memory safety bugs;Arrays;Libraries;Safety;Computer bugs;Indexes;Standards;SMT-based verification;test generation;memory safety},
  month = {November},
  number = {},
  pages = {75-80},
  title = {{Crust: A bounded verifier for Rust}},
  volume = {},
  year = {2015}
}

@inproceedings{torlak:onward:2013,
  acmid = {2509586},
  address = {New York, NY, USA},
  author = {Emina Torlak and Rastislav Bodik},
  booktitle = {Proceedings of the 2013 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming \& Software},
  doi = {10.1145/2509578.2509586},
  isbn = {978-1-4503-2472-4},
  keywords = {solver-aided languages},
  location = {Indianapolis, Indiana, USA},
  numpages = {18},
  pages = {135-152},
  publisher = {ACM},
  series = {Onward! 2013},
  title = {{Growing solver-aided languages with Rosette}},
  url = {http://doi.acm.org/10.1145/2509578.2509586},
  year = {2013}
}

@inproceedings{torlak:pldi:2014,
  acmid = {2594340},
  address = {New York, NY, USA},
  author = {Emina Torlak and Rastislav Bodik},
  booktitle = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2594291.2594340},
  isbn = {978-1-4503-2784-8},
  keywords = {solver-aided languages, symbolic virtual machine},
  location = {Edinburgh, United Kingdom},
  numpages = {12},
  pages = {530-541},
  publisher = {ACM},
  series = {PLDI'14},
  title = {{A lightweight symbolic virtual machine for solver-aided host languages}},
  url = {http://doi.acm.org/10.1145/2594291.2594340},
  year = {2014}
}

@inproceedings{trabish:icse:2018,
  abstract = {Symbolic execution is a powerful program analysis technique that systematically explores multiple program paths. However, despite important technical advances, symbolic execution often struggles to reach deep parts of the code due to the well-known path explosion problem and constraint solving limitations.In this paper, we propose chopped symbolic execution, a novel form of symbolic execution that allows users to specify uninteresting parts of the code to exclude during the analysis, thus only targeting the exploration to paths of importance. However, the excluded parts are not summarily ignored, as this may lead to both false positives and false negatives. Instead, they are executed lazily, when their effect may be observable by code under analysis. Chopped symbolic execution leverages various on-demand static analyses at runtime to automatically exclude code fragments while resolving their side effects, thus avoiding expensive manual annotations and imprecision.Our preliminary results show that the approach can effectively improve the effectiveness of symbolic execution in several different scenarios, including failure reproduction and test suite augmentation.},
  address = {New York, NY, USA},
  author = {David Trabish and Andrea Mattavelli and Noam Rinetzky and Cristian Cadar},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  doi = {10.1145/3180155.3180251},
  isbn = {9781450356381},
  keywords = {symbolic execution, static analysis, program slicing},
  link = {https://doi.org/10.1145/3180155.3180251},
  location = {Gothenburg, Sweden},
  numpages = {11},
  pages = {350-360},
  publisher = {Association for Computing Machinery},
  series = {ICSE '18},
  title = {{Chopped symbolic execution}},
  url = {https://doi.org/10.1145/3180155.3180251},
  year = {2018}
}

@inproceedings{trabish:issta:2020,
  abstract = {Symbolic execution (SE) is a widely used program analysis technique. Existing SE engines model the memory space by associating memory objects with concrete addresses, where the representation of each allocated object is determined during its allocation. We present a novel addressing model where the underlying representation of an allocated object can be dynamically modified even after its allocation, by using symbolic addresses rather than concrete ones. We demonstrate the benefits of our model in two application scenarios: dynamic inter- and intra-object partitioning. In the former, we show how the recently proposed segmented memory model can be improved by dynamically merging several object representations into a single one, rather than doing that a-priori using static pointer analysis. In the latter, we show how the cost of solving array theory constraints can be reduced by splitting the representations of large objects into multiple smaller ones. Our preliminary results show that our approach can significantly improve the overall effectiveness of the symbolic exploration.},
  address = {New York, NY, USA},
  author = {David Trabish and Noam Rinetzky},
  booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  doi = {10.1145/3395363.3397363},
  isbn = {9781450380089},
  keywords = {Symbolic execution, Memory partitioning, Addressing model},
  link = {https://doi.org/10.1145/3395363.3397363},
  location = {Virtual Event, USA},
  numpages = {12},
  pages = {51-62},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2020},
  title = {{Relocatable addressing model for symbolic execution}},
  url = {https://doi.org/10.1145/3395363.3397363},
  year = {2020}
}

@article{tremblay:micro:1996,
  acmid = {624021},
  address = {Los Alamitos, CA, USA},
  author = {Marc Tremblay and J. Michael O'Connor and Venkatesh Narayanan and Liang He},
  doi = {10.1109/40.526921},
  issn = {0272-1732},
  issue_date = {August 1996},
  journal = {IEEE Micro},
  month = {August},
  number = {4},
  numpages = {11},
  pages = {10-20},
  publisher = {IEEE Computer Society Press},
  title = {{VIS speeds new media processing}},
  volume = {16},
  year = {1996}
}

@inproceedings{trtik:atva:2014,
  abstract = {We introduce a segment-offset-plane memory model for symbolic execution that supports symbolic pointers, allocations of memory blocks of symbolic sizes, and multi-writes. We further describe our efficient implementation of the model in a free open-source project Bugst. Experimental results provide empirical evidence that the implemented memory model effectively tackles the variable storage-referencing problem of symbolic execution.},
  address = {Cham},
  author = {Marek Trtík and Jan Strejček},
  booktitle = {Automated Technology for Verification and Analysis},
  editor = {Cassez, Franck and Raskin, Jean-Fran{ç}ois},
  isbn = {978-3-319-11936-6},
  pages = {380-395},
  publisher = {Springer International Publishing},
  title = {{Symbolic memory with pointers}},
  year = {2014}
}

@inproceedings{tschantz:fm:2009,
  abstract = {Privacy means something different to everyone. Against a vast and rich canvas of diverse types of privacy rights and violations, we argue technology's dual role in privacy: new technologies raise new threats to privacy rights and new technologies can help preserve privacy. Formal methods, as just one class of technology, can be applied to privacy, but privacy raises new challenges, and thus new research opportunities, for the formal methods community.},
  address = {Berlin, Heidelberg},
  author = {Michael Carl Tschantz and Jeannette M. Wing},
  booktitle = {FM 2009: Formal Methods},
  editor = {Cavalcanti, Ana and Dams, Dennis R.},
  isbn = {978-3-642-05089-3},
  pages = {1-15},
  publisher = {Springer Berlin Heidelberg},
  title = {{Formal methods for privacy}},
  year = {2009}
}

@article{tuerk:vstte:2010,
  author = {Thomas Tuerk},
  journal = {VSTTE},
  pages = {29},
  title = {{Local reasoning about while-loops}},
  volume = {2010},
  year = {2010}
}

@mastersthesis{ullrich:msc:2016,
  author = {Sebastian Ullrich},
  school = {Karlsruhe Institut of Technology},
  title = {{Simple verification of Rust programs via functional purification}},
  year = {2016}
}

@inproceedings{vanegue:sandp:2013,
  abstract = {This paper describes our experience of performing reactive security audit of known security vulnerabilities in core operating system and browser COM components, using an extended static checker HAVOCLITE. We describe the extensions made to the tool to be applicable on such large C++ components, along with our experience of using an extended static checker in the large. We argue that the use of such checkers as a configurable static analysis in the hands of security auditors can be an effective tool for finding variations of known vulnerabilities. The effort has led to finding and fixing around 70 previously unknown security vulnerabilities in over 10 millions lines operating system and browser code.},
  author = {Julien Vanegue and Shuvendu K. Lahiri},
  booktitle = {2013 IEEE Symposium on Security and Privacy},
  doi = {10.1109/SP.2013.12},
  issn = {1081-6011},
  keywords = {C++ language;formal verification;operating systems (computers);program compilers;security of data;practical reactive security audit;extended static checkers;security vulnerabilities;core operating system;browser COM components;extended static checker HAVOCLITE;C++ components;configurable static analysis;security auditors;browser code;Security;Instruments;Object oriented modeling;Browsers;Manuals;Contracts;Semantics;security audit;program verification;static analysis;extended static checking},
  month = {May},
  number = {},
  pages = {33-47},
  title = {{Towards practical reactive security audit using extended static checkers}},
  volume = {},
  year = {2013}
}

@inproceedings{vantonder:icse:2018,
  abstract = {Static analysis tools have demonstrated effectiveness at finding bugs in real world code. Such tools are increasingly widely adopted to improve software quality in practice. Automated Program Repair (APR) has the potential to further cut down on the cost of improving software quality. However, there is a disconnect between these effective bug-finding tools and APR. Recent advances in APR rely on test cases, making them inapplicable to newly discovered bugs or bugs difficult to test for deterministically (like memory leaks). Additionally, the quality of patches generated to satisfy a test suite is a key challenge. We address these challenges by adapting advances in practical static analysis and verification techniques to enable a new technique that finds and then accurately fixes real bugs without test cases. We present a new automated program repair technique using Separation Logic. At a high-level, our technique reasons over semantic effects of existing program fragments to fix faults related to general pointer safety properties: resource leaks, memory leaks, and null dereferences. The procedure automatically translates identified fragments into source-level patches, and verifies patch correctness with respect to reported faults. In this work we conduct the largest study of automatically fixing undiscovered bugs in real-world code to date. We demonstrate our approach by correctly fixing 55 bugs, including 11 previously undiscovered bugs, in 11 real-world projects.},
  address = {New York, NY, USA},
  author = {Rijnard van Tonder and Claire Le Goues},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  doi = {10.1145/3180155.3180250},
  isbn = {9781450356381},
  keywords = {separation logic, automated program repair},
  link = {https://doi.org/10.1145/3180155.3180250},
  location = {Gothenburg, Sweden},
  numpages = {12},
  pages = {151-162},
  publisher = {Association for Computing Machinery},
  series = {ICSE '18},
  title = {{Static automated program repair for heap properties}},
  url = {https://doi.org/10.1145/3180155.3180250},
  year = {2018}
}

@inproceedings{vasudevan:secpriv:2013,
  author = {Amit Vasudevan and Sagar Chaki and Limin Jia and Jonathan McCune and James Newsome and Anupam Datta},
  booktitle = {2013 IEEE Symposium on Security and Privacy},
  organization = {IEEE},
  pages = {430-444},
  title = {{Design, implementation and verification of an extensible and modular hypervisor framework}},
  year = {2013}
}

@inproceedings{vasudevan:usenix:2016,
  address = {Austin, TX},
  author = {Amit Vasudevan and Sagar Chaki and Petros Maniatis and Limin Jia and Anupam Datta},
  booktitle = {25th USENIX Security Symposium (USENIX Security 16)},
  isbn = {978-1-931971-32-4},
  month = {August},
  pages = {87-104},
  publisher = {USENIX Association},
  title = {{überSpark: Enforcing verifiable object abstractions for automated compositional security analysis of a hypervisor}},
  url = {https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/vasudevan},
  year = {2016}
}

@inproceedings{vega:pldi:2021,
  abstract = {Modern field-programmable gate arrays (FPGAs) have recently powered high-profile efficiency gains in systems from datacenters to embedded devices by offering ensembles of heterogeneous, reconfigurable hardware units. Programming stacks for FPGAs, however, are stuck in the past-they are based on traditional hardware languages, which were appropriate when FPGAs were simple, homogeneous fabrics of basic programmable primitives. We describe Reticle, a new low-level abstraction for FPGA programming that, unlike existing languages, explicitly represents the special-purpose units available on a particular FPGA device. Reticle has two levels: a portable intermediate language and a target-specific assembly language. We show how to use a standard instruction selection approach to lower intermediate programs to assembly programs, which can be both faster and more effective than the complex metaheuristics that existing FPGA toolchains use. We use Reticle to implement linear algebra operators and coroutines and find that Reticle compilation runs up to 100 times faster than current approaches while producing comparable or better run-time and utilization.},
  address = {New York, NY, USA},
  author = {Luis Vega and Joseph McMahan and Adrian Sampson and Dan Grossman and Luis Ceze},
  booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3453483.3454075},
  isbn = {9781450383912},
  keywords = {FPGAs, compilers},
  link = {https://doi.org/10.1145/3453483.3454075},
  location = {Virtual, Canada},
  numpages = {16},
  pages = {756-771},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2021},
  title = {{Reticle: A virtual machine for programming modern FPGAs}},
  url = {https://doi.org/10.1145/3453483.3454075},
  year = {2021}
}

@inproceedings{veldhuizen:oo:1998,
  author = {Todd L. Veldhuizen and Dennis Gannon},
  booktitle = {Proceedings of the SIAM Workshop on Object Oriented Methods for Inter-operable Scientific and Engineering Computing (OO'98},
  link = {http://arxiv.org/abs/math.NA/9810022},
  publisher = {SIAM Press},
  title = {{Active libraries: Rethinking the roles of compilers and libraries}},
  url = {http://arxiv.org/abs/math.NA/9810022},
  year = {1998}
}

@inproceedings{velev:dac:2000,
  acmid = {337331},
  address = {New York, NY, USA},
  author = {Miroslav N. Velev and Randal E. Bryant},
  booktitle = {Proceedings of the 37th Annual Design Automation Conference},
  doi = {10.1145/337292.337331},
  isbn = {1-58113-187-9},
  location = {Los Angeles, California, USA},
  numpages = {6},
  pages = {112-117},
  publisher = {ACM},
  series = {DAC '00},
  title = {{Formal verification of superscalar microprocessors with multicycle functional units, exception, and branch prediction}},
  year = {2000}
}

@inproceedings{verbeek:fmmsd:2019,
  author = {Freek Verbeek and Joshua Bockenek and Abhijith Bharadwaj and Ian Roessle and Binoy Ravindran},
  booktitle = {Proceedings of the 17th ACM-IEEE International Conference on Formal Methods and Models for System Design},
  doi = {10.1145/3359986.3361215},
  organization = {ACM},
  pages = {17},
  title = {{Establishing a refinement relation between binaries and abstract code}},
  year = {2019}
}

@inproceedings{vila:pldi:2020,
  abstract = {We show how to infer deterministic cache replacement policies using off-the-shelf automata learning and program synthesis techniques. For this, we construct and chain two abstractions that expose the cache replacement policy of any set in the cache hierarchy as a membership oracle to the learning algorithm, based on timing measurements on a silicon CPU. Our experiments demonstrate an advantage in scope and scalability over prior art and uncover two previously undocumented cache replacement policies.},
  address = {New York, NY, USA},
  author = {Pepe Vila and Pierre Ganty and Marco Guarnieri and Boris Köpf},
  booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/3385412.3386008},
  isbn = {9781450376136},
  keywords = {Program Synthesis, Automata Learning, Reverse Engineering, Cache Replacement Policies},
  link = {https://doi.org/10.1145/3385412.3386008},
  location = {London, UK},
  numpages = {14},
  pages = {519-532},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2020},
  title = {{CacheQuery: Learning replacement policies from hardware caches}},
  url = {https://doi.org/10.1145/3385412.3386008},
  year = {2020}
}

@inproceedings{visser:tacas:2020,
  abstract = {COASTAL is a program analysis tool for Java programs. It combines concolic execution and fuzz testing in a framework with built-in concurrency, allowing the two approaches to cooperate naturally.},
  address = {Cham},
  author = {Willem Visser and Jaco Geldenhuys},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  doi = {10.1007/978-3-030-45237-7_23},
  editor = {Biere, Armin and Parker, David},
  isbn = {978-3-030-45237-7},
  pages = {373-377},
  publisher = {Springer International Publishing},
  title = {{COASTAL: Combining concolic and fuzzing for Java (competition contribution)}},
  year = {2020}
}

@inproceedings{vogels:fmoods:2011,
  abstract = {With the years, program complexity has increased dramatically: ensuring program correctness has become considerably more difficult with the advent of multithreading, security has grown more prominent during the last decade, etc. As a result, static verification has become more important than ever.},
  address = {Berlin, Heidelberg},
  author = {Frédéric Vogels and Bart Jacobs and Frank Piessens and Jan Smans},
  booktitle = {Formal Techniques for Distributed Systems},
  editor = {Bruni, Roberto and Dingel, Juergen},
  isbn = {978-3-642-21461-5},
  pages = {319-333},
  publisher = {Springer Berlin Heidelberg},
  title = {{Annotation inference for separation logic based verifiers}},
  year = {2011}
}

@inproceedings{vonbehren:hotos:2003,
  acmid = {1251058},
  address = {Berkeley, CA, USA},
  author = {Robert von Behren and Jeremy Condit and Eric Brewer},
  booktitle = {Proceedings of the 9th Conference on Hot Topics in Operating Systems - Volume 9},
  location = {Lihue, Hawaii},
  numpages = {1},
  pages = {4},
  publisher = {USENIX Association},
  series = {HOTOS'03},
  title = {{Why events are a bad idea (for high-concurrency servers)}},
  year = {2003}
}

@inproceedings{votipka:sp:2018,
  author = {Daniel Votipka and Rock Stevens and Elissa M. Redmiles and Jeremy Hu and Michelle L. Mazurek},
  booktitle = {2018 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP.2018.00003},
  issn = {2375-1207},
  keywords = {computer crime;program testing;security of data;software vulnerability discovery processes;software testers;white-hat hackers;bug bounty programs;smarter bug bounty policies;hacker participation;security training;Computer hacking;Computer bugs;Software;Interviews;Tools;Sociology;interview study;software vulnerabilities;vulnerability discovery;software testing;usable security;security workers},
  month = {May},
  number = {},
  pages = {374-391},
  title = {{Hackers vs. testers: A comparison of software vulnerability discovery processes}},
  volume = {},
  year = {2018}
}

@inproceedings{wagner:hotos:2013,
  author = {Jonas Wagner and Volodymyr Kuznetsov and George Candea},
  booktitle = {14th Workshop on Hot Topics in Operating Systems},
  title = {{-Overify: Optimizing programs for fast verification}},
  year = {2013}
}

@inproceedings{walker:popl:2000,
  address = {New York, NY, USA},
  author = {David Walker},
  booktitle = {Proceedings of the 27th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/325694.325728},
  isbn = {1581131259},
  location = {Boston, MA, USA},
  numpages = {14},
  pages = {254–267},
  publisher = {Association for Computing Machinery},
  series = {POPL'00},
  title = {{A type system for expressive security policies}},
  url = {https://doi.org/10.1145/325694.325728},
  year = {2000}
}

@inproceedings{walker:tic:2001,
  abstract = {Linear type systems permit programmers to deallocate or explicitly recycle memory, but are severely restricted by the fact that they admit no aliasing. This paper describes a pseudo-linear type system that allows a degree of aliasing and memory reuse as well as the ability to define complex recursive data structures. Our type system can encode conventional linear data structures such as linear lists and trees as well as more sophisticated data structures including cyclic and doubly-linked lists and trees. In the latter cases, our type system is expressive enough to represent pointer aliasing and yet safely permit destructive operations such as object deallocation.We demonstrate the flexibility of our type system by encoding two common space-conscious algorithms: destination-passing style and Deutsch-Schorr-Waite or \textasciigrave \textasciigrave link-reversal\textquotesingle \textquotesingle  traversal algorithms.},
  address = {Berlin, Heidelberg},
  author = {David Walker and Greg Morrisett},
  booktitle = {Types in Compilation},
  doi = {10.1007/3-540-45332-6_7},
  editor = {Harper, Robert},
  isbn = {978-3-540-45332-1},
  pages = {177-206},
  publisher = {Springer Berlin Heidelberg},
  title = {{Alias types for recursive data structures}},
  year = {2001}
}

@inproceedings{wand:lfp:1980,
  acmid = {802786},
  address = {New York, NY, USA},
  author = {Mitchell Wand},
  booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
  doi = {10.1145/800087.802786},
  location = {Stanford University, California, USA},
  numpages = {10},
  pages = {19-28},
  publisher = {ACM},
  series = {LFP '80},
  title = {{Continuation-based multiprocessing}},
  year = {1980}
}

@inproceedings{wand:lics:1987,
  author = {Mitchell Wand},
  booktitle = {Proceedings of the Second Annual IEEE Symposium on Logic in Computer Science (LICS 1987)},
  location = {Ithaca, NY, USA},
  month = {June},
  pages = {37-44},
  publisher = {IEEE Computer Society Press},
  title = {{Complete type inference for simple objects}},
  year = {1987}
}

@inproceedings{wang:pldi:2007,
  address = {New York, NY, USA},
  author = {Perry H. Wang and Jamison D. Collins and Gautham N. Chinya and Hong Jiang and Xinmin Tian and Milind Girkar and Nick Y. Yang and Guei-Yuan Lueh and Hong Wang},
  booktitle = {Proceedings PLDI 2007},
  doi = {10.1145/1250734.1250753},
  isbn = {978-1-59593-633-2},
  location = {San Diego, California, USA},
  pages = {156-166},
  publisher = {ACM},
  title = {{EXOCHI: architecture and programming environment for a heterogeneous multi-core multithreaded system}},
  year = {2007}
}

@inproceedings{wang:sosp:2013,
  abstract = {This paper studies an emerging class of software bugs called optimization-unstable code: code that is unexpectedly discarded by compiler optimizations due to undefined behavior in the program. Unstable code is present in many systems, including the Linux kernel and the Postgres database. The consequences of unstable code range from incorrect functionality to missing security checks.To reason about unstable code, this paper proposes a novel model, which views unstable code in terms of optimizations that leverage undefined behavior. Using this model, we introduce a new static checker called Stack that precisely identifies unstable code. Applying Stack to widely used systems has uncovered 160 new bugs that have been confirmed and fixed by developers.},
  address = {New York, NY, USA},
  author = {Xi Wang and Nickolai Zeldovich and M. Frans Kaashoek and Armando Solar-Lezama},
  booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
  doi = {10.1145/2517349.2522728},
  isbn = {9781450323888},
  link = {https://doi.org/10.1145/2517349.2522728},
  location = {Farminton, Pennsylvania},
  numpages = {16},
  pages = {260-275},
  publisher = {Association for Computing Machinery},
  series = {SOSP '13},
  title = {{Towards optimization-safe systems: Analyzing the impact of undefined behavior}},
  url = {https://doi.org/10.1145/2517349.2522728},
  year = {2013}
}

@inproceedings{wang:tase:2018,
  author = {Feng Wang and Fu Song and Min Zhang and Xiaoran Zhu and Jun Zhang},
  booktitle = {2018 International Symposium on Theoretical Aspects of Software Engineering (TASE)},
  doi = {10.1109/TASE.2018.00014},
  issn = {null},
  keywords = {multi-threading;program compilers;program interpreters;program testing;program verification;programming language semantics;rewriting systems;specification languages;storage management;ownership system;garbage collection;formal analysis;Rust programs;formal semantics;formal executable operational semantics;rewriting-based executable semantic framework;verification tools;KRust;Rust compiler;formal executable semantics;high-level system programming language;memory safety;thread safety;Rust test suite;formal interpreter;Formal operational semantics;Rust programming language;K framework},
  month = {Aug},
  number = {},
  pages = {44-51},
  title = {{KRust: A formal executable semantics of Rust}},
  volume = {},
  year = {2018}
}

@misc{weigl:arxiv:2019,
  archiveprefix = {arXiv},
  author = {Alexander Weigl and Mattias Ulbrich and Suhyun Cha and Bernhard Beckert and Birgit Vogel-Heuser},
  eprint = {1910.09068},
  primaryclass = {cs.LO},
  title = {{Relational test tables: A practical specification language for evolution and security}},
  year = {2019}
}

@article{weiss:arxiv:2018,
  archiveprefix = {arXiv},
  author = {Aaron Weiss and Daniel Patterson and Amal Ahmed},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-1806-02693.bib},
  eprint = {1806.02693},
  journal = {CoRR},
  timestamp = {Mon, 13 Aug 2018 16:47:54 +0200},
  title = {{Rust distilled: An expressive tower of languages}},
  url = {http://arxiv.org/abs/1806.02693},
  volume = {abs/1806.02693},
  year = {2018}
}

@inproceedings{weitz:icfp:2017,
  address = {Oxford, UK},
  author = {Konstantin Weitz and Steven Lyubomirsky and Stefan Heule and Emina Torlak and Michael D. Ernst and Zachary Tatlock},
  booktitle = {ICFP 2017: Proceedings of the 22nd ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/3110269},
  month = {September},
  pages = {25:1-25:28},
  title = {{SpaceSearch: A library for building and verifying solver-aided tools}},
  year = {2017}
}

@inproceedings{wickerson:popl:2017,
  acmid = {3009838},
  address = {New York, NY, USA},
  author = {John Wickerson and Mark Batty and Tyler Sorensen and George A. Constantinides},
  booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages},
  doi = {10.1145/3009837.3009838},
  isbn = {978-1-4503-4660-3},
  keywords = {C/C++, OpenCL, constraint solving, graphics processor (GPU), model checking, program synthesis, shared memory concurrency, weak memory models},
  location = {Paris, France},
  numpages = {15},
  pages = {190-204},
  publisher = {ACM},
  series = {POPL 2017},
  title = {{Automatically comparing memory consistency models}},
  year = {2017}
}

@article{windley:ieeetoc:1995,
  author = {Phillip J. Windley},
  doi = {10.1109/12.368009},
  journal = {Computers, IEEE Transactions on},
  number = {1},
  pages = {54-72},
  publisher = {IEEE},
  title = {{Formal modeling and verification of microprocessors}},
  volume = {44},
  year = {1995}
}

@inproceedings{woh:micro:2008,
  abstract = {With the multitude of existing and upcoming wireless standards, it is becoming increasingly difficult for hardware-only baseband processing solutions to adapt to the rapidly changing wireless communication landscape. Software Defined Radio (SDR) promises to deliver a cost effective and flexible solution by implementing a wide variety of wireless protocols in software. In previous work, a fully programmable multicore architecture, SODA, was proposed that was able to meet the real-time requirements of 3G wireless protocols. SODA consists of one ARM control processor and four wide single instruction multiple data (SIMD) processing elements. Each processing element consists of a scalar and a wide 512-bit 32-lane SIMD datapath. A commercial prototype based on the SODA architecture, Ardbeg (named after a brand of Scotch Whisky), has been developed. In this paper, we present the architectural evolution of going from a research design to a commercial prototype, including the goals, trade-offs, and final design choices.  Ardbeg's redesign process can be grouped into the following three major areas: optimizing the wide SIMD datapath, providing long instruction word (LIW) support for SIMD operations, and adding application-specific hardware accelerators. Because SODA was originally designed with 180nm technology, the wide SIMD datapath is re-optimized in Ardbeg for 90nm technology. This includes re-evaluating the most efficient SIMD width, designing a wider SIMD shuffle network, and implementing faster SIMD arithmetic units. Ardbeg also provides modest LIW support by allowing two SIMD operations to issue in the same cycle. This LIW execution supports SDR algorithms' most common parallel SIMD execution patterns with minimal hardware overhead. A viable commercial SDR solution must be competitive with existing ASIC solutions. Therefore, algorithm-specific hardware is added for performance bottleneck algorithms while still maintaining enough flexibility to support multiple wireless protocols. The combination of these architectural improvements allows Ardbeg to achieve 1.5-7x speedup over SODA across multiple wireless algorithms while consuming less power.},
  acceptance = {19},
  affiliation = {ARM Ltd and University of Michigan and Arizona State University},
  ar_shortname = {MICRO 08},
  author = {Mark Woh and Yuan Lin and Sangwon Seo and Scott A. Mahlke and Trevor N. Mudge and Chaitali Chakrabarti and Richard Bruce and Danny Kershaw and Alastair D. Reid and Mladen Wilder and Krisztián Flautner},
  booktitle = {41st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-41 2008)},
  day = {8-12},
  doi = {10.1109/MICRO.2008.4771787},
  location = {Lake Como, Italy},
  month = {November},
  pages = {152-163},
  publisher = {IEEE Computer Society},
  title = {{From SODA to scotch: The evolution of a wireless baseband processor}},
  year = {2008}
}

@inproceedings{wolf:codes:2004,
  address = {Los Alamitos, CA, USA},
  author = {Pieter van der Wolf and Erwin A. de Kock and Tomas Henriksson and Wido Kruijtzer and Gerben Essink},
  booktitle = {Hardware/software codesign and system synthesis, International conference on},
  doi = {10.1109/CODES+ISSS.2004.17},
  issn = {},
  keywords = {design;performance;standardization;system design method;media processing;task-level interface;platform interface;multiprocessor mapping;code transformation},
  link = {https://doi.ieeecomputersociety.org/10.1109/CODES+ISSS.2004.17},
  month = {sep},
  pages = {206-217},
  publisher = {IEEE Computer Society},
  title = {{Design and programming of embedded multiprocessors: An interface-centric approach}},
  url = {https://doi.ieeecomputersociety.org/10.1109/CODES+ISSS.2004.17},
  volume = {},
  year = {2004}
}

@misc{wolff:draft:2021,
  author = {Fabian Wolff and Aurel Bílý and Christoph Matheja and Peter Müller and Alexander J. Summers},
  title = {{Modular specification and verification of closures in Rust (draft paper)}},
  url = {https://www.cs.ubc.ca/~alexsumm/papers/WolffBilyMathejaMuellerSummers21.pdf},
  year = {2021}
}

@inproceedings{woodruff:isca:2014,
  author = {Jonathan Woodruff and Robert N. M. Watson and David Chisnall and Simon W. Moore and Jonathan Anderson and Brooks Davis and Ben Laurie and Peter G. Neumann and Robert M. Norton and Michael Roe},
  booktitle = {2014 ACM/IEEE 41st International Symposium on Computer Architecture (ISCA)},
  doi = {10.1109/ISCA.2014.6853201},
  number = {},
  pages = {457-468},
  title = {{The CHERI capability model: Revisiting RISC in an age of risk}},
  volume = {},
  year = {2014}
}

@article{woodruff:tocs:2019,
  abstract = {We present CHERI Concentrate, a new fat-pointer compression scheme applied to CHERI, the most developed capability-pointer system at present. Capability fat pointers are a primary candidate to enforce fine-grained and non-bypassable security properties in future computer systems, although increased pointer size can severely affect performance. Thus, several proposals for capability compression have been suggested elsewhere that do not support legacy instruction sets, ignore features critical to the existing software base, and also introduce design inefficiencies to RISC-style processor pipelines. CHERI Concentrate improves on the state-of-the-art region-encoding efficiency, solves important pipeline problems, and eases semantic restrictions of compressed encoding, allowing it to protect a full legacy software stack. We present the first quantitative analysis of compiled capability code, which we use to guide the design of the encoding format. We analyze and extend logic from the open-source CHERI prototype processor design on FPGA to demonstrate encoding efficiency, minimize delay of pointer arithmetic, and eliminate additional load-to-use delay. To verify correctness of our proposed high-performance logic, we present a HOL4 machine-checked proof of the decode and pointer-modify operations. Finally, we measure a 50 to 75 percent reduction in L2 misses for many compiled C-language benchmarks running under a commodity operating system using compressed 128-bit and 64-bit formats, demonstrating both compatibility with and increased performance over the uncompressed, 256-bit format.},
  author = {Jonathan Woodruff and Alexandre Joannou and Hongyan Xia and Anthony Fox and Robert M. Norton and David Chisnall and Brooks Davis and Khilan Gudka and Nathaniel W. Filardo and A. Theodore Markettos and Michael Roe and Peter G. Neumann and Robert N. M. Watson and Simon W. Moore},
  doi = {10.1109/TC.2019.2914037},
  issn = {1557-9956},
  journal = {IEEE Transactions on Computers},
  keywords = {},
  month = {Oct},
  number = {10},
  pages = {1455-1469},
  title = {{CHERI concentrate: Practical compressed capabilities}},
  volume = {68},
  year = {2019}
}

@inproceedings{wright:icsm:2013,
  author = {Hyrum K. Wright and Daniel Jasper and Manuel Klimek and Chandler Carruth and Zhanyong Wan},
  booktitle = {2013 IEEE International Conference on Software Maintenance},
  doi = {10.1109/ICSM.2013.93},
  issn = {1063-6773},
  keywords = {application program interfaces;C++ language;parallel programming;program compilers;software maintenance;large-scale automated refactoring;ClangMR;large C++ codebases;Clang compiler framework;MapReduce parallel processor;API update;Google;Google;Indexes;Standards;Semantics;Conferences;Transforms;Software systems},
  month = {Sep.},
  number = {},
  pages = {548-551},
  title = {{Large-scale automated refactoring using ClangMR}},
  volume = {},
  year = {2013}
}

@misc{wu:arxiv:2017,
  archiveprefix = {arXiv},
  author = {Lingfei Wu and Dashun Wang and James A. Evans},
  eprint = {1709.02445},
  primaryclass = {physics.soc-ph},
  title = {{Large teams have developed science and technology; small teams have disrupted it}},
  year = {2017}
}

@inproceedings{xi:icfp:2001,
  address = {New York, NY, USA},
  author = {Hongwei Xi and Robert Harper},
  booktitle = {Proceedings of the Sixth ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/507635.507657},
  isbn = {1581134150},
  location = {Florence, Italy},
  numpages = {12},
  pages = {169–180},
  publisher = {Association for Computing Machinery},
  series = {ICFP'01},
  title = {{A dependently typed assembly language}},
  url = {https://doi.org/10.1145/507635.507657},
  year = {2001}
}

@inproceedings{xie:bugs:2005,
  author = {Yichen Xie and Mayur Naik and Brian Hackett and Alex Aiken},
  booktitle = {Proceedings of BUGS 2005 (PLDI 2005 Workshop on the Evaluation of Software Defect Detection Tools)},
  location = {Chicago, IL, USA},
  month = {June},
  title = {{Soundness and its role in bug detection systems}},
  url = {http://www.cs.umd.edu/~pugh/SoftwareDefectWorkshop05/BugWorkshop05.pdf},
  year = {2005}
}

@inproceedings{xie:popl:2005,
  abstract = {We describe a software error-detection tool that exploits recent advances in boolean satisfiability (SAT) solvers. Our analysis is path sensitive, precise down to the bit level, and models pointers and heap data. Our approach is also highly scalable, which we achieve using two techniques. First, for each program function, several optimizations compress the size of the boolean formulas that model the control- and data-flow and the heap locations accessed by a function. Second, summaries in the spirit of type signatures are computed for each function, allowing inter-procedural analysis without a dramatic increase in the size of the boolean constraints to be solved.We demonstrate the effectiveness of our approach by constructing a lock interface inference and checking tool. In an interprocedural analysis of more than 23,000 lock related functions in the latest Linux kernel, the checker generated 300 warnings, of which 179 were unique locking errors, a false positive rate of only 40\%.},
  address = {New York, NY, USA},
  author = {Yichen Xie and Alex Aiken},
  booktitle = {Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/1040305.1040334},
  isbn = {158113830X},
  keywords = {boolean satisfiability, program analysis, error detection},
  link = {https://doi.org/10.1145/1040305.1040334},
  location = {Long Beach, California, USA},
  numpages = {13},
  pages = {351-363},
  publisher = {Association for Computing Machinery},
  series = {POPL '05},
  title = {{Scalable error detection using boolean satisfiability}},
  url = {https://doi.org/10.1145/1040305.1040334},
  year = {2005}
}

@misc{xu:arxiv:2021,
  archiveprefix = {arXiv},
  author = {Hui Xu and Zhuangbin Chen and Mingshen Sun and Yangfan Zhou and Michael Lyu},
  eprint = {2003.03296},
  primaryclass = {cs.PL},
  title = {{Memory-safety challenge considered solved? An in-depth study with all Rust CVEs}},
  year = {2021}
}

@inproceedings{yang:issta:2012,
  abstract = {This paper introduces memoized symbolic execution (Memoise), a new approach for more efficient application of forward symbolic execution, which is a well-studied technique for systematic exploration of program behaviors based on bounded execution paths. Our key insight is that application of symbolic execution often requires several successive runs of the technique on largely similar underlying problems, e.g., running it once to check a program to find a bug, fixing the bug, and running it again to check the modified program. Memoise introduces a trie-based data structure that stores the key elements of a run of symbolic execution. Maintenance of the trie during successive runs allows re-use of previously computed results of symbolic execution without the need for re-computing them as is traditionally done. Experiments using our prototype implementation of Memoise show the benefits it holds in various standard scenarios of using symbolic execution, e.g., with iterative deepening of exploration depth, to perform regression analysis, or to enhance coverage using heuristics.},
  address = {New York, NY, USA},
  author = {Guowei Yang and Corina S. Păsăreanu and Sarfraz Khurshid},
  booktitle = {Proceedings of the 2012 International Symposium on Software Testing and Analysis},
  doi = {10.1145/2338965.2336771},
  isbn = {9781450314541},
  link = {https://doi.org/10.1145/2338965.2336771},
  location = {Minneapolis, MN, USA},
  numpages = {11},
  pages = {144-154},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2012},
  title = {{Memoized symbolic execution}},
  url = {https://doi.org/10.1145/2338965.2336771},
  year = {2012}
}

@inproceedings{yang:pldi:2010,
  author = {Jean Yang and Chris Hawblitzel},
  booktitle = {PLDI},
  doi = {10.1145/1809028.1806610},
  pages = {99-110},
  publisher = {ACM},
  title = {{Safe to the last instruction: automated verification of a type-safe operating system}},
  year = {2010}
}

@inproceedings{yang:pldi:2011,
  abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to find compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our first contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undefined and unspecified behaviors that would destroy its ability to automatically find wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
  address = {New York, NY, USA},
  author = {Xuejun Yang and Yang Chen and Eric Eide and John Regehr},
  booktitle = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/1993498.1993532},
  isbn = {9781450306638},
  keywords = {compiler defect, random program generation, automated testing, compiler testing, random testing},
  link = {https://doi.org/10.1145/1993498.1993532},
  location = {San Jose, California, USA},
  numpages = {12},
  pages = {283-294},
  publisher = {Association for Computing Machinery},
  series = {PLDI '11},
  title = {{Finding and understanding bugs in C compilers}},
  url = {https://doi.org/10.1145/1993498.1993532},
  year = {2011}
}

@article{yanovski:unknown:2021,
  author = {Joshua Yanovski and Hoang-Hai Dang and Ralf Jung and Derek Dreyer},
  link = {https://plv.mpi-sws.org/rustbelt/ghostcell/paper.pdf},
  month = {March},
  title = {{GhostCell: Separating permissions from data in Rust}},
  year = {2021}
}

@inproceedings{yun:usenix:2018,
  address = {Baltimore, MD},
  author = {Insu Yun and Sangho Lee and Meng Xu and Yeongjin Jang and Taesoo Kim},
  booktitle = {Proceedings of the 27th USENIX Security Symposium (Security)},
  month = {August},
  title = {{QSYM: A practical concolic execution engine tailored for hybrid fuzzing}},
  year = {2018}
}

@inproceedings{zaostrovnykh:sosp:2019,
  abstract = {We present the design and implementation of Vigor, a software stack and toolchain for building and running software network middleboxes that are guaranteed to be correct, while preserving competitive performance and developer productivity. Developers write the core of the middlebox--the network function (NF)--in C, on top of a standard packet-processing framework, putting persistent state in data structures from Vigor's library; the Vigor toolchain then automatically verifies that the resulting software stack correctly implements a specification, which is written in Python.Vigor has three key features: network function developers need no verification expertise, and the verification process does not require their assistance (push-button verification); the entire software stack is verified, down to the hardware (full-stack verification); and verification can be done in a pay-as-you-go manner, i.e., instead of investing upfront a lot of time in writing and verifying a complete specification, one can specify one-off properties in a few lines of Python and verify them without concern for the rest.We developed five representative NFs--a NAT, a Maglev load balancer, a MAC-learning bridge, a firewall, and a traffic policer--and verified with Vigor that they satisfy standards-derived specifications, are memory-safe, and do not crash or hang. We show that they provide competitive performance.The Vigor framework is available at http://vigor.epfl.ch.},
  address = {New York, NY, USA},
  author = {Arseniy Zaostrovnykh and Solal Pirelli and Rishabh Iyer and Matteo Rizzo and Luis Pedrosa and Katerina Argyraki and George Candea},
  booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
  doi = {10.1145/3341301.3359647},
  isbn = {9781450368735},
  link = {https://doi.org/10.1145/3341301.3359647},
  location = {Huntsville, Ontario, Canada},
  numpages = {16},
  pages = {275-290},
  publisher = {Association for Computing Machinery},
  series = {SOSP '19},
  title = {{Verifying software network functions with no verification expertise}},
  url = {https://doi.org/10.1145/3341301.3359647},
  year = {2019}
}

@inproceedings{zdancewic:csfw:2001,
  author = {Steve Zdancewic and Andrew C. Myers},
  booktitle = {Proceedings 14th IEEE Computer Security Foundations Workshop},
  doi = {10.1109/CSFW.2001.930133},
  issn = {1063-6900},
  keywords = {Robustness;Algorithms;Government;Computer science;Computer security;Information security;Control systems;Contracts;Monitoring;Access control},
  month = {June},
  number = {},
  pages = {15-23},
  title = {{Robust declassification}},
  volume = {},
  year = {2001}
}

@inproceedings{zdancewic:csfw:2003,
  author = {Steve Zdancewic and Andrew C. Myers},
  booktitle = {16th IEEE Computer Security Foundations Workshop, 2003. Proceedings.},
  doi = {10.1109/CSFW.2003.1212703},
  organization = {IEEE},
  pages = {29-43},
  title = {{Observational determinism for concurrent program security}},
  year = {2003}
}

@inproceedings{zeldovich:osdi:2006,
  acmid = {1298481},
  address = {Berkeley, CA, USA},
  author = {Nickolai Zeldovich and Silas Boyd-Wickizer and Eddie Kohler and David Mazières},
  booktitle = {Proceedings of the 7th Symposium on Operating Systems Design and Implementation},
  isbn = {1-931971-47-1},
  location = {Seattle, Washington},
  numpages = {16},
  pages = {263-278},
  publisher = {USENIX Association},
  series = {OSDI'06},
  title = {{Making information flow explicit in HiStar}},
  year = {2006}
}

@inproceedings{zeller:bugs:2005,
  author = {Andreas Zeller},
  booktitle = {Proceedings of BUGS 2005 (PLDI 2005 Workshop on the Evaluation of Software Defect Detection Tools)},
  location = {Chicago, IL, USA},
  month = {June},
  title = {{Locating defects is uncertain}},
  url = {http://www.cs.umd.edu/~pugh/SoftwareDefectWorkshop05/BugWorkshop05.pdf},
  year = {2005}
}

@inproceedings{zhang:apsec:2018,
  author = {Chao Zhang and Weiliang Yin and Zhiqiang Lin},
  booktitle = {QuASoQ@APSEC},
  publisher = {CEUR-WS.org},
  title = {{Boost symbolic execution using dynamic state merging and forking}},
  year = {2018}
}

@article{zhang:asplos:2015,
  author = {Danfeng Zhang and Yao Wang and G. Edward Suh and Andrew C. Myers},
  doi = {10.1145/2694344.2694372},
  journal = {ACM SIGARCH Computer Architecture News},
  number = {1},
  pages = {503-516},
  publisher = {ACM},
  title = {{A hardware design language for timing-sensitive information flow security}},
  volume = {43},
  year = {2015}
}

@inproceedings{zhang:ccs:2020,
  abstract = {As a young programming language designed for systems software development, Rust aims to provide safety guarantees like high-level languages and performance efficiency like low-level languages. Lifetime is a core concept in Rust, and it is key to both safety checks and automated resource management conducted by the Rust compiler. However, Rust's lifetime rules are very complex. In reality, it is not uncommon that Rust programmers fail to infer the correct lifetime, causing severe concurrency and memory bugs. In this paper, we present VRLifeTime, an IDE tool that can visualize lifetime for Rust programs and help programmers avoid lifetime-related mistakes. Moreover, VRLifeTime can help detect some lifetime-related bugs (i.e., double locks) with detailed debugging information. A demo video is available at https://youtu.be/L5F_XCOrJTQ.},
  address = {New York, NY, USA},
  author = {Ziyi Zhang and Boqin Qin and Yilun Chen and Linhai Song and Yiying Zhang},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  doi = {10.1145/3372297.3420024},
  isbn = {9781450370899},
  keywords = {concurrency bugs, Rust},
  link = {https://doi.org/10.1145/3372297.3420024},
  location = {Virtual Event, USA},
  numpages = {3},
  pages = {2085-2087},
  publisher = {Association for Computing Machinery},
  series = {CCS '20},
  title = {{VRLifeTime - An IDE tool to avoid concurrency and memory bugs in Rust}},
  url = {https://doi.org/10.1145/3372297.3420024},
  year = {2020}
}

@inproceedings{zhang:fmcad:2018,
  author = {Hongce Zhang and Caroline Trippel and Yatin Manerkar and Aarti Gupta and Margaret Martonosi and Sharad Malik},
  booktitle = {Formal Methods in Computer-Aided Design, FMCAD},
  doi = {10.23919/FMCAD.2018.8603015},
  title = {{Integrating memory consistency models with instruction-level abstraction for heterogeneous system-on-chip verification}},
  year = {2018}
}

@inproceedings{zhang:issta:2014,
  abstract = {Scaling symbolic execution to large programs or programs with complex inputs remains difficult due to path explosion and complex constraints, as well as external method calls. Additionally, creating an effective test structure with symbolic inputs can be difficult. A popular symbolic execution strategy in practice is to perform symbolic execution not "from scratch" but based on existing test cases. This paper proposes that the effectiveness of this approach to symbolic execution can be enhanced by (1) reducing the size of seed test cases and (2) prioritizing seed test cases to maximize exploration efficiency. The proposed test case reduction strategy is based on a recently introduced generalization of delta debugging, and our prioritization techniques include novel methods that, for this purpose, can outperform some traditional regression testing algorithms. We show that applying these methods can significantly improve the effectiveness of symbolic execution based on existing test cases.},
  address = {New York, NY, USA},
  author = {Chaoqiang Zhang and Alex Groce and Mohammad Amin Alipour},
  booktitle = {Proceedings of the 2014 International Symposium on Software Testing and Analysis},
  doi = {10.1145/2610384.2610392},
  isbn = {9781450326452},
  keywords = {Test case reduction, Test prioritization, Symbolic execution},
  link = {https://doi.org/10.1145/2610384.2610392},
  location = {San Jose, CA, USA},
  numpages = {11},
  pages = {160-170},
  publisher = {Association for Computing Machinery},
  series = {ISSTA 2014},
  title = {{Using test case reduction and prioritization to improve symbolic execution}},
  url = {https://doi.org/10.1145/2610384.2610392},
  year = {2014}
}

@article{zhang:toplas:2017,
  address = {New York, NY, USA},
  articleno = {18},
  author = {Danfeng Zhang and Andrew C. Myers and Dimitrios Vytiniotis and Simon L. Peyton-Jones},
  doi = {10.1145/3121137},
  issn = {0164-0925},
  issue_date = {September 2017},
  journal = {ACM Trans. Program. Lang. Syst.},
  keywords = {information flow, type inference, static program analysis, Jif, OCaml, Error diagnosis, Haskell},
  link = {https://doi.org/10.1145/3121137},
  month = {August},
  number = {4},
  numpages = {47},
  publisher = {Association for Computing Machinery},
  title = {{SHErrLoc: A static holistic error locator}},
  url = {https://doi.org/10.1145/3121137},
  volume = {39},
  year = {2017}
}

@inproceedings{zhao:ndss:2019,
  author = {Lei Zhao and Yue Duan and Heng Yin and Jifeng Xuan},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/conf/ndss/ZhaoDYX19},
  booktitle = {26th Annual Network and Distributed System Security Symposium, NDSS 2019, San Diego, California, USA, February 24-27, 2019},
  doi = {10.14722/ndss.2019.23504},
  link = {https://www.ndss-symposium.org/ndss-paper/send-hardest-problems-my-way-probabilistic-path-prioritization-for-hybrid-fuzzing/},
  timestamp = {Thu, 02 May 2019 15:52:50 +0200},
  title = {{Send hardest problems my way: Probabilistic path prioritization for hybrid fuzzing}},
  url = {https://www.ndss-symposium.org/ndss-paper/send-hardest-problems-my-way-probabilistic-path-prioritization-for-hybrid-fuzzing/},
  year = {2019}
}

@inproceedings{zhuang:pldi:2006,
  abstract = {Calling context profiles are used in many inter-procedural code optimizations and in overall program understanding. Unfortunately, the collection of profile information is highly intrusive due to the high frequency of method calls in most applications. Previously proposed calling-context profiling mechanisms consequently suffer from either low accuracy, high overhead, or both. We have developed a new approach for building the calling context tree at runtime, called adaptive bursting. By selectively inhibiting redundant profiling, this approach dramatically reduces overhead while preserving profile accuracy. We first demonstrate the drawbacks of previously proposed calling context profiling mechanisms. We show that a low-overhead solution using sampled stack-walking alone is less than 50\% accurate, based on degree of overlap with a complete calling-context tree. We also show that a static bursting approach collects a highly accurate profile, but causes an unacceptable application slowdown. Our adaptive solution achieves 85\% degree of overlap and provides an 88\% hot-edge coverage when using a 0.1 hot-edge threshold, while dramatically reducing overhead compared to the static bursting approach.},
  address = {New York, NY, USA},
  author = {Xiaotong Zhuang and Mauricio J. Serrano and Harold W. Cain and Jong-Deok Choi},
  booktitle = {Proceedings of the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/1133981.1134012},
  isbn = {1595933204},
  keywords = {adaptive, profiling, java virtual machine, calling context, calling context tree, call graph},
  link = {https://doi.org/10.1145/1133981.1134012},
  location = {Ottawa, Ontario, Canada},
  numpages = {9},
  pages = {263-271},
  publisher = {Association for Computing Machinery},
  series = {PLDI '06},
  title = {{Accurate, efficient, and adaptive calling context profiling}},
  url = {https://doi.org/10.1145/1133981.1134012},
  year = {2006}
}

@inproceedings{zivojnovic:vlsi:1996,
  author = {Vojin Zivojnovic and Stefan Pees and Heinrich Meyr},
  booktitle = {VLSI Signal Processing, IX},
  doi = {10.1109/VLSISP.1996.558311},
  keywords = {digital signal processing chips;digital simulation;pipeline processing;specification languages;ASAP sequencer;Gantt charts;HW/SW co-design;HW/SW codesign;L-charts;LISA;TI-TMS320C54x signal processor;behavioral pipeline modeling;bit-accurate processor models;coarse ISA models;cosimulation environment;cycle/phase-accurate processor models;generic machine model;instruction set simulators;machine description language;pipeline controller;pipeline flushes;reservation tables;resource constraints;standard pipeline description;Application software;Computer architecture;Digital signal processing;Hardware;Hazards;Instruction sets;Paper technology;Pipelines;Signal processing;Software design},
  month = {October},
  pages = {127-136},
  title = {{LISA – machine description language and generic machine model for HW/SW co-design}},
  year = {1996}
}

@inproceedings{zorn:iscawddd:2017,
  author = {Bill Zorn and Dan Grossman and Luis Ceze},
  booktitle = {Proceedings of 14th Annual Workshop on Duplicating, Deconstructing and Debunking (ISCAWDDD)},
  location = {Toronto, Canada},
  month = {June},
  title = {{Solver aided reverse engineering of architectural features}},
  year = {2017}
}


